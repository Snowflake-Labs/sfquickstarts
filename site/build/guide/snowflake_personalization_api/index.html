
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Build a Real-Time Personalization API with Snowflake</title>

  
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5Q8R2G');</script>
  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-08H27EW14N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-08H27EW14N');
</script>

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://quickstarts.snowflake.com/elements/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5Q8R2G"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  
  <google-codelab-analytics gaid="UA-41491190-9"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="snowflake_personalization_api"
                  title="Build a Real-Time Personalization API with Snowflake"
                  environment="web"
                  feedback-link="https://github.com/Snowflake-Labs/sfguides/issues">
    
      <google-codelab-step label="Overview" duration="5">
        <p>For real-time personalization, modern mobile+web applications and marketing technology platforms often want to retrieve customer profile, product/inventory, or location data through http APIs in real-time. This tutorial will go through how to build, deploy, host, and call a custom API for these point-lookups in real-time, all powered by Snowflake.</p>
<p>This API consists of creating a single endpoint for customer profile data stored in Snowflake. After completing this guide, you will have built a custom API built with <a href="https://flask.palletsprojects.com/" target="_blank">Python Flask</a> that queries a <a href="https://docs.snowflake.com/en/user-guide/tables-hybrid" target="_blank">Snowflake Hybrid Table</a>.</p>
<p>Optionally, you&#39;ll be able to test this endpoint to show that these lookups with <a href="https://JMeter.apache.org/download_JMeter.cgi" target="_blank">Apache JMeter</a> to show that you can get ~200ms or less response time (P90) on these lookups.</p>
<p>The dataset for this guide is the <a href="https://docs.snowflake.com/en/user-guide/sample-data-tpch" target="_blank">TPC-H</a> data set included in your Snowflake account.</p>
<h2 is-upgraded>Prerequisites</h2>
<ul>
<li>Privileges necessary to create a user, database, warehouse, compute pool, repository, network rule, external access integration, and service in Snowflake</li>
<li>Privileges necessary to access the tables in the <code>SNOWFLAKE_SAMPLE_DATA.TPCH_SF10</code> database and schema</li>
<li>Access to run SQL in the Snowflake console or SnowSQL</li>
<li>Basic experience using git, GitHub, and Codespaces</li>
<li>Intermediate knowledge of Python</li>
</ul>
<h2 class="checklist" is-upgraded>What You&#39;ll Learn</h2>
<ul class="checklist">
<li>How to configure and build a custom API Powered by Snowflake</li>
<li>How to build, publish, and deploy a container with the API in Snowflake</li>
</ul>
<h2 is-upgraded>What You&#39;ll Need</h2>
<ul>
<li><a href="https://snowflake.com" target="_blank">Snowflake</a> Account in an AWS or Azure commercial region</li>
<li><a href="https://github.com/" target="_blank">GitHub</a> Account with credits for Codespaces</li>
</ul>
<h2 is-upgraded>What You&#39;ll Build</h2>
<ul>
<li>Real-Time API Powered by Snowflake</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Setting up a Warehouse" duration="1">
        <p>The API needs a warehouse to query the data to return to the caller. To create the database and warehouse, connect to Snowflake and run the following commands in the Snowflake console or using SnowSQL:</p>
<pre><code language="language-sql" class="language-sql">USE ROLE ACCOUNTADMIN;
CREATE WAREHOUSE DATA_API_WH WITH WAREHOUSE_SIZE=&#39;xsmall&#39;;
</code></pre>
<h2 is-upgraded>Create the Application Role in Snowflake</h2>
<p>The application will run as a new role with minimal priviledges. To create the role, connect to Snowflake and run the following SQL statements to create the role and grant it access to the data needed for the application.</p>
<pre><code language="language-SQL" class="language-SQL">USE ROLE ACCOUNTADMIN;
CREATE ROLE DATA_API_ROLE;

GRANT USAGE ON WAREHOUSE DATA_API_WH TO ROLE DATA_API_ROLE;
GRANT IMPORTED PRIVILEGES ON DATABASE SNOWFLAKE_SAMPLE_DATA TO ROLE DATA_API_ROLE;

GRANT ROLE DATA_API_ROLE TO ROLE ACCOUNTADMIN;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Setting up your Development Environment" duration="3">
        <p>The code used in this guide is hosted in github. You will need a new Codespace from the GitHub <a href="https://github.com/sfc-gh-lambrosetti/snow_personalization_api" target="_blank">repository</a>.</p>
<p>To create a new codespace, browse to the GitHub <a href="https://github.com/sfc-gh-lambrosetti/snow_personalization_api" target="_blank">repository</a> in a browser. You will need to login to GitHub if you are not already logged in to access Codespaces. After logging in, click on the green &#34;&lt;&gt; Code&#34; button and &#34;create codespace on main&#34; button.</p>
<p>You will then be redirected into Codespaces where your development environment will load and all code from GitHub will be loaded in the project.</p>
<h2 is-upgraded>Endpoint</h2>
<p>The API creates a single endpoint using the Snowflake connector:</p>
<p><code>https://host/customer/CUST_ID</code></p>
<p>Which takes the following required path parameter:</p>
<p><code>CUST_ID</code> - the customer ID. This is a unique customer identifier for you customer. This guide uses a numeric ID; however, alphanumeric is also acceptable.</p>
<h2 is-upgraded>Code</h2>
<p><strong>NOTE: No coding or actions necessary as a part of this section - this is for your review and understanding only!</strong></p>
<p>The <code>src/</code> directory has all the source code for the API. The <code>app.py</code> file contains the main entrypoint for the API endpoint, <code>get_customer()</code>, using the Snowflake Connector for Python. The function retrieves a single, or multiple comma-separated, customer(s) from the <code>hybrid_customer</code> table. Review the code and the SQL needed to retrieve the data from Snowflake and serialize it to JSON for the response.</p>
<pre><code language="language-python" class="language-python">@app.route(&#39;/customer/&lt;cust_id&gt;&#39;)
@cache.memoize(timeout=180)
def get_customer(cust_id):
    sql_string = &#39;&#39;&#39;
        SELECT
            C_CUSTOMER_SK,
            C_CUSTOMER_ID,
            C_CURRENT_CDEMO_SK,
            C_CURRENT_HDEMO_SK,
            C_CURRENT_ADDR_SK,
            C_FIRST_SHIPTO_DATE_SK,
            C_FIRST_SALES_DATE_SK,
            C_SALUTATION,
            C_FIRST_NAME,
            C_LAST_NAME,
            C_PREFERRED_CUST_FLAG,
            C_BIRTH_DAY,
            C_BIRTH_MONTH,
            C_BIRTH_YEAR,
            C_BIRTH_COUNTRY,
            C_LOGIN,
            C_EMAIL_ADDRESS,
            C_LAST_REVIEW_DATE
        FROM api.data.hybrid_customer
        WHERE C_CUSTOMER_SK in ({cust_id});
    &#39;&#39;&#39;
    sql = sql_string.format(cust_id=cust_id)
    try:
        res = conn.cursor(DictCursor).execute(sql)
        return make_response(jsonify(res.fetchall()))
    except:
        abort(500, &#34;Error reading from Snowflake. Check the QUERY_HISTORY for details.&#34;)
</code></pre>
<p>You&#39;ll notice that an in-memory cache is used to cache responses for 180 seconds (3 minutes). This is because:</p>
<ol type="1">
<li>It&#39;s assumed that this data will not change very often (e.g. every 30-60 minutes).</li>
<li>A cache layer is needed because of the use-case and to reduce strain on the database (e.g. repeat calls to the same endpoint with the same ID)</li>
<li>A caching mechanism is not possible from the caller</li>
</ol>
<p>Later on, we&#39;ll have the opportunity to test the endpoint with and without the in-memory cache.</p>
<p>While this is only a single endpoint, you can easily add other endpoints as well. Check out how to create other endpoints in a similar version to this guide <a href="https://github.com/sfc-gh-bculberson/lab_data_api_python" target="_blank">here</a>.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Building the Application Container" duration="1">
        <p>To create the application container, we will leverage docker. The Dockerfile is based on python 3.8 and installs the required libraries needed for the application as well as the code. To create the docker container, run this command in the terminal provided by <strong>Codespaces</strong>:</p>
<pre><code language="language-bash" class="language-bash">docker build -t papi .
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Creating the Image Registry and Hybrid Table" duration="1">
        <p>To create the image registry and the database which contains it, connect to Snowflake and run the following commands in the Snowflake console or using SnowSQL:</p>
<pre><code language="language-sql" class="language-sql">USE ROLE ACCOUNTADMIN;
CREATE DATABASE API;
CREATE SCHEMA DATA;

GRANT ALL ON DATABASE API TO ROLE DATA_API_ROLE;
GRANT ALL ON SCHEMA API.PUBLIC TO ROLE DATA_API_ROLE;
GRANT ALL ON SCHEMA API.DATA TO ROLE DATA_API_ROLE;

USE ROLE DATA_API_ROLE;
CREATE OR REPLACE HYBRID TABLE hybrid_customer (
  C_CUSTOMER_SK NUMBER(38,0) PRIMARY KEY,
	C_CUSTOMER_ID VARCHAR(16),
	C_CURRENT_CDEMO_SK NUMBER(38,0),
	C_CURRENT_HDEMO_SK NUMBER(38,0),
	C_CURRENT_ADDR_SK NUMBER(38,0),
	C_FIRST_SHIPTO_DATE_SK NUMBER(38,0),
	C_FIRST_SALES_DATE_SK NUMBER(38,0),
	C_SALUTATION VARCHAR(10),
	C_FIRST_NAME VARCHAR(20),
	C_LAST_NAME VARCHAR(30),
	C_PREFERRED_CUST_FLAG VARCHAR(1),
	C_BIRTH_DAY NUMBER(38,0),
	C_BIRTH_MONTH NUMBER(38,0),
	C_BIRTH_YEAR NUMBER(38,0),
	C_BIRTH_COUNTRY VARCHAR(20),
	C_LOGIN VARCHAR(13),
	C_EMAIL_ADDRESS VARCHAR(50),
	C_LAST_REVIEW_DATE VARCHAR(10)
) AS
SELECT 
  C_CUSTOMER_SK,
	C_CUSTOMER_ID,
	C_CURRENT_CDEMO_SK,
	C_CURRENT_HDEMO_SK,
	C_CURRENT_ADDR_SK,
	C_FIRST_SHIPTO_DATE_SK,
	C_FIRST_SALES_DATE_SK,
	C_SALUTATION,
	C_FIRST_NAME,
	C_LAST_NAME,
	C_PREFERRED_CUST_FLAG,
	C_BIRTH_DAY,
	C_BIRTH_MONTH,
	C_BIRTH_YEAR,
	C_BIRTH_COUNTRY,
	C_LOGIN,
	C_EMAIL_ADDRESS,
	C_LAST_REVIEW_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CUSTOMER
    ORDER BY C_CUSTOMER_SK ASC
    LIMIT 10000;

USE ROLE ACCOUNTADMIN;
USE DATABASE API;
USE SCHEMA PUBLIC;

CREATE OR REPLACE IMAGE REPOSITORY API;

GRANT READ ON IMAGE REPOSITORY API TO ROLE DATA_API_ROLE;

SHOW IMAGE REPOSITORIES;
</code></pre>
<p>Note the <code>repository_url</code> in the response as that will be needed in the next step.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Pushing the Container to the Repository" duration="1">
        <p>Run the following command in the terminal, replacing the <code>{repository_url}</code> with your repository in the previous step, in <strong>Codespaces</strong> to login to the container repository. You will be prompted for your Snowflake username and password to login to your repository.</p>
<pre><code language="language-bash" class="language-bash">docker login {repository_url}
docker build -t {repository_url}/papi .
docker push {repository_url}/papi
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Creating the Compute Pool" duration="1">
        <p>To create the compute pool to run the application, connect to Snowflake and run the following command in the Snowflake console or using SnowSQL:</p>
<pre><code language="language-sql" class="language-sql">USE ROLE ACCOUNTADMIN;

CREATE COMPUTE POOL API
  MIN_NODES = 1
  MAX_NODES = 5
  INSTANCE_FAMILY = CPU_X64_XS;

GRANT USAGE ON COMPUTE POOL API TO ROLE DATA_API_ROLE;
GRANT MONITOR ON COMPUTE POOL API TO ROLE DATA_API_ROLE;

</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Creating the Application Service" duration="1">
        <p>To create the service to host the application, connect to Snowflake and run the following command in the Snowflake console or using SnowSQL.</p>
<pre><code language="language-sql" class="language-sql">USE ROLE ACCOUNTADMIN;
GRANT BIND SERVICE ENDPOINT ON ACCOUNT TO ROLE DATA_API_ROLE;

USE ROLE DATA_API_ROLE;
CREATE SERVICE API.PUBLIC.API
 IN COMPUTE POOL API
 FROM SPECIFICATION  
$$
spec:
  container:
  - name: api
    image: /api/public/api/papi:latest
  endpoint:
  - name: api
    port: 8001
    public: true
$$
QUERY_WAREHOUSE = DATA_API_WH;

</code></pre>
<p>It will take a few minutes for your service to initialize, you can check status with these commands:</p>
<pre><code language="language-sql" class="language-sql">CALL SYSTEM$GET_SERVICE_STATUS(&#39;api&#39;);
CALL SYSTEM$GET_SERVICE_LOGS(&#39;api.public.api&#39;, 0, &#39;api&#39;);
</code></pre>
<p>After your service has started, you can get the endpoints with this command:</p>
<pre><code language="language-sql" class="language-sql">SHOW ENDPOINTS IN SERVICE API;
</code></pre>
<p>The endpoint generation will take 2-3 minutes, while you wait, go ahead and check to make sure you can select from the Hybrid Table:</p>
<pre><code language="language-sql" class="language-sql">USE ROLE DATA_API_ROLE;
SELECT * FROM HYBRID_CUSTOMER WHERE C_CUSTOMER_SK = 1885;
</code></pre>
<p>Check the endpoint again when you&#39;re ready to see if it&#39;s finished:</p>
<pre><code language="language-sql" class="language-sql">SHOW ENDPOINTS IN SERVICE API;
</code></pre>
<p>Make note of the ingress_url as that will be needed to test the application. This service will start the API, running at <code>https://{INGRESS_URL}</code>.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Testing the API" duration="1">
        <p>To verify the API is online, go to the <code>https://{INGRESS_URL}</code> in your browser. You will be asked to authenticate to Snowflake and be given the root content:</p>
<pre><code language="language-json" class="language-json">{&#34;result&#34;:&#34;Nothing to see here&#34;}
</code></pre>
<h2 is-upgraded>Testing using a webpage</h2>
<p>This project comes with a simple webpage that allows you to test the API. To get to it, open <code>https://{INGRESS_URL}/test</code> in a web browser.</p>
<p>There is a form that allows you to test retrieval of a customer. Enter any number between 1 and 10000.</p>
<p>When you hit the <code>Submit</code> button, the API endpoint is called and the data is returned to the web page.</p>
<p><strong>Note: The first time you try this, it might take 1-3 seconds because the virtual warehouse needs to start. Afterwards, you should not see this latency.</strong></p>


      </google-codelab-step>
    
      <google-codelab-step label="Calling the API programmatically" duration="3">
        <h2 is-upgraded>Create the user and generate the Snowflake Token</h2>
<p>For this next step, go back to <strong>codespaces</strong> - we&#39;ll need to create a Snowflake service user to programmatically call the API. This user will need to authenticate with key-pair authentication - let&#39;s generate the RSA private key:</p>
<pre><code language="language-bash" class="language-bash">openssl genrsa 2048 | openssl pkcs8 -topk8 -inform PEM -out rsa_key.p8 -nocrypt
</code></pre>
<p>Then generate public key:</p>
<pre><code language="language-bash" class="language-bash">openssl rsa -in rsa_key.p8 -pubout -out rsa_key.pub
</code></pre>
<p>And finally print the key to use on the new Snowflake service user:</p>
<pre><code language="language-bash" class="language-bash">awk &#39;NF {sub(/-----.*-----/, &#34;&#34;); printf &#34;%s&#34;, $0} END {print &#34;&#34;}&#39; rsa_key.pub
</code></pre>
<p>Go ahead and copy the above public key output, as you&#39;ll need to paste it into the <code>RSA_PUBLIC_KEY</code> below when you create the user in Snowflake:</p>
<pre><code language="language-sql" class="language-sql">USE ROLE ACCOUNTADMIN;
CREATE USER SVC_DATA_API TYPE = SERVICE DEFAULT_ROLE = DATA_API_ROLE RSA_PUBLIC_KEY = &#39;MIIB...&#39;;
GRANT ROLE DATA_API_ROLE TO USER SVC_DATA_API;
</code></pre>
<p>Great! Now, we&#39;ll need to generate a token to call the API, this is a 2 step process:</p>
<ol type="1">
<li>Generate a JWT (JSON Web Token) using your key-pair</li>
<li>Use the JWT to generate a Snowflake Token</li>
</ol>
<p>Luckily, we have some helper scripts to do that for you. Back in <strong>codespaces</strong>, here&#39;s what you need to run:</p>
<pre><code language="language-bash" class="language-bash">python3 access-via-keypair.py \
--account {account-identifier} \
--user SVC_DATA_API \
--role DATA_API_ROLE \
--private_key_file_path rsa_key.p8 \
--endpoint {ingress-url}
</code></pre>
<ul>
<li><strong>ACCOUNT-IDENTIFIER</strong> is your LOCATOR + REGION (e.g. abc1234.us-east-1). Find more info about that <a href="https://docs.snowflake.com/en/user-guide/admin-account-identifier" target="_blank">here</a> Note*: Locator is usually not recommended; however, it&#39;s the only thing that worked with my demo account. Feel free to try with your true &#34;account identifier&#34; and let me know if that works!</li>
<li><strong>INGRESS-URL</strong> is the <code>{INGRESS_URL}</code> from earlier. In case you need a way to find it again, run this in Snowflake or SnowSQL:</li>
</ul>
<pre><code language="language-sql" class="language-sql">SHOW ENDPOINTS IN SERVICE API;
</code></pre>
<p>Now, run the helper script by copy+paste into codespaces, and you should get a Snowflake Token in the response, printed in the codespaces terminal. Copy that for the next step. This Snowflake Token will be available for use for the next 59 minutes. Afterwards, you&#39;ll need to generate a new token by running the same script.</p>
<p>If you want more details on how the JWT get and Snowflake Token get generated, and to get the full helper scripts, visit these <a href="https://docs.snowflake.com/en/developer-guide/snowpark-container-services/tutorials/tutorial-1#optional-access-the-public-endpoint-programmatically" target="_blank">docs</a>.</p>
<h2 is-upgraded>Test using cURL or Postman</h2>
<p>You can test this from codespaces, or your terminal locally (remember to use <code>bash</code> if you&#39;re in zsh):</p>
<pre><code language="language-bash" class="language-bash">curl --location &#39;https://{INGRESS_URL}/customer/1885&#39; \
--header &#39;Authorization: Snowflake Token=&#34;&lt;SNOWFLAKE_TOKEN&gt;&#34;&#39; \
--header &#39;Content-Type: application/x-www-form-urlencoded&#39;
</code></pre>
<p>Alternatively, you can test with <a href="https://www.postman.com/downloads/" target="_blank">Postman</a>.</p>
<p>When testing individual calls, remember that performance might be slightly higher than you expect. It&#39;s why I recommend testing under some load with JMeter.</p>


      </google-codelab-step>
    
      <google-codelab-step label="(Optional) Test performance with JMeter locally" duration="8">
        <p>Disclaimer: This performance testing is supposed to be directional in nature - don&#39;t think of it as &#34;true&#34; performance testing.</p>
<p>First, install Apache JMeter. If you&#39;re on a Mac, it&#39;s easiest to do this with Homebrew via</p>
<pre><code language="language-bash" class="language-bash">brew install jmeter

#after installation
jmeter
</code></pre>
<p>Otherwise, check the <a href="https://JMeter.apache.org/download_JMeter.cgi" target="_blank">download page</a>.</p>
<p>From the github repo, download the Test Plan <code>snow_papi.jmx</code> and the <code>cust_ids.csv</code> files locally.</p>
<p>After starting JMeter, select <code>File</code> and then <code>Open</code>, and select <code>snow_papi.jmx</code>. This is the test plan that you&#39;ll use for JMeter. You&#39;ll need to change the following configurations to the test plan:</p>
<ol type="1">
<li>In the left nav, under &#34;Test Personalization API&#34;, click <code>HTTP Request</code> and replace the <code>{INGRESS_URL}</code> with the endpoint URL. You can copy/paste from your cURL or Postman test earlier.</li>
<li>In the &#34;HTTP Header Manager&#34;, replace <code><Snowflake TOKEN></code> with the correct Token. You can also copy/paste this from the cURL/Postman test earlier.</li>
<li>In the &#34;Customer ID Test Set Config&#34;, change the <code>Filename</code> path to be the correct path for the <code>cust_ids.csv</code> file that you downloaded earlier.</li>
</ol>
<p>After that, you should be able to hit the green arrow (play button) at top to start/run! You can click &#34;Aggregate Graph&#34;, select  multiple check boxes for Median, 90% line, 95% line, and 99% line to compare, and the <code>Graph</code> tab to look at the actual bar chart.</p>
<p>A quick note - while we load an in-memory cache as part of the app, this test set is set by default <em>to not use</em> the cache at all. To see performance with the cache, go back to &#34;Customer ID Test Set Config&#34;, and turn <code>Sharing Mode</code> to &#34;Current Thread&#34;. If you decide to try this, don&#39;t forget to stop the exist testing, right-click the &#34;Results Tree&#34; and &#34;Aggregate Graph&#34; to <code>clear</code> out captured results before testing again!</p>


      </google-codelab-step>
    
      <google-codelab-step label="Stopping the API" duration="1">
        <p>To stop the API, you can suspend the service. From the Snowflake console or SnowSQL, run:</p>
<pre><code language="language-sql" class="language-sql">USE ROLE DATA_API_ROLE;
ALTER SERVICE API.PUBLIC.API SUSPEND;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Cleanup" duration="2">
        <p>To fully remove everything you did today you only need to drop some objects in your Snowflake account. From the Snowflake console or SnowSQL, as <code>ACCOUNTADMIN</code> run:</p>
<pre><code language="language-SQL" class="language-SQL">USE ROLE ACCOUNTADMIN;

DROP DATABASE IF EXISTS API;
DROP USER IF EXISTS SVC_DATA_API;
DROP ROLE IF EXISTS DATA_API_ROLE;
DROP COMPUTE POOL IF EXISTS API;
DROP WAREHOUSE IF EXISTS DATA_API_WH;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Conclusion and Resources" duration="1">
        <h2 is-upgraded>Conclusion</h2>
<p>You&#39;ve successfully built a custom Personalization API in Python powered by Snowflake Hybrid Tables and Snowpark Container Services.</p>
<p>When you go to put an API into production you should think about how you&#39;ll generate new tokens over time, and use a more production-ready cache like Redis, which can also be hosted with Snowpark Container Serivces.</p>
<p>To get more comfortable with this solution, implement new endpoints with new datasets, like products, store locations, or other catalog data.</p>
<h2 is-upgraded>What You Learned</h2>
<ul>
<li>How to configure and build a custom point-lookup API Powered by Snowflake</li>
<li>How to test the API from your local machine</li>
</ul>
<h2 is-upgraded>Resources</h2>
<p>If you want to build a Data API using Snowflake standard tables for analytical queries, be sure to check out the previous version of this <a href="https://github.com/sfc-gh-bculberson/lab_data_api_python" target="_blank">here</a>.</p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/native-shim.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/custom-elements.min.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/prettify.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>
  <script type="text/javascript">
    window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=t.forceSSL||"https:"===document.location.protocol,a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=(r?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+e+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","removeEventProperty","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
    heap.load("2025084205");
  </script>
</body>
</html>
