summary: これはSnowflakeの大まかな紹介であり、ログイン、クエリの実行、データのロード方法について説明しています。
id: getting_started_with_snowflake_ja
categories: featured,getting-started
environments: web
status: Published
feedback link: https://github.com/Snowflake-Labs/sfguides/issues
tags: Getting Started, Data Science, Data Engineering, ja, はじめに, データサイエンス, データエンジニアリング

# Snowflake入門 - ゼロからはじめるSnowflake

<!-- ------------------------ -->
## 概要

duration:2

Snowflakeへようこそデータベースおよびデータウェアハウスの管理者およびアーキテクト向けに作成されたこのエントリーレベルガイドでは、Snowflakeインターフェイスの操作方法について説明すると共に、Snowflakeのコア機能をいくつかご紹介します。[Snowflakeの30日間の無料トライアルに登録](https://trial.snowflake.com)し、このラボ演習を進めてください。基本事項を学習したら、自社のデータを処理したり、Snowflakeのより高度な機能をプロのように使いこなしたりできるようになります。

### 無料のバーチャルハンズオンラボ

このSnowflakeガイドは、インストラクター主導の無料のバーチャルハンズオンラボとしてご利用いただけます。[今すぐVHOLに登録してください](https://www.snowflake.com/virtual-hands-on-lab/)。

### 前提条件：

- [Snowflakeの30日間無料トライアル環境](https://trial.snowflake.com)の使用
- SQL、データベース構想、オブジェクトについての基本知識
- CSVカンマ区切りのファイルおよびJSON半構造化データに精通していること

### 学習する内容：

- ステージ、データベース、テーブル、ビュー、仮想ウェアハウスの作成方法。
- 構造化データおよび半構造化データのロード方法。
- テーブル間の結合を含む、Snowflake内のデータに対する分析クエリの実行方法。
- オブジェクトのクローン方法。
- タイムトラベルを使用してユーザーエラーを元に戻す方法。
- ロールおよびユーザーを作成し、権限を付与する方法。
- 他のアカウントと安全かつ簡単にデータを共有する方法。
- Snowflakeマーケットプレイスでデータセットを利用する方法。

<!-- ------------------------ -->
## ラボ環境の準備

duration:2

まだ[Snowflakeの30日間無料トライアル](https://signup.snowflake.com/developers)に登録していない方は、登録してください。このラボの残りのセクションでは、トライアルに登録することによって作成した新しいSnowflakeアカウントの使用を前提としています。

このラボで使用するSnowflakeエディション（標準、エンタープライズ、ビジネスクリティカルなど）、クラウドプロバイダー（AWS、Azure、GCP）、リージョン（米国東部、EUなど）は、どれでも構いません。ただし、物理的に最も近いリージョンを選択し、Snowflakeエディションとして最も人気のあるエンタープライズを選択することをお勧めします。

登録後、アクティベーションリンクとSnowflakeアカウントにアクセスするためのURLが記載されたメールが届きます。

<!-- ------------------------ -->
## Snowflakeのユーザーインターフェイスとラボストーリー

duration:8

> aside negative
> 
> **スクリーンショット、サンプルコード、環境について** このラボのスクリーンショットに表示される例と結果は、皆さんが演習を完了したときに実際に目にするものとは若干異なる場合があります。

### Snowflakeユーザーインターフェイス（UI）へのログイン

ブラウザウィンドウを開き、登録メールと合わせて送信されたSnowflakeの30日間トライアル環境のURLを入力します。

以下のログインダイアログが表示されます。登録時に指定したユーザー名とパスワードを入力します。

![ログイン画面](assets/3UIStory_1.png)

### Snowflake UIを実際に操作してみる

Snowflakeの使い方に慣れていきましょう。このセクションでは、ユーザーインターフェイスの基本コンポーネントについて説明します。左側の余白を上から下へ見ていきましょう。

![snowflakeナビゲーションバー](assets/3UIStory_2.png)

#### ワークシート

![「ワークシート」タブのメイン画面](assets/3UIStory_3.png)

「**ワークシート**」タブには、SQLクエリの送信、DDLおよびDML操作の実行、クエリまたは操作の完了時の結果表示のためのインターフェイスが用意されています。新規ワークシートは、右上の「**+ワークシート**」をクリックして作成します。

![「ワークシート」タブの詳細](assets/3UIStory_4.png)

左上には次の項目があります。

- **ホーム**アイコン：メインコンソールに戻ったり、ワークシートを閉じたりするときに使用します。
- **Worksheet_name**ドロップダウン：デフォルトの名前は、ワークシート作成時のタイムスタンプとなります。ワークシート名を編集するには、タイムスタンプをクリックしてください。ドロップダウンには、ワークシートに対して実行できる追加の操作も表示されます。
- 「**フィルターの管理」**ボタン：カスタムフィルターは、サブクエリまたは値のリストとして解決される特別なキーワードです。

右上には次の項目があります。

- 「**コンテキスト」**ボックス：これにより、Snowflakeがこのセッションで使用するロールとウェアハウスを把握できます。UIまたはSQLコマンドで変更できます。
- 「**共有」**ボタン：共有メニューを開いて他のユーザーに共有するか、ワークシートへリンクをコピーします。
- 「**再生/実行**」ボタン：現在カーソルを合わせているSQLステートメント、または選択された複数のSQLステートメントを実行します。

中央のペインには次の項目があります。

- 上部にある、ワークシートのデータベース/スキーマ/オブジェクトコンテキストを設定するためのドロップダウン。
- クエリおよびその他のSQLステートメントを入力および実行する一般的な作業領域。

中段左のパネルには次の項目があります。

- 「**ワークシート**」タブ：このタブを使用すると、異なるワークシートを素早く選択して切り替えることができます。
- 「**データベース**」タブ：このタブを使用すると、現在のロールが使用できるすべてのデータベースオブジェクトを確認できます。
- **検索**バー：ワークシートで現在使用されているロールがアクセスできるすべてのデータベース、スキーマ、テーブル、ビューを探索できるデータベースオブジェクトブラウザです。

最下部のペインには、クエリやその他の操作の結果が表示されます。さらに、4つのオプション（「**オブジェクト**」、「**クエリ」**、「**結果」**、「**チャート」**）もあります。これらはUI上の該当するパネルを開閉します。「**チャート」**を選択すると、返された結果を視覚化するパネルが開きます。これについては、後で詳しく説明します。

このページの各種ペインは、スライダーを調整することでサイズを変更できます。ワークシート内に余裕が必要な場合は、左のパネルのデータベースオブジェクトブラウザを折りたたんでください。本ガイドのスクリーンショットの多くは、このパネルを閉じた状態となっています。

> aside negative
> 
> **ワークシートとUIの比較** このラボのほとんどの演習は、時間を節約するため、このワークシート内に記述済みのSQLを使用して実行されます。これらのタスクはUIからでも実行できますが、複数のUIタブを行ったり来たりしなければならないことになります。

#### ダッシュボード

![「ダッシュボード」タブ](assets/3UIStory_5.png)

「**ダッシュボード**」タブでは、1つ以上のチャートの柔軟な表示を作成できます（並べ替え可能なタイル形式で）。タイルとウィジェットは、ワークシートに結果を返すSQLクエリを実行することによって生成されます。ダッシュボードは、最小限の構成においてさまざまなサイズで機能します。

#### データベース

![「データベース」タブ](assets/3UIStory_6.png)

「**データ**」の下の「**データベース」**タブには、自分が作成したデータベースやアクセス権限のあるデータベースに関する情報が表示されます。データベースの作成、クローン、ドロップ、または所有権の譲渡を行ったり、UIのデータをロードしたりできます。自分の環境にデータベースがすでに存在していることに注意してください。ただし、それをこのラボで使用することはありません。

#### プライベート共有データ

![「共有データ」タブ](assets/3UIStory_7.png)

また、「**データ」**の下の「**プライベート共有データ**」タブでは、データのコピーを作成することなく、個別のSnowflakeアカウント間または外部ユーザー間でSnowflakeテーブルを簡単かつ安全に共有するためのデータシェアリングを設定できます。データシェアリングについてはセクション10で取り上げます。

#### マーケットプレイス

![「マーケットプレイス」タブ](assets/3UIStory_8.png)

「**マーケットプレイス**」タブでは、すべてのSnowflakeユーザーが、プロバイダーが提供するデータセットを閲覧および利用することができます。共有データには2つのタイプがあります。公開データとパーソナライズされたデータです。公開データとは、即時クエリに利用できる無料のデータセットです。パーソナライズされたデータの場合は、データのプロバイダーに連絡し、データ共有の承認を得る必要があります。

#### クエリ履歴

![「履歴」タブ](assets/3UIStory_9.png)

「**アクティビティ」**の下には、「**クエリ履歴**」と「**コピー履歴」**という2つのタブがあります。

- 「**クエリ履歴」**には、過去のクエリと、結果を絞り込むために使用できるフィルター（ユーザー、ウェアハウス、ステータス、クエリタグなど）が表示されます。過去14日間に自分のSnowflakeアカウントから実行されたすべてのクエリの詳細が表示されます。クエリIDをクリックすると、詳細情報を見ることができます。
- 「**コピー履歴**」には、データをSnowflakeに取り込むために実行されたコピーコマンドのステータスが表示されます。

#### ウェアハウス

![「ウェアハウス」タブ](assets/3UIStory_10.png)

「**管理**」の下の「**ウェアハウス」**タブでは、Snowflakeでデータをロードまたはクエリするための、仮想ウェアハウスと呼ばれるコンピューティングリソースを設定および管理します。COMPUTE_WHと呼ばれるウェアハウスが、お使いの環境内にすでに存在しています。

#### リソースモニター

![「リソースモニター」タブ](assets/3UIStory_11.png)

「**管理」**の下の「**リソースモニター」**タブには、仮想ウェアハウスが消費するクレジット数を制御するために作成されたすべてのリソースモニターが表示されます。各リソースモニターについて、クレジットクォータ、監視のタイプ、スケジュール、および仮想ウェアハウスがクレジット上限に達したときに実行されるアクションが表示されます。

#### ロール

![「ロール」タブ](assets/3UIStory_12.png)

「**管理」**の下の「**ユーザーとロール**」タブのサブタブである「**ロール」**には、ロールのリストとその階層が表示されます。このタブでは、ロールの作成、再編成、およびユーザーへの付与を実行できます。「**テーブル」**サブタブを選択すると、ロールを表形式/リスト形式でも表示できます。

#### ユーザー

![「ユーザー」タブ](assets/3UIStory_13.png)

「**管理」**タブの下の「**ユーザーとロール**」タブのサブタブである「**ユーザー**」には、そのアカウント内のユーザーのリストと、デフォルトのロールおよびユーザーの所有者が表示されます。新規アカウントでは、追加のロールが作成されていないため、レコードは表示されません。現在のロールを通じて付与された権限により、このタブに表示される情報が決まります。このタブで利用できるすべての情報を表示するには、ロールをアカウント管理者に切り替えてください。

![ユーザー設定ドロップダウン](assets/3UIStory_14.png)

UIの右上にあるユーザー名をクリックすると、パスワード、ロール、環境設定を変更できます。Snowflakeには、システム定義のロールがいくつかあります。現在のロールはデフォルトの`SYSADMIN`であり、このラボではほぼこのロールのままとなります。

> aside negative
> 
> **SYSADMIN** `SYSADMIN`（システム管理者）ロールには、アカウント内でウェアハウス、データベース、およびその他のオブジェクトを作成する権限があります。リアルワールド環境では、このラボのタスクにさまざまなロールを使用し、ユーザーにロールを割り当てることになります。ロールとSnowflakeのアクセス制御モデルについてはセクション9で詳しく取り上げます。また、[Snowflakeドキュメント](https://docs.snowflake.net/manuals/user-guide/security-access-control.html)でも追加情報をご覧いただけます。

### ラボストーリー

このラボは、米国のニューヨーク市に実在する市全域の自転車シェアリングシステムであるCiti Bikeの分析チームをベースとしています。このチームは、自社の自転車利用者についての理解を深め、利用者に最高のサービスを提供する方法を知るために、社内のトランザクションシステムからのデータについて分析を実行したいと考えています。

まず私たちは、自転車利用者のトランザクションから得られた構造化された`.csv`データをSnowflakeにロードします。その後、オープンソースの半構造化JSON気象データを利用して、自転車の利用回数と天候に相関関係があるかを判断していきます。

<!-- ------------------------ -->
## データロードの準備

duration:14

構造化されたCiti Bike利用者のトランザクションデータをSnowflakeにロードする準備から始めましょう。

このセクションでは、以下の手順を、順を追って説明していきます。

- データベースとテーブルを作成する。
- 外部ステージを作成する。
- データのファイル形式を作成する。

> aside negative
> 
> **データをSnowflakeに取り込む** 多くのロケーションからSnowflakeにデータを取り込むには多数の方法があります。たとえば、COPYコマンド、Snowpipeの自動取り込み、外部コネクタ、サードパーティのETL/ELTソリューションなどです。Snowflakeへのデータの取り込みに関する詳細については、[Snowflakeドキュメント](https://docs.snowflake.net/manuals/user-guide-data-load.html)を参照してください。このラボでは、COPYコマンドとAWS S3ストレージを使用してデータを手動でロードします。実際のシナリオでは、自動化プロセスまたはETLソリューションを使用する可能性が高いでしょう。

使用するデータは、Citi Bike（NYC）によって提供された自転車シェアのデータです。データは、米国西部リージョンのAmazon AWS S3バケットにエクスポートされ、事前設定されています。データは、走行時間、ロケーション、ユーザータイプ、性別、年齢などの情報で構成されています。AWS S3上では、このデータは6,150万行、377個のオブジェクト、圧縮サイズ1.9GBで表されています。

以下は、Citi Bike（CSV）データファイルのスニペットです。

![データスニペット](assets/4PreLoad_1.png)

このカンマ区切り形式のファイルには、単一のヘッダーラインがあり、ヘッダーラインに含まれるフィールドの見出しを含め、すべての文字列値がダブルクォーテーションで囲まれています。これは、このセクションの後半で、このデータを格納するSnowflakeテーブルを構成する際に重要になります。

### データベースとテーブルを作成する

まず、構造化データのロードに使用する`CITIBIKE`という名前のデータベースを作成しましょう。

左上の「**ロールの切り替え」** > 「**SYSADMIN**」で自分の名前を選択し、現在SYSADMINロールを使用していることを確認してください。

「**データベース」**タブに移動します。「**作成**」をクリックし、データベースに`CITIBIKE`という名前を付けて「**作成**」をクリックします。

![ワークシートの作成](assets/4PreLoad_2.png)

「**ワークシート**」タブに移動します。ステップ3で作成したワークシートが表示されます。

![新規ワークシート](assets/4PreLoad_3.png)

ワークシート内のコンテキストを適切に設定する必要があります。ワークシートの右上隅で、「**共有」**ボタンの左のボックスをクリックし、コンテキストメニューを表示します。ここで、各ワークシートから表示および実行できるエレメントを制御します。ここでは、UIを使用してコンテキストを設定します。このラボの後半では、ワークシート内のSQLコマンドを使用して同じことを実行します。

以下のコンテキスト設定を選択します。

ロール：`SYSADMIN`ウェアハウス：`COMPUTE_WH`

![コンテキストのロールとウェアハウスの設定](assets/4PreLoad_4.png)

次に、データベースのドロップダウンで、以下のコンテキスト設定を選択します。

データベース：`CITIBIKE` スキーマ = `PUBLIC`

![コンテキストデータベース設定](assets/4PreLoad_4b.png)

> aside negative
> 
> **データ定義言語（DDL）の操作は無料です。**これまで実行したDDL操作はどれもコンピューティングリソースを必要としません。そのため、すべてのオブジェクトを無料で作成することができます。

ワークシートでの作業をしやすくするために、名前を変更しましょう。左上隅で、ワークシート名（これはワークシート作成時のタイムスタンプです）をダブルクリックし、`CITIBIKE_ZERO_TO_SNOWFLAKE`に変更します。

次に、カンマ区切りのデータのロードに使用する`TRIPS`という名前のテーブルを作成します。UIを使用する代わりに、ワークシートを使用してテーブルを作成するDDLを実行します。以下のSQLテキストをワークシートにコピーしてください。

```SQL
create or replace table trips
(tripduration integer,
starttime timestamp,
stoptime timestamp,
start_station_id integer,
start_station_name string,
start_station_latitude float,
start_station_longitude float,
end_station_id integer,
end_station_name string,
end_station_latitude float,
end_station_longitude float,
bikeid integer,
membership_type string,
usertype string,
birth_year integer,
gender integer);
```

> aside negative
> 
> **コマンド実行のための多数のオプション。**UI、「ワークシート」タブ、またはSnowSQLコマンドラインツールを使用して実行できます。また、お好みのSQLエディターを使用してODBC/JDBC経由で実行することも、その他のコネクタ（Python、Sparkなど）を使用して実行することもできます。前述のとおり、このラボでは、時間を節約するため、ほとんどの操作はUIを使用せずにワークシートで記述済みSQLを実行することで行われます。

SQLテキストの任意の場所にカーソルを合わせ、ワークシートの右上にある青い「**再生/実行**」ボタンをクリックしてクエリを実行します。または、キーボードショートカットの[Ctrl]/[Cmd]+[Enter]を使用します。

TRIPSテーブルが作成されたことを確認します。ワークシートの下部の「結果」セクションに、「Table TRIPS successfully created（テーブルTRIPSが問題なく作成されました）」というメッセージが表示されます。

![TRIPS確認メッセージ](assets/4PreLoad_5.png)

ワークシート左上の**ホーム**アイコンをクリックして「**データベース**」タブに移動します。「**データ」**、「**データベース」**の順にクリックします。データベースリストで、`CITIBIKE`、`PUBLIC`、「**テーブル」**の順にクリックすると、新たに作成した`TRIPS`テーブルが表示されます。左側にデータベースが表示されない場合は、データベースが隠れている場合がありますので、ブラウザを拡大してください。

![TRIPSテーブル](assets/4PreLoad_6.png)

`TRIPS`と「**列**」タブをクリックすると、先ほど作成したテーブル構造が表示されます。

![TRIPSテーブル構造](assets/4PreLoad_7.png)

### 外部ステージを作成する

ここでは、公開された外部のS3バケット内ですでにステージングされている、構造化されたカンマ区切りのデータを扱います。このデータを使用する前に、まず外部バケットのロケーションを指定するステージを作成する必要があります。

> aside positive
> 
> このラボではAWS-Eastバケットを使用します。将来のデータのエグレス/転送コストを防ぐために、Snowflakeアカウントと同じクラウドプロバイダーおよびリージョンからステージングロケーションを選択する必要があります。

「**データベース**」タブから、`CITIBIKE`データベースと`PUBLIC`スキーマをクリックします。「**作成」**ボタンをクリックし、その後、「**Stage**」、「**Amazon S3**」の順にクリックします。

![ステージ作成](assets/4PreLoad_8.png)

開いた「セキュリティ保護可能なオブジェクトの作成」ダイアログで、SQLステートメントの以下の値を置き換えます。

`<stage_name>`: `citibike_trips`

`<url>`: `s3://snowflake-workshop-lab/citibike-trips-csv/`

**注意：**URLの最後には、必ずフォワードスラッシュ（`/`）を入れてください。これを入れておかなければ、後でバケットからデータを読み込む際にエラーが発生します。また、必要のない「credentials = (...)」ステートメントが削除されていることを確認してください。下図のように「--」を使用してコメントアウトすることもできます。create stageコマンドは、下図のようになります。あるいは、3行目を含めないでください。

> aside positive
> 
> このラボのS3バケットは公開であるため、ステートメント内のcredentialsオプションは空のままで構いません。実際のシナリオでは、外部ステージに使用するバケットにはキー情報が必要になるでしょう。

![ステージ設定の作成](assets/4PreLoad_9.png)

では`citibike_trips`ステージのコンテンツを見ていきましょう。「**ワークシート」**タブに戻り、作成した「CITIBIKE_ZERO_TO_SNOWFLAKE」ワークシートを開いて、下図のように、先ほどのコードの下に以下のSQLステートメントを追加して実行します。

```SQL
list @citibike_trips;
```

最下部のペインの結果に、ステージ内のファイルのリストが表示されます。

![ワークシート結果](assets/4PreLoad_10.png)

### ファイル形式を作成する

Snowflakeにデータをロードする前に、データ構造に合うファイル形式を作成する必要があります。

ワークシートで、以下のコマンドをそれ以外のコードの下に追加して実行し、ファイル形式を作成します。

```SQL
--create file format

create or replace file format csv type='csv'
  compression = 'auto' field_delimiter = ',' record_delimiter = '\n'
  skip_header = 0 field_optionally_enclosed_by = '\042' trim_space = false
  error_on_column_count_mismatch = false escape = 'none' escape_unenclosed_field = '\134'
  date_format = 'auto' timestamp_format = 'auto' null_if = ('') comment = 'file format for ingesting data for zero to snowflake';
```

![ファイル形式の作成](assets/4PreLoad_11.png)

次のコマンドを実行することにより、ファイル形式が正しい設定で作成されていることを確認します。

```SQL
--verify file format is created

show file formats in database citibike;
```

作成されたファイル形式が結果にリスト表示されます。

![ファイル形式の作成設定](assets/4PreLoad_12.png)

<!-- ------------------------ -->
## データのロード

duration:10

このセクションでは、仮想ウェアハウスとCOPYコマンドを使用して、前のセクションで作成したSnowflakeテーブルへの構造化データの一括ロードを開始します。

### データロードのためのウェアハウスのサイズ変更と使用

データをロードするにはコンピューティングリソースが必要です。Snowflakeコンピュートノードは仮想ウェアハウスと呼ばれ、データのロード、クエリの実行、DML操作の実行のいずれであっても、ワークロードに応じて動的にサイズを変更できます。それぞれのワークロードは独自のウェアハウスを持つことができるため、リソースの競合はありません。

「**ウェアハウス**」タブへ移動します（「**管理」**の下）。ここでは、既存のウェアハウスをすべて表示できるほか、使用状況トレンドの分析も可能です。

右上にある「**+ウェアハウス」**に注意してください。ここで新しいウェアハウスを素早く追加できます。ただし、ここでは30日間のトライアル環境に含まれる既存のウェアハウスであるCOMPUTE_WHを使用します。

`COMPUTE_WH`ウェアハウスの行をクリックします。その後、右上にある**...**（3つのドット）をクリックすると、ウェアハウス上で実行できるアクションが表示されます。このウェアハウスを使用して、AWS S3からデータをロードします。

![コンピューティングウェアハウスの設定](assets/5Load_1.png)

「**編集」**をクリックし、このウェアハウスのオプションとSnowflakeのユニークな機能の一部を実際に確認してみてください。

> aside positive
> 
> このアカウントがSnowflakeエンタープライズエディション（またはそれ以上）を使用していない場合は、以下のスクリーンショットの「**モード」**または「**クラスター」**オプションは表示されません。このラボでは、マルチクラスターウェアハウス機能は使用しませんが、Snowflakeの主な機能として説明します。

![ウェアハウス構成の設定](assets/5Load_2.png)

- 「**サイズ」**ドロップダウンでウェアハウスの容量を選択します。大規模なデータロード処理やコンピュートインテンシブなクエリの場合は、より大規模なウェアハウスが推奨されます。サイズは、Snowflakeアカウントがホストされているクラウドプロバイダー（AWS、Azure、またはGCP）からプロビジョニングされる基礎となるコンピューティングリソースの量に直結します。また、ウェアハウスが1時間稼働するごとに消費するクレジット数もこのサイズによって決まります。サイズが大きくなればなるほど、クラウドプロバイダーからウェアハウスに割り当てられるコンピューティングリソースの量とウェアハウスが消費するクレジットの数が多くなります。たとえば、`4X-Large`設定では、1時間ごとに128クレジットが消費されます。このサイズ設定は、いつでもワンクリックで変更できます。

- Snowflakeエンタープライズエディション（またはそれ以上）を使用している場合は、「**クエリアクセラレーション**」オプションを使用できます。このオプションをウェアハウスに対して有効にすると、通常のクエリよりも多くのリソースを使用する外れ値クエリの影響を減らすことで、ウェアハウス全体のパフォーマンスを向上させることができます。これは無効のままにしておきます。

- Snowflakeエンタープライズエディション（またはそれ以上）を使用しており、「**マルチクラスターウェアハウス」**オプションが有効になっている場合、追加のオプションが表示されます。ここでは、ウェアハウスがコンピューティングリソースのクラスターを複数（最大10クラスター）使用するように設定できます。たとえば、`4X-Large`マルチクラスターウェアハウスに最大クラスターサイズの10が割り当てられた場合、そのウェアハウスは基礎となるコンピューティングリソースの10倍までスケールアウトできます（しかも数秒で！）。ただし、この場合、10クラスターすべてが1時間フル稼働すると、ウェアハウスが消費するクレジット数は1280に増えることに注意してください（128クレジット/時間 x 10クラスター）。マルチクラスターは、多くのビジネスアナリストが同じウェアハウスを使用してさまざまなクエリを同時に実行するような同時実行シナリオに最適です。このユースケースでは、さまざまなクエリが高速に実行されるように複数のクラスターに割り当てられます。

- 「**詳細ウェアハウスオプション**」では、使用していないウェアハウスを自動的に一時停止し、クレジットを無駄に消費しないようにするオプションがあります。一時停止されたウェアハウスを自動的に再開するオプションもあります。このオプションが有効な場合、新しいワークロードがウェアハウスに送信されると、自動的に再開されます。この機能によって、Snowflakeの効率的な「従量課金」モデルが可能となり、リソースが必要になったときにスケールアップし、不要になったときに自動的にスケールダウンするかオフにすることができるため、アイドリング状態のリソースをほぼ完全に排除できます。さらに、ウェアハウスのタイプを標準からSnowpark用に最適化されたものに変更するオプションもあります。Snowpark用に最適化されたウェアハウスは、ノードあたり16倍のメモリを提供し、単一の仮想ウェアハウスノードでストアドプロシージャを使用するMLトレーニングのユースケースなど、大規模なメモリ要件を持つワークロードに推奨されます。ここでは、タイプを標準のままにしておきます

> aside negative
> 
> **Snowflakeコンピュートとその他のデータウェアハウスの比較** 先ほど説明した仮想ウェアハウスとコンピュート機能の多く（仮想ウェアハウスの作成、スケールアップ、スケールアウト、自動サスペンド/再開機能など）は、Snowflakeでは簡単に使用でき、数秒で実行できます。オンプレミスデータウェアハウスでは、これらの機能を使用することは、不可能とは言えないまでもはるかに困難です。大量の物理ハードウェア、ワークロードの急増に対応するためのハードウェアのオーバープロビジョニング、かなりの量の設定作業、その他の課題への対処が必要になるからです。他のクラウドベースデータウェアハウスでさえも、Snowflakeのように設定に多大な労力と時間をかけずにスケールアップやスケールアウトを行うことはできません。

**警告 - 支出に注意してください。**このラボ中またはその終了後に、正当な理由なく以下の操作を実行しないよう注意してください。これらの操作を行うと、400ドルの無料クレジットを必要以上に早く使い切ってしまう可能性があります。

- 自動サスペンドを無効にしないでください。自動サスペンドが無効化されていると、ウェアハウスは使用されていなくても稼働し続け、クレジットを消費し続けます。
- ワークロードを考慮し、過剰なウェアハウスサイズを使用しないでください。ウェアハウスが大きいほど、消費されるクレジットが多くなります。

この仮想ウェアハウスを使用して、CSVファイルの構造化データ（AWS S3バケットに格納）をSnowflakeにロードすることになります。しかし、まずウェアハウスのサイズを変更して、使用するコンピューティングリソースを増やすことにします。ロード後、所要時間を記録してください。このセクションの後のステップで、さらに大きなウェアハウスで同じロード操作を再実行し、ロード時間が短縮していることを確認します。

このデータウェアハウスの**サイズ**を`X-Small`から`Small`へ変更し、その後「**ウェアハウスを保存**」ボタンをクリックします。

![小さく設定](assets/5Load_3.png)

### データのロード

これで、COPYコマンドを実行し、先ほど作成した`TRIPS`テーブルにデータをロードできるようになりました。

「**ワークシート**」タブで`CITIBIKE_ZERO_TO_SNOWFLAKE`ワークシートに戻ります。ワークシートのコンテキストが以下のように正しく設定されていることを確認してください。

ロール：`SYSADMIN` ウェアハウス：`COMPUTE_WH` データベース：`CITIBIKE` スキーマ = `PUBLIC`

![ワークシートのコンテキスト](assets/5Load_4.png)

ワークシートで以下のステートメントを実行し、ステージングされたデータをテーブルにロードします。これには30秒ほどかかる場合があります。

```SQL
copy into trips from @citibike_trips file_format=csv PATTERN = '.*csv.*' ;
```

結果ペインに、ロードされた各ファイルのステータスが表示されます。ロードが完了すると、右下の「**クエリの詳細**」ペインをスクロールして、最後に実行されたステートメントのさまざまなステータス、エラー統計、および視覚化を確認できるようになります。

![結果ロードステータス](assets/5Load_5.png)

次に、**ホーム**アイコンをクリックしてから、「**アクティビティ」**、「**クエリ履歴**」の順にクリックして、「**クエリ履歴**」タブに移動します。リストの一番上にあるクエリを選択します。これは、最後に実行されたCOPY INTOステートメントです。「**クエリプロファイル」**タブを選択し、クエリ実行時のステップ、クエリの詳細、最もコストの高いノード、およびその他の統計情報を記録します。

![履歴と期間](assets/5Load_6.png)

次に、より大きなウェアハウスで`TRIPS`テーブルをリロードし、追加されたコンピューティングリソースがロード時間に与える影響を見てみましょう。

ワークシートに戻り、TRUNCATE TABLEコマンドを使用して、テーブルからすべてのデータとメタデータを消去します。

```SQL
truncate table trips;
```

以下のコマンドを実行して、テーブルが空になったことを確認します。

```SQL
--verify table is clear
select * from trips limit 10;
```

結果には「Query produced no results（クエリで結果が生成されませんでした）」と表示されます。

次のALTER WAREHOUSEを使用してウェアハウスのサイズを`large`に変更します。

```SQL
--change warehouse size from small to large (4x)
alter warehouse compute_wh set warehouse_size='large';
```

次のSHOW WAREHOUSESを使用して変更を確認します。

```SQL
--load data with large warehouse
show warehouses;
```

![UIステップ1でコンテキストのサイズを大に変更](assets/5Load_7.png)

サイズはUIを使用して変更することもできます。その場合は、ワークシートコンテキストボックスをクリックし、コンテキストボックスの右横にある**設定**（3本線）アイコンをクリックし、「**サイズ」**ドロップダウンで`Small`から`Large`に変更します。

![UIステップ1でコンテキストのサイズを大に変更](assets/5Load_8.png) ![UIステップ2でコンテキストのサイズを大に変更](assets/5Load_8b.png)

先ほどと同じCOPY INTOステートメントを実行し、同じデータを再度ロードします。

```SQL
copy into trips from @citibike_trips
file_format=CSV;
```

![ロード時間の比較](assets/5Load_9.png)

ロードが完了したら、「**クエリ」**ページに戻ります（**ホーム**アイコン、「**アクティビティ」**、「**クエリ履歴」**の順にクリック）。2つのCOPY INTOコマンドの時間を比較します。`Large`ウェアハウスを使用してロードするほうが大幅に速いことが分かります。

### データアナリティクス用の新しいウェアハウスの作成

ラボストーリーに戻り、Citi Bikeチームがデータロード/ETLワークロードと、BIツールを使用してSnowflakeをクエリする分析エンドユーザーの間でリソースの競合が発生しないようにしたいと考えているとしましょう。前述したように、Snowflakeでは、適切なサイズのさまざまなウェアハウスを各種ワークロードに割り当てることで、これを簡単に実現できます。Citi Bikeには、すでにデータロード用のウェアハウスがあるため、分析を実行するエンドユーザー用に新しいウェアハウスを作成しましょう。次のセクションでは、このウェアハウスを使用して分析を実行します。

「**管理**」から「**ウェアハウス**」タブへ進み、「**+ウェアハウス**」をクリックして新しいウェアハウスの名前を\`\`とし、サイズを`Large`に設定します。

Snowflakeエンタープライズエディション（またはそれ以上）を使用しており、「**マルチクラスターウェアハウス**」が有効になっている場合、追加の設定が表示されます。

- 「**最大クラスター**」が`1`に設定されていることを確認します。
- その他の設定はすべてデフォルトのままにしておきます。

![ウェアハウス設定](assets/5Load_10.png)

「**ウェアハウスの作成」**ボタンをクリックし、ウェアハウスを作成します。

<!-- ------------------------ -->
## クエリ、結果キャッシュ、クローンの操作

duration:8

前の演習では、SnowflakeのCOPY一括ローダーコマンドと`COMPUTE_WH`仮想ウェアハウスを使用して、2つのテーブルにデータをロードしました。今回は、Citi Bikeのアナリティクスユーザーとして、ワークシートと2つ目のウェアハウス`ANALYTICS_WH`を使用して、これらのテーブルのデータをクエリします。

> aside negative
> 
> **実際のロールとクエリ作業** 実際の企業内では、アナリティクスユーザーはSYSADMINとは異なるロールを担うことが多いでしょう。ラボをシンプルに保つため、このセクションでは引き続きSYSADMINロールを使用していきます。さらに、クエリは通常、Tableau、Looker、PowerBIなどのビジネスインテリジェンスプロダクトで実行されます。より高度な分析が必要な場合は、Datarobot、Dataiku、AWS Sagemakerなどのデータサイエンスツールを使用してSnowflakeをクエリできます。JDBC/ODBC、Spark、Python、その他のサポート対象のプログラムインターフェイスを利用するテクノロジーであれば、Snowflakeのデータに対して分析を実行することができます。このラボをシンプルに保つため、すべてのクエリはSnowflakeワークシートを使用して実行されます。

### クエリの実行

**CITIBIKE_ZERO_TO_SNOWFLAKE**ワークシートに移動し、前のセクションで作成した新しいウェアハウスを使用するよう、ウェアハウスを変更します。ワークシートのコンテキストは次のようになっているはずです。

ロール：`SYSADMIN` ウェアハウス：`ANALYTICS_WH (L)` データベース：`CITIBIKE` スキーマ = `PUBLIC`

![サンプルデータクエリ結果](assets/6Query_1.png)

以下のクエリを実行し、`trips`データのサンプルを表示します。

```SQL
select * from trips limit 20;
```

![サンプルデータクエリ結果](assets/6Query_2.png)

では、Citi Bikeの利用状況に関する基本的な時間別統計をいくつか見ていきましょう。ワークシートで以下のクエリを実行します。それぞれの時間の走行回数、平均走行時間、平均走行距離が表示されます。

```SQL
select date_trunc('hour', starttime) as "date",
count(*) as "num trips",
avg(tripduration)/60 as "avg duration (mins)",
avg(haversine(start_station_latitude, start_station_longitude, end_station_latitude, end_station_longitude)) as "avg distance (km)"
from trips
group by 1 order by 1;
```

![時間ごとのクエリ結果](assets/6Query_3.png)

### 結果キャッシュの使用

Snowflakeには、過去24時間に実行されたすべてのクエリの結果を保持する結果キャッシュがあります。これはウェアハウスをまたいで利用可能であるため、あるユーザーに返されたクエリ結果を、基礎データが変更されていない限り、同じクエリを実行したシステム上の他のどのユーザーでも利用することができます。このようにクエリ結果を繰り返し返すことで、クエリの実行が非常に高速になるだけでなく、コンピュートクレジットの消費も回避できます。

まったく同じクエリを再度実行し、結果キャッシュの動作を見てみましょう。

```SQL
select date_trunc('hour', starttime) as "date",
count(*) as "num trips",
avg(tripduration)/60 as "avg duration (mins)",
avg(haversine(start_station_latitude, start_station_longitude, end_station_latitude, end_station_longitude)) as "avg distance (km)"
from trips
group by 1 order by 1;
```

右側の「**クエリの詳細」**ペインで、2回目のクエリ実行速度が大幅に向上していることに注意してください。これは、結果がキャッシュされているためです。

![キャッシュされたクエリの実行時間](assets/6Query_4.png)

### 別のクエリの実行

次に、以下のクエリを実行し、どの月が最も忙しいかを確認してみましょう。

```SQL
select
monthname(starttime) as "month",
count(*) as "num trips"
from trips
group by 1 order by 2 desc;
```

![月のクエリ結果](assets/6Query_5.png)

### テーブルの複製

Snowflakeを使用すると、テーブル、スキーマ、およびデータベースのクローンを数秒で作成できます。これは、「ゼロコピークローン」とも呼ばれます。クローンが作成されると、Snowflakeは、ソースオブジェクト内に存在するデータのスナップショットを取得し、クローンオブジェクトでそれを利用できるようにします。クローンオブジェクトは書き込み可能であり、クローン元から独立しています。つまり、ソースオブジェクトまたはクローンオブジェクトのどちらかに加えられた変更は、もう一方のオブジェクトには反映されないということです。

ゼロコピークローニングの一般的なユースケースは、本番環境のクローンを作成し、開発およびテストチームがテストや実験に使用できるようにすることです。こうすることで、本番環境に悪影響が及ぶことがなくなると同時に、2つの別個の環境を設定して管理する必要がなくなります。

> aside negative
> 
> **ゼロコピークローニング** ゼロコピークローニングの大きな利点は、基礎データはコピーされないという点にあります。変更されるのは、基礎データへのポインタとメタデータのみです。したがって、クローンは「ゼロコピー」であり、データがクローンされてもストレージ要件が2倍になることはありません。ほとんどのデータウェアハウスではこれを行うことはできませんが、Snowflakeでは簡単にできます。

ワークシートで以下のコマンドを実行し、`trips`テーブルの開発（dev）テーブルクローンを作成します。

```SQL
create table trips_dev clone trips;
```

左のペインで3つの点（**...**）をクリックし、「**更新」**を選択します。`CITIBIKE`データベースの下のオブジェクトツリーを展開し、`trips_dev`という名前の新規テーブルが表示されていることを確認します。これで、開発チームは、`trips`テーブルや他のオブジェクトに影響を与えることなく、更新や削除も含め、このテーブルに対してどのような操作でも実行することができるようになります。

![trips_devテーブル](assets/6Query_6.png)

<!-- ------------------------ -->
## 半構造化データ、ビュー、結合の操作

duration:16

> aside positive
> 
> このセクションでは、追加データをロードする必要があるため、データロードをおさらいしつつ、半構造化データのロードも紹介していきます。

ラボの例に戻りましょう。Citi Bikeの分析チームは天候が自転車の利用回数にどのような影響を与えるかを見極めたいと考えています。そのため、このセクションでは次のことを行います。

- 公開されているS3バケットにある半構造化JSON形式の気象データをロードする。
- ビューを作成し、SQLドット表記を使用してJSONデータをクエリする。
- 前にロードした`TRIPS`データにJSONデータを結合するクエリを実行する。
- 気象データと自転車の利用回数データを分析し、それらの関係を見極める。

JSONデータは、*MeteoStat*によって提供される気象情報で構成されており、2016年7月5日から2019年6月25日までのニューヨーク市の歴史的条件を詳細に示しています。また、AWS S3上でステージングされており、データは75000行、36個のオブジェクトで構成され、1.1MBに圧縮されています。テキストエディタで見ると、GZファイルの未加工JSONは以下のようになります。

![未加工のJSONサンプル](assets/7SemiStruct_1_1.png)

> aside negative
> 
> **半構造化データ** Snowflakeでは、JSON、Parquet、Avroなどの半構造化データを変換なしで簡単にロードしたりクエリしたりすることができます。これはSnowflakeの重要な機能です。現在生成されているビジネス関連データの多くが半構造化データであり、従来のデータウェアハウスの多くは、そのようなデータを簡単にロードしたりクエリしたりできないからです。Snowflakeでは、それを簡単に実行できます。

### データ用に新しいデータベースとテーブルを作成する

まず、ワークシートで、半構造化JSONデータの格納に使用する`WEATHER`という名前のデータベースを作成しましょう。

```SQL
create database weather;
```

以下のUSEコマンドを実行し、ワークシートのコンテキストを適切に設定します。

```SQL
use role sysadmin;

use warehouse compute_wh;

use database weather;

use schema public;
```

> aside positive
> 
> **複数コマンドの実行** それぞれのコマンドを個別に実行する必要があることに注意してください。ただし、すべてのコマンドを選択してから、「**再生/実行**」ボタンをクリックする（あるいはキーボードのショートカットを使用する）ことで、それらをまとめて順番に実行することができます。

次に、JSONデータのロードに使用する`JSON_WEATHER_DATA`という名前のテーブルを作成しましょう。ワークシートで、次のCREATE TABLEコマンドを実行します。

```SQL
create table json_weather_data (v variant);
```

なお、Snowflakeには、JSONオブジェクト全体を単一の行として格納し、最終的にオブジェクトを直接クエリできるようにする、`VARIANT`という名前の特殊な列データ型があります。

> aside negative
> 
> **半構造化データマジック** VARIANTデータ型により、Snowflakeはスキーマを事前に定義することなく半構造化データを取り込むことができます。

ワークシート下部の結果ペインで、テーブル`JSON_WEATHER_DATA`が作成されていることを確認します。

![成功メッセージ](assets/7SemiStruct_2_1.png)

### 別の外部ステージの作成

`CITIBIKE_ZERO_TO_SNOWFLAKE`ワークシートで、以下のコマンドを使用して、半構造化JSONデータがAWS S3に保存されているバケットをポイントするステージを作成します。

```SQL
create stage nyc_weather
url = 's3://snowflake-workshop-lab/zero-weather-nyc';
```

では`nyc_weather`ステージのコンテンツを見ていきましょう。以下のLISTコマンドを実行して、ファイルのリストを表示します。

```SQL
list @nyc_weather;
```

結果ペインにS3からの`.gz`ファイルのリストが表示されます。

![結果出力](assets/7SemiStruct_3_1.png)

### 半構造化データのロードと検証

このセクションでは、ウェアハウスを使用して、S3バケットからのデータを先ほど作成した`JSON_WEATHER_DATA`テーブルにロードします。

`CITIBIKE_ZERO_TO_SNOWFLAKE`ワークシートで、以下のCOPYコマンドを実行し、データをロードします。

なお、`FILE FORMAT`オブジェクトはコマンド内のインラインで指定できます。構造化データをCSV形式でロードした前のセクションでは、CSV構造に対応するファイル形式を定義する必要がありました。ここでのJSONデータは整形式であるため、JSONタイプを指定するだけで、すべてのデフォルト設定を使用することができます。

```SQL
copy into json_weather_data
from @nyc_weather 
    file_format = (type = json strip_outer_array = true);
```

各ファイルのステータスが`LOADED`となっていること確認します。

![クエリ結果](assets/7SemiStruct_4_1.png)

では、ロードされたデータを見ていきましょう。

```SQL
select * from json_weather_data limit 10;
```

いずれかの行をクリックすると、右側のパネルにフォーマットされたJSONが表示されます。

![JSONデータスニペット](assets/7SemiStruct_5_1.png)

パネル内の表示を閉じてクエリの詳細を再度表示するには、パネルの右隅にカーソルを合わせると表示される**X**（閉じる）ボタンをクリックします。

### ビューの作成と半構造化データのクエリ

次に、Snowflakeでビューを作成し、SQLを使用してJSONデータを直接クエリする方法を見ていきましょう。

> aside negative
> 
> **ビューとマテリアライズドビュー** ビューを使用すると、クエリの結果にテーブルのようにアクセスできます。ビューを使用すると、エンドユーザーにデータを分かりやすく提示したり、エンドユーザーがソーステーブルで表示できる内容を制限したり、よりモジュール化されたSQLを書いたりすることができるようになります。Snowflakeは、マテリアライズドビューにも対応しています。このビューではクエリ結果がテーブルであるかのように格納されます。それによってアクセスは迅速化しますが、これにはストレージスペースが必要となります。Snowflakeエンタープライズエディション（またはそれ以上）を使用していれば、マテリアライズドビューを作成し、それをクエリすることができます。

以下のコマンドを実行して、半構造化JSON気象データの列ビューを作成します。こうすることで、アナリストによるデータの理解とクエリの実行が容易になります。`station_id`の`72502`という値は、ニューアーク空港に対応しています。ここは、全期間の気象条件を有する最も近いステーションです。

```SQL
// create a view that will put structure onto the semi-structured data
create or replace view json_weather_data_view as
select
    v:obsTime::timestamp as observation_time,
    v:station::string as station_id,
    v:name::string as city_name,
    v:country::string as country,
    v:latitude::float as city_lat,
    v:longitude::float as city_lon,
    v:weatherCondition::string as weather_conditions,
    v:coco::int as weather_conditions_code,
    v:temp::float as temp,
    v:prcp::float as rain,
    v:tsun::float as tsun,
    v:wdir::float as wind_dir,
    v:wspd::float as wind_speed,
    v:dwpt::float as dew_point,
    v:rhum::float as relative_humidity,
    v:pres::float as pressure
from
    json_weather_data
where
    station_id = '72502';
```

このコマンドでは、SQLドット表記である`v:temp`を使用してJSONオブジェクト階層内の下位レベルの値を取得します。これにより、各フィールドをリレーショナルテーブルの列のように扱うことができます。

新しいビューは、オブジェクトブラウザの左側の`WEATHER` > `PUBLIC` > 「**ビュー**」の下に`JSON_WEATHER_DATA`として表示されます。このビューを表示するには、オブジェクトブラウザの展開または更新が必要になる場合があります。

![ドロップダウンのJSON_WEATHER_DATA \_VIEW](assets/7SemiStruct_6_1.png)

以下のクエリでビューを確認します。

```SQL
select * from json_weather_data_view
where date_trunc('month',observation_time) = '2018-01-01'
limit 20;
```

結果は、通常の構造化データソースと同じように見えることに注意してください。皆さんの結果セットでは`observation_time`の値が異なる場合があります。

![ビューでのクエリ結果](assets/7SemiStruct_7_1.png)

### 結合操作を使用してデータセットに対して相関させる

ここで、天候が自転車の利用回数にどのような影響を与えるかという当初の質問に答えるために、JSON気象データを`CITIBIKE.PUBLIC.TRIPS`データに結合します。

以下のクエリを実行して、`WEATHER`を`TRIPS`に結合し、特定の天候条件に関連する走行回数をカウントします。

> aside positive
> 
> まだワークシートの中にいるため、`WEATHER`データベースも使用中です。したがって、データベース名とスキーマ名を指定することで`TRIPS`テーブルへの参照を完全に修飾する必要があります。

```SQL
select weather_conditions as conditions
,count(*) as num_trips
from citibike.public.trips
left outer join json_weather_data_view
on date_trunc('hour', observation_time) = date_trunc('hour', starttime)
where conditions is not null
group by 1 order by 2 desc;
```

![天候の結果](assets/7SemiStruct_8_1.png)

当初の目標は、自転車の利用者数データと気象データの両方を分析することで、自転車に乗る回数と天候の間に何らかの相関関係があるかどうかを判断することでした。上記の結果から、明確な答えが得られました。想像のとおり、天候が良好であれば走行回数はかなり多くなっています。

<!-- ------------------------ -->
## タイムトラベルの使用

duration:6

Snowflakeの強力なタイムトラベル機能を使用すると、履歴データや、データを格納するオブジェクトに、一定期間内の任意の時点でアクセスすることができます。デフォルトの期間の幅は24時間ですが、Snowflakeエンタープライズエディションを使用している場合は、最大90日間まで増やすことができます。ほとんどのデータウェアハウスではこの機能が提供されていませんが、Snowflakeではこれを簡単に実行できます。

次に、便利な適用例をいくつかご紹介します。

- 削除されたデータ関連オブジェクト（テーブル、スキーマ、データベースなど）を復元する。
- 過去の重要な時点のデータを複製し、バックアップする。
- 特定の期間におけるデータの使用状況および操作を分析する。

### テーブルのドロップとドロップ解除

まず、誤って、または意図的に削除されたデータオブジェクトを復元する方法を見てみましょう。

`CITIBIKE_ZERO_TO_SNOWFLAKE`ワークシートで、以下のDROPコマンドを実行し、`JSON_WEATHER_DATA`テーブルを削除します。

```SQL
drop table json_weather_data;
```

テーブルに対してクエリを実行します。

```SQL
select * from json_weather_data limit 10;
```

基礎テーブルがドロップされているため、下部の結果ペインにはエラーが表示されます。

![テーブルがドロップされたことを示すエラー](assets/8Time_1.png)

次に、テーブルを復元します。

```SQL
undrop table json_weather_data;
```

json_weather_dataテーブルが復元されたはずです。以下のクエリを実行して確認してください。

```SQL
--verify table is undropped

select * from json_weather_data limit 10;
```

![復元されたテーブルの結果](assets/8Time_2.png)

### テーブルのロールバック

`CITIBIKE`データベース内の`TRIPS`テーブルを以前の状態にロールバックし、テーブル内のステーション名をすべて「oops」という単語に置き換えてしまう、意図しないDMLエラーを修正してみましょう。

まず、以下のSQLステートメントを実行し、ワークシートを正しいコンテキストに切り替えます。

```SQL
use role sysadmin;

use warehouse compute_wh;

use database citibike;

use schema public;
```

以下のコマンドを実行し、テーブル内のすべての駅名を「oops」という単語に置き換えます。

```SQL
update trips set start_station_name = 'oops';
```

次に、自転車の利用回数の上位20ステーションを返すクエリを実行します。ステーション名の結果に1行しか含まれていないことに注意してください。

```SQL
select
start_station_name as "station",
count(*) as "rides"
from trips
group by 1
order by 2 desc
limit 20;
```

![1行の結果](assets/8Time_3.png)

通常であれば、バックアップがあることを祈りながらあれこれ奔走するところです。

Snowflakeでは、1つのコマンドを実行するだけで、直近のUPDATEコマンドのクエリIDを見つけ、それを`$QUERY_ID`という名前の変数に格納することができます。

```SQL
set query_id =
(select query_id from table(information_schema.query_history_by_session (result_limit=>5))
where query_text like 'update%' order by start_time desc limit 1);
```

タイムトラベルを使用して、正しいステーション名でテーブルを作り直します。

```SQL
create or replace table trips as
(select * from trips before (statement => $query_id));
```

前のクエリを再度実行し、ステーション名が復元されていることを確認します。

```SQL
select
start_station_name as "station",
count(*) as "rides"
from trips
group by 1
order by 2 desc
limit 20;
```

![復元された名前の結果](assets/8Time_4.png)

<!-- ------------------------ -->
## ロール、アカウント管理者、アカウント使用状況の操作

duration:8

このセクションでは、ロールの作成やロールへの特定の権限の付与など、Snowflakeのアクセス制御セキュリティモデルについて説明します。また、ラボの前半で簡単に紹介したACCOUNTADMIN（アカウント管理者）ロールのその他の用途についても検討します。

ラボストーリーを続けます。ここでは、ある若手のDBAがCiti Bikeに入社し、システム定義のデフォルトロールであるSYSADMINよりも権限の少ない新しいロールを作成するとしましょう。

> aside negative
> 
> **ロールベースのアクセス制御** Snowflakeは、ユーザーがアクセスできるオブジェクトと機能、およびユーザーのアクセスレベルを指定する、非常に強力かつ粒度の高いアクセス制御を提供しています。詳細については、[Snowflakeドキュメント](https://docs.snowflake.net/manuals/user-guide/security-access-control.html)を確認してください。

### 新しいロールの作成とユーザーの追加

`CITIBIKE_ZERO_TO_SNOWFLAKE`ワークシートでACCOUNTADMINロールに切り替え、新しいロールを作成します。ACCOUNTADMINは、SYSADMINとSECURITYADMINのシステム定義ロールをカプセル化したものです。これはアカウントの最上位のロールであり、限られた数のユーザーにのみ付与する必要があります。

`CITIBIKE_ZERO_TO_SNOWFLAKE`ワークシートで以下のコマンドを実行します。

```SQL
use role accountadmin;
```

ワークシートの右上で、コンテキストがACCOUNTADMINに変更されていることに注意してください。

![ACCOUNTADMINコンテキスト](assets/9Role_1.png)

ロールをアクセス制御で使用できるようにするには、少なくとも1人のユーザーがそのロールに割り当てられている必要があります。では、`JUNIOR_DBA`という名前の新しいロールを作成し、Snowflakeユーザーに割り当ててみましょう。このタスクを完了するには、ユーザー名を把握している必要があります。ユーザー名は、自分がUIにログインするときに使用した名前です。

以下のコマンドを使用して、ロールを作成し、それを自分に割り当てます。GRANT ROLEコマンドを実行する前に、`YOUR_USERNAME_GOES_HERE`を自分のユーザー名に置き換えてください。

```SQL
create role junior_dba;

grant role junior_dba to user YOUR_USERNAME_GOES_HERE;
```

> aside positive
> 
> SYSADMINなどのロールでこの操作を実行しようとすると、権限が不十分であるため、操作が失敗します。デフォルト（および設計上）では、SYSADMINロールでは新しいロールやユーザーを作成できないようになっています。

ワークシートのコンテキストを、新しい`JUNIOR_DBA`ロールに変更します。

```SQL
use role junior_dba;
```

ワークシートの右上で、コンテキストが変更され、`JUNIOR_DBA`ロールが反映されていることに注意してください。

![JUNIOR_DBAコンテキスト](assets/9Role_2.png)

また、新しく作成されたロールにはウェアハウスの使用権限がないため、ウェアハウスは選択されていません。ADMINロールに戻し、`COMPUTE_WH`ウェアハウスの使用権限を付与することで、この問題を解決しましょう。

```SQL
use role accountadmin;

grant usage on warehouse compute_wh to role junior_dba;
```

`JUNIOR_DBA`ロールに戻します。これで`COMPUTE_WH`を使用できるようになりました。

```SQL
use role junior_dba;

use warehouse compute_wh;
```

最後に、左のデータベースオブジェクトブラウザパネルにデータベース、`CITIBIKE`と`WEATHER`が表示されなくなったことに気付くでしょう。これは、`JUNIOR_DBA`ロールにはそれらにアクセスする権限がないためです。

ACCOUNTADMINロールに再度切り替えて、データベース`CITIBIKE`および`WEATHER`を表示し使用するために必要な使用権限を`JUNIOR_DBA`に付与します。

```SQL
use role accountadmin;

grant usage on database citibike to role junior_dba;

grant usage on database weather to role junior_dba;
```

`JUNIOR_DBA`ロールに切り替えます。

```SQL
use role junior_dba;
```

これで、左のデータベースオブジェクトブラウザにデータベース`CITIBIKE`および`WEATHER`が表示されるようになりました。表示されない場合は、パネルの**...**をクリックし、その後「**更新**」をクリックしてみてください。

![データベースが表示されたオブジェクトブラウザパネル](assets/9Role_3.png)

### アカウント管理者UIの表示

では、このロールのみがアクセスできるUIのその他の領域を確認するために、アクセス制御ロールを`ACCOUNTADMIN`に戻してみましょう。ただし、このタスクの実行には、ワークシートではなくUIを使用します。

まず、ワークシート左上の**ホーム**アイコンをクリックします。次に、UIの左上にある自分の名前をクリックし、ユーザー設定メニューを表示します。メニューで「**ロールの切り替え**」へ進み、ACCOUNTADMINを選択します。

![UIロールの切り替え](assets/9Role_4.png)

> aside negative
> 
> **ユーザー設定とワークシートのロールの比較** ここでワークシートではなく、ユーザー設定メニューを使ってロールを変更したのはなぜでしょうか？UIセッションとそれぞれのワークシートは、別々のロールを有します。UIセッションのロールは、UIで表示やアクセスが可能なエレメントを制御するものであり、ワークシートのロールは、そのロール内でアクセスできるオブジェクトと操作のみを制御するものです。

UIセッションをACCOUNTADMINロールに切り替えると、「**管理**」の下で新しいタブが利用できるようになることに注意してください。

#### 使用状況

![アカウントの使用状況](assets/9Role_5.png)

「**使用状況**」タブには以下の項目が表示され、それぞれに独自のページが用意されています。

- **組織**：組織内の全アカウントのクレジット使用状況です。
- **消費**：現在のアカウントの仮想ウェアハウスによって消費されたクレジットです。
- **ストレージ**：現在のアカウントのすべてのデータベース、内部ステージ、Snowflake Failsafeに格納されている過去1か月の平均データ量です。
- **転送**：過去1か月に（現在のアカウントの）リージョンから他のリージョンに転送された平均データ量です。

各ページの右上にあるフィルターを使用すると、使用状況/消費量/その他の視覚化をさまざまな尺度で細分化することができます。

#### セキュリティ

![アカウントの使用状況](assets/9Role_6.png)

「**セキュリティ**」タブには、Snowflakeアカウント用に作成されたネットワークポリシーが含まれています。新しいネットワークポリシーは、ページの右上にある「+ネットワークポリシー」を選択して作成できます。

#### 請求

![アカウントの使用状況](assets/9Role_7.png)

「**請求**」タブには、アカウントの支払い方法が含まれています。

- Snowflakeのご契約ユーザーの場合は、このタブに契約情報に関連付けられたお名前が表示されます。
- オンデマンドのSnowflakeユーザーで、月々のお支払いに使用するクレジットカード情報が登録されている場合は、このタブにそのクレジットカード情報が表示されます。クレジットカードが登録されていない場合、トライアル終了時にクレジットカード情報を追加することで、引き続きSnowflakeをご利用いただくことができます。

次のセクションのために、UIセッションはACCOUNTADMINロールのままにしておきます。

<!-- ------------------------ -->
## データの安全な共有とマーケットプレイス

duration:12

Snowflakeは、安全なデータシェアリング機能を通じて、アカウント間でのデータアクセスを実現します。共有は、データプロバイダーによって作成され、データコンシューマーにより、自身のSnowflakeアカウントまたはプロビジョニングされたSnowflakeリーダーアカウントを通じてインポートされます。コンシューマーは、外部エンティティの場合もあれば、独自のSnowflakeアカウントを持つ必要がある社内の部門である場合もあります。

安全なデータシェアリングについて：

- データプロバイダーのアカウントに存在するデータのコピーは1つのみ。
- 共有データは常にライブのリアルタイムであり、コンシューマーが即時に利用可能。
- プロバイダーは、共有に対する取り消し可能なきめ細かいアクセスを設定可能。
- データシェアリングは特に旧式のデータシェアリング方法と比較した場合にシンプルで安全。旧式の方法は一般に、インターネットを介した大容量の`.csv`ファイルの転送など、手動で安全でない。

> aside positive
> 
> **クロスリージョンおよびクロスクラウドなデータシェアリング** リージョンまたはクラウドプラットフォームをまたいでデータを共有するには、レプリケーションを設定する必要があります。これはこのラボの範囲外ですが、詳細は[こちらのSnowflakeの記事](https://www.snowflake.com/trending/what-is-data-replication)でご確認いただけます。

Snowflakeは、安全なデータシェアリングを使用して、アカウント使用状況データおよびサンプルデータセットをすべてのSnowflakeアカウントに提供します。この機能において、Snowflakeはデータプロバイダーとして機能し、他のすべてのアカウントはコンシューマーとして機能します。

安全なデータシェアリングはSnowflakeマーケットプレイスの原動力でもあります。Snowflakeマーケットプレイスは、すべてのSnowflakeユーザーが利用できるものであり、多数のデータプロバイダーやSaaSベンダーからサードパーティのデータセットを見つけ、それらにアクセスすることができます。このデータシェアリングモデルでも、データはプロバイダーのアカウントから移動することはなく、データセットを変換なしで利用することができます。

### 既存の共有を表示

ホームページで、「**データ」**、「**データベース」**の順に進みます。データベースのリストで、**SOURCE**列を調べます。この列に`Local`と表示されている2つのデータベースがあります。これらは、ラボで先に作成していた2つのデータベースです。もう1つのデータベース、`SNOWFLAKE`には列に`Share`の表示がありますが、これは、プロバイダーから共有されていることを示しています。

![データベースアイコンの上の矢印](assets/10Share_1.png)

### アウトバウンド共有の作成

Citi Bikeのストーリーに戻りましょう。ここでは、私たちがCiti BikeのSnowflakeアカウント管理者であると想定します。私たちには、ほぼリアルタイムで`TRIPS`データベースのデータを分析することを希望している信頼できるパートナーがいます。このパートナーは、私たちのアカウントと同じリージョンに自社のSnowflakeアカウントを持っています。では、安全なデータシェアリングを使って、このパートナーがこの情報にアクセスできるようにしていきましょう。

「**データ**」、「**プライベートシェアリング**」の順に進み、タブの上部の「**マイアカウントで共有**」をクリックします。右上の「**共有**」ボタンをクリックし、「**直接共有の作成**」を選択します。

![アウトバウンド共有ボタン](assets/10Share_2.png)

「**+データの選択**」をクリックし、`CITIBIKE`データベースと`PUBLIC`スキーマに移動します。スキーマで作成済みの2つのテーブルを選択し、「**完了**」ボタンをクリックします。

![フィールドの共有](assets/10Share_3.png)

共有のデフォルト名は、ランダムな数値を付加した一般的な名前となっています。デフォルト名を編集し、将来的に共有を識別するのに役立つわかりやすい名前に変更します（`ZERO_TO_SNOWFLAKE_SHARED_DATA`など）。コメントを追加することもできます。

実際のシナリオでは、次に、Citi Bikeのアカウント管理者が1つ以上のコンシューマーアカウントを共有に追加することになると思いますが、今回のラボではそこまでは実行しません。

ダイアログの下部にある「**共有の作成**」ボタンをクリックします。

![成功メッセージ](assets/10Share_4.png)

ダイアログが閉じ、作成した安全な共有がページに表示されます。

![TRIPS_SHARE共有](assets/10Share_5.png)

コンシューマーの追加、説明の追加/変更、共有内のオブジェクトの編集はいつでも実行できます。このページで共有名の隣にある**<**ボタンをクリックすると、「**他のアカウントと共有**」ページに戻ります。

![TRIPS_SHARE共有](assets/10Share_6.png)

ここでは、自分のSnowflakeアカウントのデータへのアクセスを、データのコピーや転送を必要としない安全な方法で他のアカウントにほんの数秒で付与できることを示しました。

Snowflakeは、機密性を損なうことなくデータを安全に共有する方法をいくつか提供しています。テーブルに加えて、安全なビュー、安全なUDF（ユーザー定義関数）、その他の安全なオブジェクトを共有できます。これらの方法を使用して機密情報へのアクセスを防ぎながらデータを共有することについての詳細は、[Snowflakeドキュメント](https://docs.snowflake.com/ja/user-guide/data-sharing-secure-views.html)を参照してください。

### Snowflakeマーケットプレイス

自分がACCOUNTADMINロールを使用していることを確認したうえで、**マーケットプレイス**に移動します。

![マーケットプレイスタブ](assets/10Share_7.png)

#### リスティングの検索

上部の検索ボックスでリスティングを検索できます。検索ボックスの右にあるドロップダウンリストを使用すると、プロバイダー、ビジネスニーズ、カテゴリーでデータリスティングをフィルタリングできます。

検索ボックスに「`COVID`」と入力し、結果をスクロールして**COVID-19疫学データ**（提供：Starschema）を選択します。

![健康タブ](assets/10Share_8.png)

**COVID-19疫学データ**のページでは、データセットの詳細や、クエリの使用例を見ることができます。準備ができたら、「**取得**」ボタンをクリックします。そうすることで、この情報を自分のSnowflakeアカウント内で利用できるようになります。

![データフィールドの取得](assets/10Share_starschema_get_data.png)

ダイアログで情報を確認し、再度「**取得**」をクリックします。

![データフィールドの取得](assets/10Share_starschema_get_data2.png)

ここで「**完了**」をクリックしても構いません。あるいは、Starschemaが提供するサンプルクエリを実行することもできます。

![データフィールドの取得](assets/10Share_starschema_query_data.png)

「**開く**」を選択すると、新しいブラウザタブ/ウィンドウで新規ワークシートが開きます。

1. コンテキストの設定
2. 実行したいクエリを選択します（または、クエリテキストにカーソルを合わせます）。
3. 「**実行/再生**」ボタンをクリックします（または、キーボードのショートカットを使用します）。
4. 最下部のペインでデータ結果を確認できます。
5. サンプルクエリの実行が完了したら、左上の**ホーム**アイコンをクリックします。

![データフィールドの取得](assets/10Share_starschema_query_data2.png)

次：

1. 「**データ」**、「**データベース」**の順にクリックします。
2. `COVID19_BY_STARSCHEMA_DM`データベースをクリックします。
3. クエリできるスキーマ、テーブル、ビューの詳細を確認できます。

![covid19データベース](assets/10Share_starschema_db_info.png)

これで完了です。これで、Starschema提供のCOVID-19データセットのサブスクライブが問題なく完了しました。このデータセットは、世界的なCOVIDのデータにより毎日更新されます。データベース、テーブル、ビュー、ETLプロセスを作成する必要がなかったことに注意してください。Snowflakeマーケットプレイスの共有データを検索し、アクセスするだけでした。

新しいワークシートインターフェイスの使い方について詳しくは、[Snowsightドキュメント](https://docs.snowflake.com/ja/user-guide/ui-snowsight.html#using-snowsight)を参照してください

<!-- ------------------------ -->
## Snowflake環境のリセット

duration:2

このラボの一環として作成したオブジェクトをすべて削除して環境をリセットしたい場合は、ワークシートでSQLステートメントを実行します。

まず、ワークシートで自分がACCOUNTADMINロールを使用していることを確認してください。

```SQL
use role accountadmin;
```

次に、以下のSQLコマンドを実行して、ラボで作成したすべてのオブジェクトをドロップします。

```SQL
drop share if exists zero_to_snowflake_shared_data;
-- If necessary, replace "zero_to_snowflake-shared_data" with the name you used for the share

drop database if exists citibike;

drop database if exists weather;

drop warehouse if exists analytics_wh;

drop role if exists junior_dba;
```

<!-- ------------------------ -->
## まとめと次のステップ

duration:2

おめでとうございます。導入ラボ実習が終了しました。これで、Snowflakeの基礎はマスターできましたので、学んだ基礎を自分のデータに適用することができます。おさらいが必要な場合は、このガイドを参照するようにしてください。

無料トライアルを続行し、自分のサンプルデータまたは本番データをロードして、このラボで扱っていないSnowflakeのより高度な機能を試してみることをお勧めします。

### 関連リソース：

- [Snowsight](https://docs.snowflake.com/ja/user-guide/ui-snowsight.html#using-snowsight)ドキュメントの詳細を確認する。
- [無料トライアルを最大限に活用するための決定版ガイド](https://www.snowflake.com/test-driving-snowflake-the-definitive-guide-to-maximizing-your-free-trial/)を読む。
- [Snowflakeのバーチャルイベントまたは対面イベント](https://www.snowflake.com/about/events/)に参加し、当社の機能や顧客についてさらに詳しい情報を得る。
- [Snowflake Community](https://community.snowflake.com/s/topic/0TO0Z000000wmFQWAY/getting-started-with-snowflake)に参加する。
- [Snowflake University](https://community.snowflake.com/s/article/Getting-Access-to-Snowflake-University)に登録する。
- 詳細を当社[セールスチーム](https://www.snowflake.com/free-trial-contact-sales/)に問い合わせる。

### ここまで学んだ内容：

- ステージ、データベース、テーブル、ビュー、仮想ウェアハウスの作成方法。
- 構造化データおよび半構造化データのロード方法。
- テーブル間の結合を含む、Snowflake内のデータに対する分析クエリの実行方法。
- オブジェクトのクローン方法。
- タイムトラベルを使用してユーザーエラーを元に戻す方法。
- ロールおよびユーザーを作成し、権限を付与する方法。
- 他のアカウントと安全かつ簡単にデータを共有する方法。
- Snowflakeマーケットプレイスでデータセットを利用する方法。