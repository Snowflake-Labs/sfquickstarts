{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000000",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell1"
      },
      "source": "# Getting Started with Snowflake Notebooks \n\nWelcome to the 2026 EY Data & AI Challenge! \n\nThis notebook will get you up and running with Snowflake Notebooks. By the end, you'll see how Snowflake can help you leverage a powerful cloud-computing environment to gather satellite imagery data from an external source and conduct geospatial analyses using that data. Once you successfully run this notebook, you will understand the steps required to use Python notebooks for the data challenge. Dive in and have fun !!!"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000001",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell2"
      },
      "source": "## Confirm setup of External Access Integration (EAI)\n\nBefore running this notebook, you will need to run a SQL script to create an [External Access Integration](https://docs.snowflake.com/en/developer-guide/external-network-access/external-network-access-overview). \n\nThis script creates external network access to install PyPI packages and access Planetary Computer API endpoints. \n\nThe setup script can be accessed directly within Snowflake using this [deeplink](https://app.snowflake.com/templates?template=setup_account_data_challenge_template).\n\nThe SQL script is also located in the Snowflake-Labs repo on [Github](https://github.com/Snowflake-Labs/sfquickstarts/tree/master/site/sfguides/src/ey-ai-and-data-challenge).\n\nAn EAI relies upon network rules that are stored in a database. You can attach many rules to the same policy. This same process can be used to setup other access points for external datasets from Google or Amazon.\n\nSnowflake notebooks can run SQL and Python cells. When you run the next cell, you should see a dialog box where you can choose which External Access Integration you wish to use. Select \"DATA_CHALLENGE_EXTERNAL_ACCESS\". Click \"Create and Connect.\" It will take 2-3 minutes for the kernel to connect to the container service.\n\nWhen you see that the kernel status is \"Connected\", then the SQL cell will run, and \"DATA_CHALLENGE_EXTERNAL_ACCESS\" will be listed in the output. "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6f09ae-e8bb-4a1d-91df-bf71aa819e8a",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_1"
      },
      "outputs": [],
      "source": "show integrations;"
    },
    {
      "cell_type": "markdown",
      "id": "ac715424-ca4b-4d62-aba9-79700a84be00",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": "## Import Python packages\nSnowflake Notebooks have 2 runtime options: On Warehouse or On Container. \nWhen you run Snowflake Notebooks inside Snowflake Workspaces, notebooks run on Container, so you can easily use \"pip install\" to load python libraries. \n\nThe Container runtime contains Streamlit and many other third-party packages (by default)[https://docs.snowflake.com/en/developer-guide/snowflake-ml/container-runtime-ml#snowflake-runtime-packages]. \n\nYou can add any additional packages from [PyPI- Python Package Index](www.pypi.org) by loading all dependencies in a **requirements.txt** file. You can create the file by running the Python cell below, or manually upload your **requirements.txt** file into the same folder as this notebook using the plus button in the left sidebar. "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9d2ec4-66df-46ae-8035-594a074ebc67",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Step 1: Create the requirements.txt file locally\nrequirements = \"\"\"\nrioxarray==0.17.0\npystac==1.11.0\npystac_client==0.9.0\nplanetary_computer==1.0.0\nodc-stac==0.3.10\nshapely==2.1.1\nrasterio==1.4.3\ntqdm==4.66.5\npandas==2.3.0\nxarray==2025.3.1\nmatplotlib==3.10.3\ngeopandas==1.1.1\nseaborn==0.13.2\nscikit-learn==1.5.2\nnetCDF4==1.7.2\nadlfs==2025.8.0\nzarr==2.17.2\ndask==2024.10.0\nxarray[complete]\nnumcodecs==0.12.1\n\"\"\"\n\nwith open('/tmp/requirements.txt', 'w') as f:\n    f.write(requirements)\n\nprint(\"File created locally\")\n\n# Step 2: Upload to notebook stage using SQL\n\nsession.sql(f\"\"\"\n    PUT file:///tmp/requirements.txt \n    snow://workspace/USER$.PUBLIC.DEFAULT$/versions/live/\n    AUTO_COMPRESS=FALSE \n    OVERWRITE=TRUE\n\"\"\").collect()\n\nprint(\"Uploaded to notebook environment! Refresh your browser tab to see in sidebar.\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": "## File Management\nThe method above stores files in the notebook environment. These files persist across sessions.\n\nIt is also possible to save files from a Notebook to a Snowflake Internal Stage. [Read the docs](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-work-with-files#store-files-in-a-snowflake-stage) for more info on these different options.\n\nTo save a file from your python environment into a Snowflake stage, use this syntax:",
      "id": "e67d2e54-d371-48e4-867a-0edc34f8fa26"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "session.sql(f\"\"\"\n    CREATE STAGE IF NOT EXISTS SNOWFLAKE_LEARNING_DB.PUBLIC.MY_STAGE\n    DIRECTORY = ( ENABLE = TRUE)\n\"\"\").collect()\n\nsession.file.put('requirements.txt', \"@SNOWFLAKE_LEARNING_DB.PUBLIC.MY_STAGE\",\n    auto_compress = False,\n    overwrite = True)\nprint(\"Uploaded to Stage!\")",
      "id": "406f3dbd-70be-4f2c-a461-974aae6bc7b7"
    },
    {
      "id": "6780bf40-6120-4404-96b4-a699b28442ff",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_2",
        "language": "sql"
      },
      "source": "list @SNOWFLAKE_LEARNING_DB.PUBLIC.MY_STAGE;",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "946af850-554a-4ce5-b78c-7bd245def693",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": "## Python Package Management\n\nSnowflake Notebooks operate similar to Jupyter notebooks that run in your local environment, with one significant difference in the way storage is handled. \n\nWhen you run \"pip install\" in your local environment, there is a physical folder structure where the packages are stored. In Snowflake, there are 2 storage layers: the persistent storage layer (that you can see in the sidebar to the left) and the container storage layer that resets each time your Notebook Container Service restarts. \n\nBy default, the Notebook Service has an idle timeout of 24 hours, but the Compute Pool (which uses Snowflake Credits) has an idle timeout of 5 minutes. This means that after 5 minutes, you stop using up your Snowflake Credits, but the variables and packages in the kernel will remain active for 24 hours. For more information, read the [Snowflake Docs](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-in-workspaces/notebooks-in-workspaces-compute-setup)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8434480c-c87f-4e8b-bb29-1100c4cc3b8e",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import time\n\nstart_time = time.time()\nprint(\"Installing packages to shared directory...\")\nprint(\"This may take a few minutes...\\n\")\n\n# Install all packages from requirements.txt to the shared directory\n!pip install uv\n!uv pip install  -r requirements.txt \n\nelapsed_time = time.time() - start_time\nprint(f\"\\n✓ Package installation complete!\")\nprint(f\"  Time elapsed: {elapsed_time:.1f} seconds ({elapsed_time/60:.1f} minutes)\")"
    },
    {
      "cell_type": "markdown",
      "id": "41c9e6bf-dbc3-4c2d-809e-ffa54890aa52",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell6"
      },
      "source": "## Restart Kernel\n\nAfter installing packages, it is necessary to restart the kernel, to access the new python packages.\nClick the \"⌄\" symbol next to the  \"Connect/Connected\" button at the top of the editing pane in [Snowflake Workspaces](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-in-workspaces/notebooks-in-workspaces-overview)."
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000008",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell11"
      },
      "source": "## Load Python Dependencies\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce110000-1111-2222-3333-ffffff000009",
      "metadata": {
        "language": "python",
        "name": "cell12"
      },
      "outputs": [],
      "source": "# Import common GIS tools\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\n# Import Planetary Computer tools\nimport pystac_client\nimport planetary_computer as pc\nfrom odc.stac import stac_load\n\nimport dask\nimport dask.array as da"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000010",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell13"
      },
      "source": "# Load the satellite data\nFirst, we define our area of interest using latitude and longitude coordinates of the centroid. Then we define the size of the surrounding bounding box (in degrees). Finally, we define the time window."
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ce110000-1111-2222-3333-ffffff000011",
      "metadata": {
        "language": "python",
        "name": "cell14"
      },
      "outputs": [],
      "source": "# Sample region in South Africa\n# Contains Water Quality Sample Site #184 and #186 on the Wilge River\nlat_long = (-27.2923, 28.5365) # Lat-Lon centroid location\nbox_size_deg = 0.15 # Surrounding box in degrees"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ce110000-1111-2222-3333-ffffff000012",
      "metadata": {
        "language": "python",
        "name": "cell15"
      },
      "outputs": [],
      "source": "# Calculate the Lat-Lon bounding box region\nmin_lon = lat_long[1]-box_size_deg/2\nmin_lat = lat_long[0]-box_size_deg/2\nmax_lon = lat_long[1]+box_size_deg/2\nmax_lat = lat_long[0]+box_size_deg/2\nbounds = (min_lon, min_lat, max_lon, max_lat)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ce110000-1111-2222-3333-ffffff000013",
      "metadata": {
        "language": "python",
        "name": "cell16"
      },
      "outputs": [],
      "source": "# Define the time window\ntime_window=\"2015-01-01/2015-05-01\""
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000014",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell17"
      },
      "source": "Using the `pystac_client` we can search the Microsoft Planetary Computer's STAC catalog for items matching our query parameters. The result is the number of scenes matching our search criteria that touch our area of interest. Some of these may be partial scenes and may contain clouds. We have included both Landsat-7 and Landsat-8 data and filtered for low-cloud (<10%) scenes."
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ce110000-1111-2222-3333-ffffff000015",
      "metadata": {
        "language": "python",
        "name": "cell18"
      },
      "outputs": [],
      "source": "stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\nsearch = stac.search(\n    collections=[\"landsat-c2-l2\"], \n    bbox=bounds, \n    datetime=time_window,\n    query={\"platform\": {\"in\": [\"landsat-7\", \"landsat-8\"]}, \"eo:cloud_cover\": {\"lt\": 10}},\n)\nitems = list(search.get_all_items())\nprint('This is the number of scenes that touch our region:',len(items))"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000016",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell19"
      },
      "source": "Next, we'll load the data into an [xarray](https://xarray.pydata.org/en/stable/) DataArray using the Open Data Cube (ODC) STAC [odc-stac](https://odc-stac.readthedocs.io/en/latest/index.html) library. The ODC [odc](https://www.opendatacube.org) is an open source geospatial data management and analysis software project that is used globally for many projects (e.g., Digital Earth Africa). The ODC-STAC code will load the selected items from the catalog search, select the desired spectral bands, including the \"qa_pixel\" cloud filtering band, reproject into Lat-Lon coordinates (EPSG:4326) at 30-meters resolution (typical of Landsat pixel resolution), and clip the region to the spatial bounding box. "
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ce110000-1111-2222-3333-ffffff000017",
      "metadata": {
        "language": "python",
        "name": "cell20"
      },
      "outputs": [],
      "source": "# Define the pixel resolution for the final product\n# Define the scale according to our selected crs, so we will use degrees\nresolution = 30  # meters per pixel \nscale = resolution / 111320.0 # degrees per pixel for CRS:4326 "
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ce110000-1111-2222-3333-ffffff000018",
      "metadata": {
        "language": "python",
        "name": "cell21"
      },
      "outputs": [],
      "source": "xx = stac_load(\n    items,\n    bands=[\"red\", \"green\", \"blue\", \"nir08\", \"swir16\", \"swir22\", \"qa_pixel\"],\n    crs=\"EPSG:4326\", # Latitude-Longitude\n    resolution=scale, # Degrees\n    chunks={\"x\": 2048, \"y\": 2048},\n    patch_url=pc.sign,\n    bbox=bounds\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ce110000-1111-2222-3333-ffffff000019",
      "metadata": {
        "language": "python",
        "name": "cell22"
      },
      "outputs": [],
      "source": "# Apply scaling and offsets for Landsat Collection-2 (reference below) to the spectral bands ONLY\n# https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2\nxx['red'] = (xx['red']*0.0000275)-0.2\nxx['green'] = (xx['green']*0.0000275)-0.2\nxx['blue'] = (xx['blue']*0.0000275)-0.2\nxx['nir08'] = (xx['nir08']*0.0000275)-0.2\nxx['swir16'] = (xx['swir16']*0.0000275)-0.2\nxx['swir22'] = (xx['swir22']*0.0000275)-0.2"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ce110000-1111-2222-3333-ffffff000020",
      "metadata": {
        "language": "python",
        "name": "cell23"
      },
      "outputs": [],
      "source": "# View the dimensions of our XARRAY and the variables\ndisplay(xx)"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000021",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell24"
      },
      "source": "## View RGB (real color) images from the time series\n\nData is available from Landsat-7 from April 1999. Data is available for Landsat-8 from April-2013 to now. A review of the available data shows that the Landdsat-7 scenes have a \"banding\" issue with the sensor that adds lines of \"no data\" to each scene. These can be removed by pixel screening but unfortunately some data is lost. So, for the selected time window and missions there are typically views of our region every 8 days. We will pick a scene with some clouds to demonstrate filtering to find the clear pixels."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2faa9c1b-e057-4828-86f8-ae79aacef986",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Test that packages work together\nimport xarray as xr\nimport dask\nimport dask.array as da\nimport zarr\nimport numpy as np\n\nprint(\"Package Versions:\")\nprint(f\"  xarray: {xr.__version__}\")\nprint(f\"  dask: {dask.__version__}\")\nprint(f\"  zarr: {zarr.__version__}\")\n\n# Test dask chunk manager\nprint(\"\\nTesting dask chunk manager...\")\ntry:\n    test_array = da.ones((10, 10), chunks=(5, 5))\n    test_xr = xr.DataArray(test_array)\n    print(f\"✓ Dask chunks working: {test_xr.chunks}\")\nexcept Exception as e:\n    print(f\"✗ Error: {e}\")\n\nprint(\"\\n✓ Ready to use!\")"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ce110000-1111-2222-3333-ffffff000022",
      "metadata": {
        "language": "python",
        "name": "cell25"
      },
      "outputs": [],
      "source": "plot_xx = xx[[\"red\",\"green\",\"blue\"]].to_array()\nplot_xx.plot.imshow(col='time', col_wrap=4, robust=True, vmin=0, vmax=0.3)\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ce110000-1111-2222-3333-ffffff000023",
      "metadata": {
        "language": "python",
        "name": "cell26"
      },
      "outputs": [],
      "source": "# Select a time slice to view a simple RGB image and the cloud mask\n# See the XARRAY dimensions above for the number of time slices (starts at 0)\n\ntime_slice = 1"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ce110000-1111-2222-3333-ffffff000024",
      "metadata": {
        "language": "python",
        "name": "cell27"
      },
      "outputs": [],
      "source": "# Plot and RGB Real Color Image for a single date\nfig, ax = plt.subplots(figsize=(8, 8))\nxx.isel(time=time_slice)[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True, ax=ax, vmin=0, vmax=0.3)\nax.set_title(\"RGB Real Color\")\nax.axis('off')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000025",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell28"
      },
      "source": "## Apply Cloud Filtering and Masking\n\nCloud masking for Landsat Collection-2 Level-2 data can be complicated. The **\"qa_pixel\"**  band is used to assess each pixel and determine its cloud or water classification. The code below is credited to Mauricio Cordiero. See his webpage [HERE](https://d9-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/media/files/LSDS-1619_Landsat-8-9-C2-L2-ScienceProductGuide-v4.pdf) for a more detailed explanation of the process. Also, you can visit the Landsat-8 Collection-2 Level-2 Product Guide [HERE](https://www.usgs.gov/media/files/landsat-8-9-collection-2-level-2-science-product-guide) for more details about the cloud mask values. In the end, we are searching for clouds, cloud shadows, and water to create a mask for any given region. This will allow us to extract the \"clear\" pixels to assess the vegetation state. "
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "ce110000-1111-2222-3333-ffffff000026",
      "metadata": {
        "language": "python",
        "name": "cell29"
      },
      "outputs": [],
      "source": "# To mask the pixels and find clouds or water, it is best to use the bit values of the 16-bit qa_pixel flag\n# See the website above for a nice explanation of the process\n\nbit_flags = {\n            'fill': 1<<0,\n            'dilated_cloud': 1<<1,\n            'cirrus': 1<<2, \n            'cloud': 1<<3,\n            'shadow': 1<<4, \n            'snow': 1<<5, \n            'clear': 1<<6,\n            'water': 1<<7\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ce110000-1111-2222-3333-ffffff000027",
      "metadata": {
        "language": "python",
        "name": "cell30"
      },
      "outputs": [],
      "source": "# Create a function that will mask pixels with a given type\n\ndef get_mask(mask, flags_list):\n    \n    # Create the result mask filled with zeros and the same shape as the mask\n    final_mask = np.zeros_like(mask)\n    \n    # Loop through the flags  \n    for flag in flags_list:\n        \n        # get the mask for each flag\n        flag_mask = np.bitwise_and(mask, bit_flags[flag])\n        \n        # add it to the final flag\n        final_mask = final_mask | flag_mask\n    \n    return final_mask > 0"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ce110000-1111-2222-3333-ffffff000028",
      "metadata": {
        "language": "python",
        "name": "cell31"
      },
      "outputs": [],
      "source": "# Pick a single time slice to view a mask with clouds and water\nsample_xx = xx.isel(time=time_slice)"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ce110000-1111-2222-3333-ffffff000029",
      "metadata": {
        "language": "python",
        "name": "cell32"
      },
      "outputs": [],
      "source": "# Find the pixels that are no data (fill), clouds, cloud shadows, or water\nmy_mask = get_mask(sample_xx['qa_pixel'], ['fill', 'dilated_cloud', 'cirrus', 'cloud', 'shadow', 'water'])"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ce110000-1111-2222-3333-ffffff000030",
      "metadata": {
        "language": "python",
        "name": "cell33"
      },
      "outputs": [],
      "source": "# Show only the mask (Yellow) with valid data in Purple\nplt.figure(figsize=(7,7))\nplt.imshow(my_mask)\nplt.title(\"Cloud / Shadows / Water Mask > YELLOW\")\nplt.axis('off')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000031",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell34"
      },
      "source": "### Prepare a data mask before plotting sample products"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "ce110000-1111-2222-3333-ffffff000032",
      "metadata": {
        "language": "python",
        "name": "cell35"
      },
      "outputs": [],
      "source": "# Calculate the mask for the entire xarray (all time slices)\nfull_mask = get_mask(xx['qa_pixel'], ['fill', 'dilated_cloud', 'cirrus', 'cloud', 'shadow', 'water'])"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "ce110000-1111-2222-3333-ffffff000033",
      "metadata": {
        "language": "python",
        "name": "cell36"
      },
      "outputs": [],
      "source": "# Create a \"clean\" dataset with the mask applied \ncleaned_data = xx.where(~full_mask)"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000034",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell37"
      },
      "source": "### Normalized Difference Vegetation Index (NDVI)\n\nThe **Normalized Difference Vegetation Index (NDVI)** is used to measure the \"greenness\" of vegetation and has a range of 0.0 to 1.0. Low values (0.0 to 0.25) reflect a lack of vegetation (bare soil, water), middle values (0.25 to 0.6) reflect crops in their growing state, and high values (0.6 to 1.0) reflect crops at their peak vegetation state. The equation uses two spectral bands where: **NDVI = (NIR-Red) / (NIR+Red)**."
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ce110000-1111-2222-3333-ffffff000035",
      "metadata": {
        "language": "python",
        "name": "cell38"
      },
      "outputs": [],
      "source": "# Plot an NDVI image for a single date with few clouds\nfig = plt.figure(figsize=(10, 7))\nndvi_image = (cleaned_data.nir08-cleaned_data.red)/(cleaned_data.nir08+cleaned_data.red)\nndvi_image.isel(time=time_slice).plot(vmin=0.0, vmax=0.8, cmap=\"RdYlGn\")\nplt.title(\"NDVI\")\nplt.axis('off')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000036",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell39"
      },
      "source": "### Normalized Difference Moisture Index (NDMI)\n\nThe **Normalized Difference Moisture Index (NDVI)** is used to measure the presence of soil moisture stress level of vegetation and has a range of -1.0 to 1.0. Higher values (0.4 to 1.0) indicate high vegetation water content, often seen in healthy, well-irrigated areas. Lower values (0 to 0.2) suggest low water content or potential water stress. Very low values (-1.0 to 0.0) typically correspond to bare soil or areas with little to no vegetation moisture. The equation uses two spectral bands where: **NDMI = (NIR-SWIR16) / (NIR+SWIR16)**."
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ce110000-1111-2222-3333-ffffff000037",
      "metadata": {
        "language": "python",
        "name": "cell40"
      },
      "outputs": [],
      "source": "# Plot an NDMI image for a single date with few clouds\nfig = plt.figure(figsize=(10, 7))\nndvi_image = (cleaned_data.nir08-cleaned_data.swir16)/(cleaned_data.nir08+cleaned_data.swir16)\nndvi_image.isel(time=time_slice).plot(vmin=-0.2, vmax=0.7, cmap=\"jet_r\")\nplt.title(\"NDMI\")\nplt.axis('off')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000038",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell41"
      },
      "source": "### SWIR-22 (Shortwave Infrared #2)\nThe Shortwave Infrared #2 band (SWIR22) has a wavelength range of 2.11 to 2.29 microns. This band is typically used for characterizing vegetation and land cover, with applications in estimating fractional crop residue cover, monitoring crop health, and distinguishing soil from vegetation. It is a critical tool for long-term land use analysis and change detection in agriculture, forestry, and coastal environments. "
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ce110000-1111-2222-3333-ffffff000039",
      "metadata": {
        "language": "python",
        "name": "cell42"
      },
      "outputs": [],
      "source": "# Plot an SWIR-22 image for a single date with few clouds\nfig = plt.figure(figsize=(10, 7))\nswir22_image = cleaned_data.swir22\nswir22_image.isel(time=time_slice).plot(vmin=0.0, vmax=0.3, cmap=\"Greys\")\nplt.title(\"SWIR22\")\nplt.axis('off')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000040",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell43"
      },
      "source": "## Conclusion\n\nCongratulations! You have successfully connected your Snowflake account to an external API, processed a variety of geospatial data, and generated complex visuals.\n\n### We wish you and your team the best of luck in the Data Challenge!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "lastEditStatus": {
      "authorEmail": "mike.johnson@snowflake.com",
      "authorId": "6455015813041",
      "authorName": "DATACHALLENGE",
      "lastEditTime": 1765934395953,
      "notebookId": "lf3rvcrx4udibhri3eqw",
      "sessionId": "e706e6f5-b100-4a64-8d5f-6114face03cc"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {
          "2ca0804b9f904dab815db80637a4f2d9": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "model_name": "LayoutModel",
            "state": {}
          },
          "e2f3ac516e3b4cf3a1ba1fc6aa0897ad": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "VBoxModel",
            "state": {
              "layout": "IPY_MODEL_2ca0804b9f904dab815db80637a4f2d9"
            }
          }
        },
        "version_major": 2,
        "version_minor": 0
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}