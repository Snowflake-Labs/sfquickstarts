{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "lastEditStatus": {
      "notebookId": "z6muvaj6imrjx37p7zov",
      "authorId": "5413728730834",
      "authorName": "DSHEMSI",
      "authorEmail": "dureti.shemsi@snowflake.com",
      "sessionId": "f6185efa-597c-40e9-a694-aba9348ac2db",
      "lastEditTime": 1765512294596
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Topic modeling at the speed of light\n\nTopic modeling is a type of statistical modeling used to discover abstract topics within a collection of documents. It is widely used in natural language processing (NLP) to uncover hidden thematic structures in large text. Traditional topic modeling techniques, such as Latent Dirichlet Allocation (LDA), can be computationally intensive, especially with large datasets. Leveraging GPUs can significantly accelerate the process, making it feasible to handle larger datasets and more complex models.\n\n## Why would you use GPUs?\n\nGPUs (Graphics Processing Units) are designed to handle parallel processing tasks efficiently. They are particularly well-suited for the matrix and vector operations that are common in machine learning and deep learning algorithms. By utilizing GPUs, we can achieve substantial speedups in training and inference times for topic modeling.\n\nLet's get started!",
      "metadata": {
        "id": "Ixefs2cdQDmK",
        "name": "cell1",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000000"
    },
    {
      "cell_type": "markdown",
      "source": "## Setup\n\nFirst, let's make sure we are running on an runtime with a GPU.",
      "metadata": {
        "id": "p9c5Jh3_QXZY",
        "name": "cell2",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000001"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ6PU5y9RVo-",
        "outputId": "0d70d402-8103-42f7-a4c1-bf14facbdf9c",
        "language": "python"
      },
      "outputs": [],
      "source": "!nvidia-smi",
      "id": "ce110000-1111-2222-3333-ffffff000002"
    },
    {
      "cell_type": "markdown",
      "source": "If the above cell returns an error please make sure that you use a container or runtime with a GPU attached and restart.\n\nTo perform the topic modeling we will us [BERTopic](https://maartengr.github.io/BERTopic/index.html), a widely used NLP (Natural Language Processing) framework built on top of BERT embeddings and designed to provide coherent and naturally sounding topic descriptions. So, let's make sure the package is available in our environment.",
      "metadata": {
        "id": "MPk6oYL4Q2HG",
        "name": "cell4",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000003"
    },
    {
      "cell_type": "code",
      "source": "!pip install bertopic --quiet",
      "metadata": {
        "id": "QIWsX5kESl3X",
        "language": "python",
        "codeCollapsed": false
      },
      "execution_count": 3,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000004"
    },
    {
      "cell_type": "markdown",
      "source": "### Imports\n\nRAPIDS provides a new experience that allows you to harness the capabilities of GPUs to run your code authored in pandas or scikit-learn, all *without* the need to change your code in a meaningful way. The Zero-Code-Change (ZCC) experience runs seamlessly on a GPU without doing any additional work on the user's part. And in any case the code to be run on a GPU has not been yet supported, the framwork will then execute the CPU version of the code without any input from the user!\n\n![test](https://rapids.ai/cudf-pandas/chart.png)\n\nTo enable this experience, all you need to to is to add these lines on top of your script!",
      "metadata": {
        "id": "-Qn_C5TLSN3W",
        "name": "cell6",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000005"
    },
    {
      "cell_type": "code",
      "id": "0086cc13-f5be-4210-911e-5c268bab2aa5",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import cuml\ncuml.accel.install()\nimport cudf.pandas\ncudf.pandas.install()",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now that we have the environment set up, we can do our imports.",
      "metadata": {
        "id": "Qe2uHKQ_UI_Q",
        "name": "cell8",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000007"
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom bertopic import BERTopic\nfrom sentence_transformers import SentenceTransformer\nfrom umap import UMAP\nfrom hdbscan import HDBSCAN",
      "metadata": {
        "id": "9gHJWbVvSHSw",
        "language": "python"
      },
      "execution_count": 7,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000008"
    },
    {
      "cell_type": "markdown",
      "source": "We are using a bunch of frameworks here. Most of these are fairly selfexplanatory (who doesn't know pandas?!) and we have already touched upon BERTopic. The remaining frameworks help us with the following:\n\n1. [SentenceTransformer](https://www.sbert.net/) is a part of a large collection of over 5000 pre-trained models that help create embeddings we will use to train the topic modeling model.\n2. [UMAP](https://umap-learn.readthedocs.io/en/latest/) is a STOA dimensionality reduction tool that is useful with non-linear problems.\n3. [HDBSCAN](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html) is a powerful clustering algorithm that uses density-based algorithm (DBSCAN) to find clusters but was further extended to convert it into a hierchical version (hence the HD prefix in the name).\n\n## Download the data\nIn this example we will be using a Amazon Review dataset and focus on the reviews of beauty products.",
      "metadata": {
        "id": "Q2no0ziOUPBH",
        "name": "cell10",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000009"
    },
    {
      "cell_type": "code",
      "source": "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/review_categories/All_Beauty.jsonl.gz --no-check-certificate",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9A6DcMTSOM1",
        "outputId": "e83c95d3-d363-4d17-8a4b-c40c4953d96b",
        "language": "python"
      },
      "execution_count": 5,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000010"
    },
    {
      "cell_type": "markdown",
      "source": "The code downloads to a local drive so now we can use pandas like we normally would but all this code actually runs on the GPU!",
      "metadata": {
        "id": "t3KTIjP1WpQN",
        "name": "cell12",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000011"
    },
    {
      "cell_type": "code",
      "source": "path = \"All_Beauty.jsonl.gz\"\ndata = pd.read_json(path, lines=True)",
      "metadata": {
        "id": "cTS9n6PSTUqj",
        "language": "python"
      },
      "execution_count": 8,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000012"
    },
    {
      "cell_type": "markdown",
      "source": "You can check this for yourself by running the `nvidia-smi` command and you should see about 1GB memory usage on the GPU.",
      "metadata": {
        "id": "9xcsLV1NW5_v",
        "name": "cell14",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000013"
    },
    {
      "cell_type": "code",
      "source": "!nvidia-smi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLqw3vGrW-Xk",
        "outputId": "8a2dd42e-74d6-4a7f-9ca8-aae3e7e2763d",
        "language": "python"
      },
      "execution_count": 9,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000014"
    },
    {
      "cell_type": "markdown",
      "source": "In this particular exercise -- we will only use the first 200k records.",
      "metadata": {
        "id": "5jqiK33YXJMX",
        "name": "cell16",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000015"
    },
    {
      "cell_type": "code",
      "source": "# Limit to e.g., 200K records for demo purposes\nN = 200000\n\ndata = data.head(N)",
      "metadata": {
        "id": "AeblFoLUTlFl",
        "language": "python"
      },
      "execution_count": 10,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000016"
    },
    {
      "cell_type": "markdown",
      "source": "Let's have a peek what the data looks like.",
      "metadata": {
        "id": "OIatxpftXZ0X",
        "name": "cell18",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000017"
    },
    {
      "cell_type": "code",
      "source": "data.head()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "G4wi4ySnXd7k",
        "outputId": "5b6e5089-a874-4e36-a631-0281a54676ac",
        "language": "python"
      },
      "execution_count": 11,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000018"
    },
    {
      "cell_type": "markdown",
      "source": "We have the rating and additional metadata associated with the review. However, we will be using the `text` column only as we are interested in understanding if we can uncover any patterns in the reviews.",
      "metadata": {
        "id": "X33kkSiSXO-6",
        "name": "cell20",
        "codeCollapsed": true,
        "collapsed": false
      },
      "id": "ce110000-1111-2222-3333-ffffff000019"
    },
    {
      "cell_type": "code",
      "source": "sample_docs = data.text.tolist()\nsample_docs[0]",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_Tfpfv_8X7db",
        "outputId": "f12265c1-e912-48ec-f5e8-2c2a9cf38780",
        "language": "python"
      },
      "execution_count": 14,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000020"
    },
    {
      "cell_type": "markdown",
      "source": "## Let's have some fun!\n\nNow that we have the data to work with -- let's start our main task: the topic modeling. First, we cannot simply pass text to the BERTopic model and we need to turn each and every sentence into a numerical representation -- an embedding. In this notebook we will use the [`all-MiniLM-L6-v2`](https://huggingface.co/nreimers/MiniLM-L6-H384-uncased) model.",
      "metadata": {
        "id": "j5kD_Fy4X-C1",
        "name": "cell22",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000021"
    },
    {
      "cell_type": "markdown",
      "id": "ab808e10-d80d-4175-a102-95f115c476d9",
      "metadata": {
        "name": "cell62",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "source": "# %%time\nimport time\nstart = time.time()\nsentence_model_mg = SentenceTransformer(\"all-MiniLM-L6-v2\")\npool = sentence_model_mg.start_multi_process_pool()\nembeddings = sentence_model_mg.encode(sample_docs, batch_size=128, show_progress_bar=True, pool=pool)\nend = time.time()\nprint(f\"Elapsed time: {end - start:.4f} seconds\")",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "8b4f0efb9eda4b4fb84e143ab406cfd3",
            "96032e32ad9548c3aea69d986da0cc46",
            "7fd74ffc6f084cd0840936956e66b662",
            "3e07c6fb80a645b9b5da60be0d52e46f",
            "fc40878bc93a4918ba1ad96b46167d46",
            "1ca5215068ef43b2beff6dfd7ec6f491",
            "0f0c82e227b54382976f5fe2c1c789f0",
            "79e4b28aa96f49e4bee7f9c89d841e9a",
            "1ca1b595228a4690a11b4260b168ee43",
            "f36814587b704097a9077f7db6ba23c0",
            "a76685dd740e41b7a92b2ba76c2143f7"
          ]
        },
        "id": "3Hjq5WaCTpe0",
        "outputId": "0182516c-4873-4df2-c3b1-dc18bc3c1430",
        "language": "python"
      },
      "execution_count": 16,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000022"
    },
    {
      "cell_type": "markdown",
      "source": "This process may take a 2 minutes or so but it's a process we only need to do once. Next, now that we have the embeddings, we can train our initial *vanilla* topic model.",
      "metadata": {
        "id": "my8Dw0ziYoiK",
        "name": "cell24",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000023"
    },
    {
      "cell_type": "code",
      "id": "7827b684-2048-41e4-9fb3-a2953ad812b7",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import numpy as np\n\n# Check for zero or duplicate embeddings\nzero_rows = np.where(np.linalg.norm(embeddings, axis=1) == 0)\nif len(zero_rows) > 0:\n    print(f\"Zero embeddings found at indices: {zero_rows}\")\n\n# Remove duplicates\n_, unique_indices = np.unique(embeddings, axis=0, return_index=True)\nif len(unique_indices) < len(embeddings):\n    print(f\"Duplicates found, keeping only unique embeddings.\")\n    embeddings = embeddings[unique_indices]\n    sample_docs = [sample_docs[i] for i in unique_indices]",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# %%time\ntopic_model = BERTopic()\ntopics, probs = topic_model.fit_transform(sample_docs, embeddings)",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaYi0quqT0aq",
        "outputId": "3a96f2e3-415b-40cb-d910-b522ef58f799",
        "language": "python",
        "codeCollapsed": false
      },
      "execution_count": 17,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000024"
    },
    {
      "cell_type": "markdown",
      "source": "Woot! We have now successfully trained a BERTopic model! On a GPU nonetheless!\n\nLet's explore what we have learned! First, we can quickly discern the most commonly occuring words in each topic (here we only use 8 top topics).",
      "metadata": {
        "id": "hDaImfCWZLud",
        "name": "cell26",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000025"
    },
    {
      "id": "0412d0b3-82ac-43e6-b3e0-86db16a35e72",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import matplotlib.pyplot as plt\n\n# Create bar charts for topics\nn_topics = 8\nfig, axes = plt.subplots(2, 4, figsize=(20, 10))\naxes = axes.flatten()\n\nfor idx in range(n_topics):\n    topic = topic_model.get_topic(idx)\n    if topic:\n        words = [word for word, score in topic[:10]]\n        scores = [score for word, score in topic[:10]]\n        \n        axes[idx].barh(range(len(words)), scores, color='steelblue')\n        axes[idx].set_yticks(range(len(words)))\n        axes[idx].set_yticklabels(words, fontsize=10)\n        axes[idx].set_title(f'Topic {idx}', fontsize=12, fontweight='bold')\n        axes[idx].invert_yaxis()\n        axes[idx].set_xlabel('Score', fontsize=9)\n\nplt.tight_layout()\nplt.show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "So we can clearly see that for each topic -- we see semantically related words. This is good!\n\nBut how many topics there are, you ask!? Well...",
      "metadata": {
        "id": "5jQBG4j7Zyi8",
        "name": "cell28",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000027"
    },
    {
      "cell_type": "code",
      "source": "print(f'The model idenitified {len(set(topics))} distinct topics...')",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIvQ199BZxoP",
        "outputId": "8a8a3d8f-f2ef-446c-a405-8e2e6fba179b",
        "language": "python"
      },
      "execution_count": 23,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000028"
    },
    {
      "cell_type": "markdown",
      "source": "That's a lot... Let's see a distribution of how common each topic was.",
      "metadata": {
        "id": "o2dMgMCmaO44",
        "name": "cell30",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000029"
    },
    {
      "cell_type": "code",
      "source": "pd.DataFrame(topics).hist()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "cxRuFNW5aYIr",
        "outputId": "a871b42b-473d-4826-ef86-b03d8bd81151",
        "language": "python"
      },
      "execution_count": 26,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000030"
    },
    {
      "cell_type": "markdown",
      "source": "Well... we're seeing that it's a long tail distribution and likely we can do better than this. Let's see if we're seeing any similarity between these topics before we proceed to refine it.",
      "metadata": {
        "id": "ayiJnX2mam05",
        "name": "cell32",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000031"
    },
    {
      "id": "a1772781-3030-438e-a914-6f2ba764efa8",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# --- Configuration (Adjust this number) ---\nTOP_N = 25 \n# ------------------------------------------\n\n# 1. Get topic info, excluding the Noise Topic (-1)\nTOPIC_INFO = topic_model.get_topic_info()\nvalid_topics = TOPIC_INFO[TOPIC_INFO.Topic != -1]['Topic'].head(TOP_N).tolist()\n\n# 2. Extract Embeddings and Calculate Similarity\n# Topic embeddings are located at index (Topic ID + 1) in the model's array\ntopic_indices = [topic_id + 1 for topic_id in valid_topics]\nembeddings = topic_model.topic_embeddings_[topic_indices]\nsimilarity_matrix = cosine_similarity(embeddings)\n\n# 3. Create Shortened Labels for the axes\ntopic_labels = TOPIC_INFO[TOPIC_INFO.Topic.isin(valid_topics)]['Name'].tolist()\ntopic_labels_short = [label.split('_')[0] + \": \" + \"_\".join(label.split('_')[1:3]) for label in topic_labels]\n\n\n# 4. Plot the Heatmap with Seaborn\nplt.figure(figsize=(16, 14)) \nsns.heatmap(\n    similarity_matrix,\n    cmap='viridis',\n    linewidths=0.5,\n    square=True,\n    annot=False, \n    cbar_kws={'label': 'Cosine Similarity Score'}\n)\n\n# Apply Labels\nplt.xticks(np.arange(len(topic_labels_short)) + 0.5, topic_labels_short, rotation=90, fontsize=10)\nplt.yticks(np.arange(len(topic_labels_short)) + 0.5, topic_labels_short, rotation=0, fontsize=10)\n\nplt.title(f'Topic Similarity Heatmap (Top {TOP_N} Topics)', fontsize=16)\nplt.show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "So the heatmap clearly shows *regions* of similar / overlapping topics (the more blue areas) and patches of less condensed overlap. This is likely better visible on the distance map between topics.",
      "metadata": {
        "id": "BlKxWtufa6lx",
        "name": "cell34",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000033"
    },
    {
      "cell_type": "code",
      "id": "f29ebc96-6dd5-4002-974a-8463b6495696",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\nembeddings_2d = UMAP(n_components=2, n_neighbors=15, min_dist=0.0).fit_transform(topic_model.topic_embeddings_)\ntopic_info = topic_model.get_topic_info()\ntopic_ids = np.array(topic_info[topic_info.Topic != -1].Topic.tolist())\n\nplt.figure(figsize=(12, 8))\nplt.scatter(embeddings_2d[1:, 0], embeddings_2d[1:, 1], c=topic_ids, cmap='viridis', s=80, alpha=0.7)\nfor i in range(min(25, len(topic_ids))):\n    words = topic_model.get_topic(topic_ids[i])\n    if words:\n        plt.annotate(f\"{topic_ids[i]}: {words[0][0]}\", (embeddings_2d[i+1, 0], embeddings_2d[i+1, 1]), fontsize=7)\nplt.colorbar(label='Topic ID')\nplt.title('2D Topic Visualization - Distance Map')\nplt.tight_layout()\nplt.show()",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Okay... There's a lot of topics but **many** overlaps!! We can surely do better than that now that we have this knowledge!\n\n## Clustering to the rescue!\n\nWe can use the UMAP to reduce the dimensionality of our dataset and then apply a clustering model (the HDBSCAN) to semantically (since we're working on embeddings!) group some of the reviews into more refined clusters!\n\nAnd the added benefit -- it all runs on a GPU!!! So no more waiting long time for the UMAP model alone to finish it's job! Running on a GPU gives us the freedom to experiment at a lightning speed!",
      "metadata": {
        "id": "YyBMg1I4bT7D",
        "name": "cell36",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000035"
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Check and fix embeddings if shape mismatch\nif embeddings.shape[0] != len(sample_docs):\n    print(f\"Shape mismatch detected: embeddings={embeddings.shape[0]}, docs={len(sample_docs)}\")\n    print(\"Re-encoding embeddings...\")\n    from sentence_transformers import SentenceTransformer\n    sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n    embeddings = sentence_model.encode(sample_docs, batch_size=256, show_progress_bar=True, device='cuda')\n    embeddings = np.array(embeddings, dtype=np.float32)\n    print(f\"Done! New embeddings shape: {embeddings.shape}\")\nelse:\n    embeddings = np.ascontiguousarray(embeddings, dtype=np.float32)\n\nsample_docs = list(sample_docs)\n\numap_model = UMAP(n_components=15, n_neighbors=15, min_dist=0.0)\nhdbscan_model = HDBSCAN(min_cluster_size=100, gen_min_span_tree=True, prediction_data=True)\n\ntopic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model)\n# %time \ntopics, probs = topic_model.fit_transform(sample_docs, embeddings)\n\n# Matplotlib replacement for topic_model.visualize_topics()\nembeddings_2d = UMAP(n_components=2, n_neighbors=15, min_dist=0.0).fit_transform(topic_model.topic_embeddings_)\ntopic_ids = np.array(topic_model.get_topic_info()[topic_model.get_topic_info().Topic != -1].Topic.tolist())\n\nplt.figure(figsize=(12, 8))\nplt.scatter(embeddings_2d[1:, 0], embeddings_2d[1:, 1], c=topic_ids, cmap='viridis', s=80, alpha=0.7)\nfor i in range(min(25, len(topic_ids))):\n    words = topic_model.get_topic(topic_ids[i])\n    if words:\n        plt.annotate(f\"{topic_ids[i]}: {words[0][0]}\", (embeddings_2d[i+1, 0], embeddings_2d[i+1, 1]), fontsize=7)\nplt.colorbar(label='Topic ID')\nplt.title('2D Topic Visualization')\nplt.tight_layout()\nplt.show()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "l5OC6xHhU4Wy",
        "outputId": "401474e3-3423-446f-cc87-1cdc1ee68b14",
        "language": "python"
      },
      "execution_count": 29,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000036"
    },
    {
      "cell_type": "markdown",
      "source": "As I was saying... it's quick!\n\nAnd now we have a much better refined topics (and there's only 105 of them!) Let's see if we still have similar words retained in each topic!",
      "metadata": {
        "id": "UUyZVCffcJAx",
        "name": "cell38",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000037"
    },
    {
      "id": "03949562-b042-4e61-8768-a16c0c984ad9",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Get all topic IDs, excluding the Noise Topic (-1)\ntopic_freqs = topic_model.get_topic_info()\n\n# Select the top 16 most frequent topics for visualization\nvalid_topic_ids = topic_freqs[topic_freqs.Topic != -1]['Topic'].head(16).tolist()\n\n# Define the number of topics to plot (16) and set up the 4x4 grid\nn_topics = len(valid_topic_ids)\nfig, axes = plt.subplots(4, 4, figsize=(20, 20))\naxes = axes.flatten()\n\n# Set a common title for the whole figure\nfig.suptitle(f'Top {n_topics} Topic Word Scores (Matplotlib)', fontsize=20, fontweight='bold')\n\nfor idx, topic_id in enumerate(valid_topic_ids):\n    # Retrieve the top words for the specific topic ID\n    topic = topic_model.get_topic(topic_id)\n    \n    if topic:\n        words = [word for word, score in topic[:10]]\n        scores = [score for word, score in topic[:10]]\n        \n        sns.barplot(x=scores, y=words, ax=axes[idx], palette='viridis')\n        \n        topic_name = topic_model.get_topic_info(topic_id).Name.iloc[0]\n        title_words = '_'.join(topic_name.split('_')[1:3])\n        \n        axes[idx].set_title(f'Topic {topic_id}: {title_words}...', fontsize=12, fontweight='bold')\n        axes[idx].set_xlabel('c-TF-IDF Score', fontsize=9)\n        axes[idx].set_ylabel(None)\n        \n# Clean up unused subplots\nfor i in range(n_topics, 16):\n    fig.delaxes(axes[i])\n\nplt.tight_layout(rect=[0, 0, 1, 0.96]) \nplt.show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Unsurprisingly -- we still do. There are still some topics that could be closely related and viewed as related e.g. topic 0 and topic 6 could be related in some cases when the reviewer talks about how gentle certain shampoos or conditioners are to the skin and how nicely they smell.\n\nLuckily, we used the HDBSCAN and we can quickly pull up these hierarchies.",
      "metadata": {
        "id": "hjBN9oDvcyUY",
        "name": "cell40",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000039"
    },
    {
      "cell_type": "code",
      "id": "f9366bb1-22b0-4341-bec2-075e7973cbb4",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "hierarchical_topics = topic_model.hierarchical_topics(sample_docs)\n\nfrom scipy.cluster.hierarchy import linkage, dendrogram\nfrom scipy.spatial.distance import squareform\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Get topic embeddings (exclude noise topic -1)\ntopic_info = topic_model.get_topic_info()\ntopic_info = topic_info[topic_info.Topic != -1]\ntopic_ids = topic_info.Topic.tolist()\ntopic_embeddings = topic_model.topic_embeddings_[1:]  \n\n# Create linkage matrix using cosine distance\ndistance_matrix = 1 - cosine_similarity(topic_embeddings)\nnp.fill_diagonal(distance_matrix, 0)  \ncondensed_dist = squareform(distance_matrix)\nlinkage_matrix = linkage(condensed_dist, method='ward')\n\n# Create labels for ALL topics with multiple words (\nlabels = []\nfor tid in topic_ids:\n    words = topic_model.get_topic(tid)\n    if words:\n        top_words = \"_\".join([w for w, s in words[:3]])\n        labels.append(f\"{tid}_{top_words}\")\n    else:\n        labels.append(str(tid))\n\n\nfig_height = max(20, len(labels) * 0.25) \nplt.figure(figsize=(14, fig_height))\ndendrogram(linkage_matrix, labels=labels, orientation='left', leaf_font_size=7)\nplt.title('Hierarchical Clustering', fontsize=16, fontweight='bold')\nplt.xlabel('Distance')\nplt.tight_layout()\nplt.show()\nprint(f\"Total topics shown: {len(labels)}\")",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Nice. So now we can further decide how to further cluster our topics. However, one thing that we saw when we first peeked inside the dataset that there was a ton of short reviews. These reviews are likely skewing our results.",
      "metadata": {
        "id": "hZC06scOeLwk",
        "name": "cell42",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000041"
    },
    {
      "cell_type": "code",
      "source": "data.head()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_OgXS7fQejQo",
        "outputId": "94e40c67-8f99-4c33-d7c1-832e2b72f7ef",
        "language": "python"
      },
      "execution_count": 33,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000042"
    },
    {
      "cell_type": "markdown",
      "source": "Let's see how big of a problem this is for us.",
      "metadata": {
        "id": "OeLfNvRFemmN",
        "name": "cell44",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000043"
    },
    {
      "cell_type": "code",
      "source": "data_word_count = data.text.str.count(\"\\w+\")\ndata_word_count.head()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "x-0e9MfXeq90",
        "outputId": "6c7c5889-202f-4cb1-c5bb-d5ff6b262de3",
        "language": "python"
      },
      "execution_count": 35,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000044"
    },
    {
      "cell_type": "markdown",
      "source": "Now let's see the stats!",
      "metadata": {
        "id": "i-mJ7dAKe4XC",
        "name": "cell46",
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000045"
    },
    {
      "cell_type": "code",
      "source": "data_word_count.describe()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "YSs4xU_Ke72Q",
        "outputId": "825ae645-6134-4420-831c-5e0f9394471a",
        "language": "python"
      },
      "execution_count": 37,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000046"
    },
    {
      "cell_type": "markdown",
      "source": "Alright... So, we see that the median is 21 words - that's a decent length. However, we'd be filtering out half of our reviews. I think 10 words (i.e. over 70% of our dataset) would be usable so let's try that.",
      "metadata": {
        "id": "KsYmNCdefCih",
        "name": "cell48",
        "codeCollapsed": true,
        "collapsed": false
      },
      "id": "ce110000-1111-2222-3333-ffffff000047"
    },
    {
      "cell_type": "code",
      "source": "# Filter dataframe\nlonger_reviews = data.loc[data.text.str.count(r\"\\w+\") >= 10]\nlonger_reviews = longer_reviews.reset_index(drop=True)\n\n# Select embeddings (should match filtered_docs order: both start at zero)\nfiltered_docs = longer_reviews.text.tolist()\nfiltered_embeddings = embeddings[longer_reviews.index.values]\nfiltered_embeddings.shape\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL8bCSUbPu1a",
        "outputId": "79ff2357-964b-47d4-aab7-a31323d21c91",
        "language": "python"
      },
      "execution_count": 45,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000048"
    },
    {
      "cell_type": "markdown",
      "source": "Good! We still have almost 150k reviews left but we are now guaranteed that these reviews convey a little bit more information than a simple -- \"good product\".",
      "metadata": {
        "id": "1nX4BSZDfpAy",
        "name": "cell50",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000049"
    },
    {
      "cell_type": "code",
      "source": "topic_model_long = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model)\n# %time \ntopics, probs = topic_model_long.fit_transform(filtered_docs, filtered_embeddings)",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y07ZMzlHfnI_",
        "outputId": "0ecd27cd-3a70-457f-c55b-83e393722586",
        "language": "python"
      },
      "execution_count": 46,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000050"
    },
    {
      "cell_type": "markdown",
      "source": "How many topics we're seeing now?",
      "metadata": {
        "id": "2Ci9qB07ggmR",
        "name": "cell52",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000051"
    },
    {
      "cell_type": "code",
      "source": "print(f'Revised number of topics: {len(set(topics))}')",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqCJ2TUAgKIo",
        "outputId": "460e6f7d-f018-467c-922f-d37be45f90f7",
        "language": "python"
      },
      "execution_count": 47,
      "outputs": [],
      "id": "ce110000-1111-2222-3333-ffffff000052"
    },
    {
      "cell_type": "code",
      "id": "a3d20949-33e4-419b-89b3-69344eaf7ba2",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\n# Get topic info and embeddings\ntopic_info = topic_model_long.get_topic_info()\ntopic_info = topic_info[topic_info.Topic != -1]  \nembeddings_2d = UMAP(n_components=2, n_neighbors=15, min_dist=0.0).fit_transform(topic_model_long.topic_embeddings_)\n\n# Get sizes based on topic frequency \nsizes = np.array(topic_info.Count.tolist())\nsizes = (sizes / sizes.max()) * 1500 + 100 \n\nplt.figure(figsize=(14, 10))\nplt.scatter(embeddings_2d[1:, 0], embeddings_2d[1:, 1], s=sizes, c='lightsteelblue', alpha=0.6, edgecolors='darkblue', linewidth=1.5)\n\n# Add labels for top topics\nfor i in range(min(20, len(topic_info))):\n    topic_id = topic_info.Topic.iloc[i]\n    words = topic_model_long.get_topic(topic_id)\n    if words:\n        label = f\"{topic_id}: {words[0][0]}_{words[1][0]}\"\n        plt.annotate(label, (embeddings_2d[i+1, 0], embeddings_2d[i+1, 1]), fontsize=8, ha='center')\n\nplt.title('Intertopic Distance Map', fontsize=16, fontweight='bold')\nplt.xlabel('Dimension 1')\nplt.ylabel('Dimension 2')\nplt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\nplt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\nplt.tight_layout()\nplt.show()",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Okay, this looks even better than before! Let's check the word frequencies.",
      "metadata": {
        "id": "Y5PHjaiihfiU",
        "name": "cell55",
        "collapsed": false,
        "codeCollapsed": true
      },
      "id": "ce110000-1111-2222-3333-ffffff000054"
    },
    {
      "cell_type": "code",
      "id": "9e3ffb2a-89b4-4700-a0ad-f7c16b4b95cc",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\n\ntopic_info = topic_model_long.get_topic_info()\nvalid_topic_ids = topic_info[topic_info.Topic != -1]['Topic'].head(16).tolist()\n\n# Colors matching \ncolors = ['#E45756', '#4C78A8', '#F58518', '#72B7B2', '#54A24B', '#EECA3B', \n          '#B279A2', '#FF9DA6', '#9D755D', '#BAB0AC', '#E45756', '#4C78A8',\n          '#F58518', '#72B7B2', '#54A24B', '#EECA3B']\n\nfig, axes = plt.subplots(4, 4, figsize=(18, 16))\naxes = axes.flatten()\nfig.suptitle('Topic Word Scores', fontsize=20, fontweight='bold')\n\nfor idx, topic_id in enumerate(valid_topic_ids):\n    topic = topic_model_long.get_topic(topic_id)\n    if topic:\n        words = [w for w, s in topic[:5]]  \n        scores = [s for w, s in topic[:5]]\n        axes[idx].barh(words, scores, color=colors[idx % len(colors)])\n        axes[idx].set_title(f'Topic {topic_id}', fontsize=11)\n        axes[idx].invert_yaxis()\n        axes[idx].tick_params(axis='y', labelsize=9)\n\nfor i in range(len(valid_topic_ids), 16):\n    fig.delaxes(axes[i])\n\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Summary\n\nIn the end, in less than a few minutes, we have a well defined clusters of topics that the reviewers of beauty products cared to share with us. Thanks to the power of GPU we were able to quickly sift through 200k reviews and come up with up to 70 clearly delineated topics that using HDBSCAN we can further group into logical topics.\n\nAnd we were able to achieve *all* of this without changing any code that would have run for hours on a CPU.\n\nThe power of GPUs gives you the power to build better models faster!\n\nTry it out for yourself!",
      "metadata": {
        "id": "ivCk5gmih0Ua",
        "name": "cell57",
        "codeCollapsed": true,
        "collapsed": false
      },
      "id": "ce110000-1111-2222-3333-ffffff000056"
    }
  ]
}