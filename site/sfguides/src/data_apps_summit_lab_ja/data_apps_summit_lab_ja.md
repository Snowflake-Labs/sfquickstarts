author: 
id: data_apps_summit_lab_ja
summary: ã“ã‚Œã¯ã‚µãƒ³ãƒ—ãƒ«ã®Snowflakeã‚¬ã‚¤ãƒ‰ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§ã™
categories: featured,app-development
environments: web
status: Published 
feedback link: https://github.com/Snowflake-Labs/sfguides/issues
tags: Getting Started, Data Science, æ—¥æœ¬èª, Data Engineering, Twitter, ja 

# Snowflakeãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹ã€Snowparkã€Streamlitã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ§‹ç¯‰

## æ¦‚è¦
Duration: 2

ã“ã®ãƒãƒ³ã‚ºã‚ªãƒ³ãƒ©ãƒœã§ã¯ã€KnoemaãŒSnowflakeãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹ã§å…¬é–‹ã—ã¦ã„ã‚‹Economical Data Atlasã‚’æ´»ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

Snowparkã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã€Snowflakeã§ç°¡å˜ãªMLãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã€Pythonãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©é–¢æ•°ï¼ˆUDFï¼‰ã‚’ä½œæˆã—ã¦ã‹ã‚‰ã€Streamlitã§ãƒ‡ãƒ¼ã‚¿ã‚’è¦–è¦šåŒ–ã—ã¾ã™ã€‚

### ä¸»ãªæ©Ÿèƒ½ã¨ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼

* Snowflakeãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹
* Snowpark for Python
* Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒª
* Pythonãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©é–¢æ•°ï¼ˆUDFï¼‰
* Streamlit

### å‰ææ¡ä»¶

* Snowflakeã¾ãŸã¯Snowflakeãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†è€…ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ï¼š[https://signup.snowflake.com/](https://signup.snowflake.com/)
* SQLã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹æƒ³ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦ã®åŸºæœ¬çŸ¥è­˜
* Pythonã«ç²¾é€šã—ã¦ã„ã‚‹ã“ã¨ã€‚  ãƒ©ãƒœç”¨ã®ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ãŒæä¾›ã•ã‚Œã¾ã™ã€‚
* ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦å®Ÿè¡Œã§ãã‚‹ã“ã¨
* [VSCode](https://code.visualstudio.com/download)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨

### å­¦ç¿’ã™ã‚‹å†…å®¹

* Snowflakeãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•
* DataFramesã‚’ä½¿ç”¨ã—ã¦Pythonã§ãƒ‡ãƒ¼ã‚¿ã«ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹æ–¹æ³•
* æ—¢å­˜ã®Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ´»ç”¨ã™ã‚‹æ–¹æ³•
* Snowflakeã§Snowpark Pythonãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©é–¢æ•°ã‚’ä½œæˆã™ã‚‹æ–¹æ³•
* Streamlitã§ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’è¦–è¦šåŒ–ã™ã‚‹æ–¹æ³•

### æ§‹ç¯‰ã™ã‚‹ã‚‚ã®

* Snowpark for Pythonã§Snowflakeã«æ¥ç¶šã—ã€ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã®ç‰¹å¾´é‡ã‚’æº–å‚™ã™ã‚‹Pythonãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€‚
* Pythonã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãSnowflakeãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©é–¢æ•°ï¼ˆUDFï¼‰
* Streamlitãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

<!-- ------------------------ -->
## ãƒ©ãƒœç’°å¢ƒã®æº–å‚™

Duration: 8

1. åˆ¥ã®ç’°å¢ƒã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã€pip install condaã‚’å®Ÿè¡Œã—ã¦condaã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚æ³¨æ„ï¼š[Miniconda](https://docs.conda.io/en/latest/miniconda.html)ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚‚ã‚ã‚Šã¾ã™ã€‚
2. ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã¾ãŸã¯ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é–‹ãã¾ã™ã€‚

> é‡è¦ï¼šApple M1ãƒãƒƒãƒ—ã‚’æ­è¼‰ã—ãŸãƒã‚·ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã§èª¬æ˜ã™ã‚‹æ‰‹é †ã§ã¯ãªãã€[ã“ã¡ã‚‰ã®æ‰‹é †](https://docs.snowflake.com/ja/developer-guide/snowpark/python/setup)ã«å¾“ã£ã¦ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã€Snowpark Pythonã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚

3. `conda create --name snowpark -c https://repo.anaconda.com/pkgs/snowflake python=3.8`ã‚’å®Ÿè¡Œã—ã¦ç’°å¢ƒã‚’ä½œæˆã—ã¾ã™ã€‚
4. `conda activate snowpark`ã‚’å®Ÿè¡Œã—ã¦condaç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–ã—ã¾ã™ã€‚
5. `conda install -c https://repo.anaconda.com/pkgs/snowflake snowflake-snowpark-python pandas scikit-learn`ã‚’å®Ÿè¡Œã—ã¦ã€Snowpark for Pythonã€pandasã€scikit-learnã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚
6. `pip install streamlit`ã¾ãŸã¯`conda install streamlit`ã‚’å®Ÿè¡Œã—ã¦Streamlitã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚
7. ã€ŒSummit HOL PCEã€ãªã©ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€ãã®ä¸­ã«Labãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰/ä¿å­˜ã—ã¾ã™ã€‚
   * å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒªãƒ³ã‚¯ï¼šhttps://drive.google.com/drive/folders/1CN6Ljj59XWv2B3Epqxk4DtfDmCH1co_Q?usp=sharing

---

### `pyarrow`é–¢é€£ã®å•é¡Œã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

- `pyarrow`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã™ã§ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€Snowparkã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å‰ã«ã‚¢ãƒ³ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚
- `pyarrow`ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€è‡ªåˆ†ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚Snowparkã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã¨ã€é©åˆ‡ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒè‡ªå‹•çš„ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã™ã€‚
- Snowparkã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã«ã€ç•°ãªã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®`pyarrow`ã‚’å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªã„ã§ãã ã•ã„ã€‚

<!-- ------------------------ -->
## Snowflakeã®ç’°å¢ƒã®æº–å‚™

Duration: 6

### Snowflakeãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹ã®åˆ©ç”¨

Snowflakeãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹ã¯ã€ãƒ“ã‚¸ãƒã‚¹ãƒ—ãƒ­ã‚»ã‚¹ã®å¤‰é©ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æ‹¡å¤§ã™ã‚‹ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒãƒ¥ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã®ã•ã¾ã–ã¾ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚ã¾ãŸã€ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«ã‚ˆã£ã¦å®Œå…¨ã«ç®¡ç†ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®å®‰å…¨ãªã‚¢ã‚¯ã‚»ã‚¹ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆã¨ãƒ¢ãƒ‡ãƒ«åŒ–ã®å¿…è¦æ€§ã‚’æ’é™¤ã—ã¾ã™ã€‚

Snowflakeãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ©ç”¨æ–¹æ³•ã‚’ç¢ºèªã™ã‚‹å‰ã«ã€Snowflakeã®è©¦ç”¨ç‰ˆãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ã€ŒSnowflakeãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚ã“ã‚Œã§ä½œæ¥­ç”¨ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—ã—ã€Snowflakeã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ãŸã®ã§ã€æ¬¡ã®æ‰‹é †ã«å¾“ã„ã¾ã™ã€‚

* å·¦ä¸Šã§ã€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†è€…ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†è€…ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãªã„å ´åˆã¯ãƒ­ãƒ¼ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚
* ã€Œãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚
* æ¤œç´¢ãƒãƒ¼ã«ã€ŒKnoema Economyã€ã¨å…¥åŠ›ã—ã€ã€ŒEconomy Data Atlasã€ã¨ã„ã†ãƒ©ãƒ™ãƒ«ã®ä»˜ã„ãŸã‚¿ã‚¤ãƒ«ãƒœãƒƒã‚¯ã‚¹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚

![alt_text](assets/cybersyn-essentials.png)

* å³ä¸Šã®ã€Œãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã€ã‚’é¸æŠã—ã¾ã™ã€‚
* ä½œæˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã®é©åˆ‡ãªãƒ­ãƒ¼ãƒ«ã‚’é¸æŠã—ã€Snowflakeã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼è¦ç´„ã¨Knoemaã®åˆ©ç”¨è¦ç´„ã«åŒæ„ã—ã¾ã™ã€‚
* ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

## 

![alt_text](assets/query-data.png)

* ã“ã®æ™‚ç‚¹ã§ã€Œã‚¯ã‚¨ãƒªãƒ‡ãƒ¼ã‚¿ã€ã‚’é¸æŠã§ãã¾ã™ã€‚ã“ã‚Œã‚’é¸æŠã™ã‚‹ã¨ã€ã‚¯ã‚¨ãƒªä¾‹ã‚’å«ã‚€ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆãŒé–‹ãã¾ã™ã€‚

![alt_text](assets/sample-query.png)

* ç±³å›½ã®ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ‡ãƒ¼ã‚¿ã«èˆˆå‘³ãŒã‚ã‚‹ã®ã§ã€æ¬¡ã®ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³`What is the US inflation over time?`ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª¿æŸ»ã—ã¾ã™ã€‚
  
  ```
  SELECT * FROM "ECONOMY"."BEANIPA" WHERE "Table Name" = 'Price Indexes For Personal Consumption Expenditures By Major Type Of Product' AND "Indicator Name" = 'Personal consumption expenditures (PCE)' AND "Frequency" = 'A' ORDER BY "Date"
  
  ```

### æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆ

Economy Data Atlasã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ãŸã®ã§ã€æ¬¡ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©é–¢æ•°ã‚’ä¿å­˜ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

Snowflakeã®ãƒ›ãƒ¼ãƒ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã€ã‚’é¸æŠã—ã¾ã™ã€‚æ–°ã—ã„ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’ã€

![alt_text](assets/worksheet.png)ãƒœã‚¿ãƒ³ã‚’é¸æŠã—ã¦ä½œæˆã—ã¾ã™ã€‚

ã“ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã«æ¬¡ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚

```python
-- First create database using the Knoema Economical Data Atlas
-- Go to Marketplace to get database

-- Setup database, need to be logged in as accountadmin role */
--Set role and warehouse (compute)
USE ROLE accountadmin;
USE WAREHOUSE compute_wh;

--Create database and stage for the Snowpark Python UDF
CREATE DATABASE IF NOT EXISTS summit_hol;
CREATE STAGE IF NOT EXISTS udf_stage;

--Test the data
-- What's the size?
SELECT COUNT(*) FROM ECONOMY_DATA_ATLAS.ECONOMY.BEANIPA;

-- What is the US inflation over time?
SELECT * FROM ECONOMY_DATA_ATLAS.ECONOMY.BEANIPA
   WHERE "Table Name" = 'Price Indexes For Personal Consumption Expenditures By Major Type Of Product'
     AND "Indicator Name" = 'Personal consumption expenditures (PCE)'
     AND "Frequency" = 'A'
ORDER BY "Date"
;

-- Now create UDF in VS Code / Notebook
-- Once we created the UDF with the Python Notebook we can test the UDF
SELECT predict_pce_udf(2021);
```

<!-- ------------------------ -->
## ï¼ˆJupyterï¼‰ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã®æ¢ç´¢

Duration: 15

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½¿ç”¨ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã§ããŸã®ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ç´¢ã—ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½¿ç”¨ã§ãã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©é–¢æ•°ï¼ˆUDFï¼‰ã§MLãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚

VSã‚³ãƒ¼ãƒ‰ã‚’é–‹ãã€å‰ã«ä½œæˆã—ãŸPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã‚’é–‹ãã¾ã™ã€‚

Pythonãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼ˆmy_snowpark_pce.ipynbï¼‰ã¨Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆmy_snowpark_streamlit_app_pce.pyï¼‰ã‚’é–‹ãã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é †ã‚’è¿½ã£ã¦èª¬æ˜ã—ã¾ã™ã€‚

VSã‚³ãƒ¼ãƒ‰ã‹ã‚‰Pythonç’°å¢ƒãŒè¦æ±‚ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚\\

![alt_text](assets/interpreter.png)

å‰ã«ä½œæˆã—ãŸã€Œsnowparkã€Condaç’°å¢ƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

å³ä¸‹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ã‚’é¸æŠã§ãã¾ã™ã€‚\\

![alt_text](assets/conda.png)

### ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®åˆæœŸåŒ–ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã€Snowflakeæ¥ç¶šã®ä½œæˆ

ã¾ãšã€Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã—ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å«ã‚ã¾ã—ã‚‡ã†ã€‚

```python
from snowflake.snowpark.session import Session
from snowflake.snowpark.types import IntegerType, FloatType
from snowflake.snowpark.functions import avg, sum, col, udf, call_udf, call_builtin, year
import streamlit as st
import pandas as pd
from datetime import date

# scikit-learn (install: pip install -U scikit-learn)
from sklearn.linear_model import LinearRegression
```

### Snowflakeã¸ã®æ¥ç¶š

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€Snowflakeã«æ¥ç¶šã™ã‚‹ãŸã‚ã®[Sessionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ](https://docs.snowflake.com/ja/LIMITEDACCESS/snowpark-python.html#creating-a-session)ã‚’ä½œæˆã—ã¾ã™ã€‚ä»¥ä¸‹ã¯ãã®ç°¡å˜ãªæ–¹æ³•ã§ã™ãŒã€èªè¨¼æƒ…å ±ã‚’ã‚³ãƒ¼ãƒ‰ã«ç›´æ¥ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã“ã¨ã¯ã€æœ¬ç•ªç’°å¢ƒã§ã¯æ¨å¥¨ã•ã‚Œãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚æœ¬ç•ªç’°å¢ƒã§ã¯ã€[AWS Secrets Manager](https://github.com/iamontheinet/sf-code-snippets/blob/main/aws_secrets_manager_sf_connection.py)ã‚„[Azure Key Vault](https://github.com/iamontheinet/sf-code-snippets/blob/main/azure_key_vault_sf_connection.py)ãªã©ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

Snowflakeã®è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
# Session
connection_parameters = {
   "account": "<account_identifier>",
   "user": "<username>",
   "password": "<password>",
   "warehouse": "compute_wh",
   "role": "accountadmin",
   "database": "summit_hol",
   "schema": "public"
}
session = Session.builder.configs(connection_parameters).create()
# test if we have a connection
session.sql("select current_warehouse() wh, current_database() db, current_schema() schema, current_version() v").show()
```

ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã§ã€ã€Œ\<>ã€ã§å›²ã¾ã‚ŒãŸå¤‰æ•°ã‚’å®Ÿéš›ã®å€¤ã«ç½®ãæ›ãˆã¾ã™ã€‚

### SQLã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã¨Snowpark Dataframeã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ã‚¯ã‚¨ãƒª

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€Snowflake for Pythonã‚³ãƒã‚¯ã‚¿ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹ã®ã¨åŒæ§˜ã«ã€Sessionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§SQLã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œã™ã‚‹å¾“æ¥ã®æ–¹æ³•ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ã‚¨ãƒªã—ã¾ã™ã€‚

```sql
# SQL query to explore the data
session.sql("SELECT * FROM ECONOMY_DATA_ATLAS.ECONOMY.BEANIPA WHERE \"Table Name\" = 'Price Indexes For Personal Consumption Expenditures By Major Type Of Product' AND \"Indicator Name\" = 'Personal consumption expenditures (PCE)' AND \"Frequency\" = 'A' ORDER BY \"Date\"").show()
```

æ¬¡ã«ã€Snowpark DataFrameã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ã‚¨ãƒªã—ã¾ã™ã€‚Snowparkã¯é…å»¶è©•ä¾¡ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ã‚¯ã‚¨ãƒªã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ãŒä½œæˆã•ã‚Œã€_show()_ãƒ¡ã‚½ãƒƒãƒ‰ãŒã“ã‚Œã‚’Snowflakeã‚µãƒ¼ãƒãƒ¼ã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã€ãã“ã§ã‚¯ã‚¨ãƒªãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Snowflakeã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ/ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–“ã§äº¤æ›ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿é‡ãŒå‰Šæ¸›ã•ã‚Œã¾ã™ã€‚

```python
# Now use Snowpark dataframe
snow_df_pce = (session.table("ECONOMY_DATA_ATLAS.ECONOMY.BEANIPA")
                           .filter(col('Table Name') == 'Price Indexes For Personal Consumption Expenditures By Major Type Of Product')
                           .filter(col('Indicator Name') == 'Personal consumption expenditures (PCE)')
                           .filter(col('"Frequency"') == 'A')
                           .filter(col('"Date"') >= '1972-01-01'))
snow_df_pce.show()
```

### MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ç‰¹å¾´é‡ã®ä½œæˆ

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸€éƒ¨ã¨ã—ã¦ã€å€‹äººæ¶ˆè²»æ”¯å‡ºç‰©ä¾¡æŒ‡æ•°ã‚’äºˆæ¸¬ã—ãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚ãã“ã§ã€scikit-learnç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã‚‹Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã¾ã™ã€‚  Snowpark API for Pythonã¯ã€Snowpark DataFramesã‚’Pandasã«å¤‰æ›ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚å†ã³Snowparkã®é…å»¶è©•ä¾¡ã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰ã™ã‚‹ã¨ã€_to\_pandas()_é–¢æ•°ãŒã‚¯ã‚¨ãƒªã‚’Snowflakeã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã€çµæœã‚’Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚

```python
# Let Snowflake perform filtering using the Snowpark pushdown and display results in a Pandas dataframe
snow_df_pce = (session.table("ECONOMY_DATA_ATLAS.ECONOMY.BEANIPA")
                       .filter(col('"Table Name"') == 'Price Indexes For Personal Consumption Expenditures By Major Type Of Product')
                       .filter(col('"Indicator Name"') == 'Personal consumption expenditures (PCE)')
                       .filter(col('"Frequency"') == 'A')
                       .filter(col('"Date"') >= '1972-01-01'))
pd_df_pce_year = snow_df_pce.select(year(col('"Date"')).alias('"Year"'), col('"Value"').alias('PCE') ).to_pandas()
pd_df_pce_year
```

### ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

ç‰¹å¾´é‡ã‚’ä½œæˆã—ãŸã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€NumPyãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ã€ç‰¹å¾´é‡ã‚’å«ã‚€Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é…åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ãŸã‚‰ã€äºˆæ¸¬ã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚

```python
# train model with PCE index
x = pd_df_pce_year["Year"].to_numpy().reshape(-1,1)
y = pd_df_pce_year["PCE"].to_numpy()

model = LinearRegression().fit(x, y)

# test model for 2021
predictYear = 2021
pce_pred = model.predict([[predictYear]])
# print the last 5 years
print (pd_df_pce_year.tail() )
# run the prediction for 2021
print ('Prediction for '+str(predictYear)+': '+ str(round(pce_pred[0],2)))
```

### ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸSnowflakeã§ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©é–¢æ•°ã®ä½œæˆ

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€é–¢æ•°å…¥åŠ›ã«åŸºã¥ã„ã¦PCEã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’äºˆæ¸¬ã™ã‚‹Pythoné–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚æ¬¡ã«ã€Snowpark APIã‚’ä½¿ç”¨ã—ã¦UDFã‚’ä½œæˆã—ã¾ã™ã€‚Snowparkãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã€é–¢æ•°ã®ã‚³ãƒ¼ãƒ‰ï¼ˆãŠã‚ˆã³ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚UDFã‚’å‘¼ã³å‡ºã™ã¨ã€Snowparkãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‚µãƒ¼ãƒãƒ¼ä¸Šã§é–¢æ•°ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ãã®çµæœã€é–¢æ•°ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è»¢é€ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

```python
def predict_pce(predictYear: int) -> float:
   return model.predict([[predictYear]])[0].round(2).astype(float)

_ = session.udf.register(predict_pce,
                       return_type=FloatType(),
                       input_type=IntegerType(),
                       packages= ["pandas","scikit-learn"],
                       is_permanent=True,
                       name="predict_pce_udf",
                       replace=True,
                       stage_location="@udf_stage")
```

ã“ã‚Œã§ã€Pythonã§SQLã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦UDFã‚’ãƒ†ã‚¹ãƒˆã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

```python
session.sql("select predict_pce_udf(2021)").show()
```

<!-- ------------------------ -->
## Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ

Duration: 7

### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸMLãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã€äºˆæ¸¬ã‚’è¡Œã†UDFã‚’ä½œæˆã—ãŸã®ã§ã€Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã§ãã¾ã™ã€‚

ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨åŒæ§˜ã«ã€Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã—ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å«ã‚ã¾ã™ã€‚

```python
# Import required libraries
# Snowpark
from snowflake.snowpark.session import Session
from snowflake.snowpark.types import IntegerType
from snowflake.snowpark.functions import avg, sum, col, call_udf, lit, call_builtin, year
# Pandas
import pandas as pd
#Streamlit
import streamlit as st
```

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¨­å®š

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
#Set page context
st.set_page_config(
    page_title="Economical Data Atlas",
    page_icon="ğŸ§Š",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://developers.snowflake.com',
        'About': "This is an *extremely* cool app powered by Snowpark for Python, Streamlit, and Snowflake Marketplace"
    }
)
```

### Snowflakeã¸ã®æ¥ç¶š

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€Snowflakeã«æ¥ç¶šã™ã‚‹ãŸã‚ã®[Sessionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ](https://docs.snowflake.com/ja/LIMITEDACCESS/snowpark-python.html#creating-a-session)ã‚’ä½œæˆã—ã¾ã™ã€‚ä»¥ä¸‹ã¯ãã®ç°¡å˜ãªæ–¹æ³•ã§ã™ãŒã€èªè¨¼æƒ…å ±ã‚’ã‚³ãƒ¼ãƒ‰ã«ç›´æ¥ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã“ã¨ã¯ã€æœ¬ç•ªç’°å¢ƒã§ã¯æ¨å¥¨ã•ã‚Œãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚æœ¬ç•ªç’°å¢ƒã§ã¯ã€[AWS Secrets Manager](https://github.com/iamontheinet/sf-code-snippets/blob/main/aws_secrets_manager_sf_connection.py)ã‚„[Azure Key Vault](https://github.com/iamontheinet/sf-code-snippets/blob/main/azure_key_vault_sf_connection.py)ãªã©ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

Snowflakeã®è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
# Create Session object
def create_session_object():
   connection_parameters = {
   "account": "<account_identifier>",
   "user": "<username>",
   "password": "<password>",
   "warehouse": "compute_wh",
   "role": "accountadmin",
   "database": "SUMMIT_HOL",
   "schema": "PUBLIC"
  }
   session = Session.builder.configs(connection_parameters).create()
   print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())
   return session
```

ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã§ã€ã€Œ\<>ã€ã§å›²ã¾ã‚ŒãŸå¤‰æ•°ã‚’å®Ÿéš›ã®å€¤ã«ç½®ãæ›ãˆã¾ã™ã€‚

### Snowpark DataFramesã§ã®ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ç±³å›½ã®å¹´é–“ã‚¤ãƒ³ãƒ•ãƒ¬ï¼ˆå€‹äººæ¶ˆè²»æ”¯å‡º - PCEï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã¾ã™ã€‚BEANIPAãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆBEA NIPAï¼šçµŒæ¸ˆåˆ†æå±€ - å›½æ°‘æ‰€å¾—ãŠã‚ˆã³ç”Ÿç”£å‹˜å®šãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯ç´„160ä¸‡è¡ŒãŒå«ã¾ã‚Œã¦ãŠã‚Šã€Snowparkã®é…å»¶è©•ä¾¡ã‚’ä½¿ç”¨ã—ã¦ã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’Snowflakeã§å‡¦ç†ã—ã¾ã™ã€‚

ã€Œãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ä½œæˆã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®MLãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸUDFã«åŸºã¥ã„ã¦ã€å®Ÿéš›ã®PCEå€¤ã¨äºˆæ¸¬ã•ã‚ŒãŸPCEå€¤ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã¾ã™ã€‚

ã•ã‚‰ã«ã€å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨äºˆæ¸¬ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«çµåˆã—ã¦ã€1ã¤ã®ãƒãƒ£ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

Streamlitã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã¯Pandas DataFramesãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚Snowpark API for Pythonã¯Snowpark DataFramesã‚’Pandasã«å¤‰æ›ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚

ã¾ãŸã€ä¸»è¦ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚‚è¡¨ç¤ºã—ãŸã„ã®ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

ãƒœãƒ¼ãƒŠã‚¹ã¨ã—ã¦ã€é¸æŠã—ãŸå¹´ã®å››åŠæœŸã”ã¨ã®PCEãƒ‡ãƒ¼ã‚¿ã¨ã€ä¸»è¦ãªè£½å“ã‚¿ã‚¤ãƒ—ã”ã¨ã®å†…è¨³ã‚’è¡¨ç¤ºã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã®2ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã¾ã™ã€‚

```python
  #US Inflation, Personal consumption expenditures (PCE) per year
   #Prepare data frame, set query parameters
   snow_df_pce = (session.table("ECONOMY_DATA_ATLAS.ECONOMY.BEANIPA")
                           .filter(col('Table Name') == 'Price Indexes For Personal Consumption Expenditures By Major Type Of Product')
                           .filter(col('Indicator Name') == 'Personal consumption expenditures (PCE)')
                           .filter(col('"Frequency"') == 'A')
                           .filter(col('"Date"') >= '1972-01-01'))
   #Select columns, substract 100 from value column to reference baseline
   snow_df_pce_year = snow_df_pce.select(year(col('"Date"')).alias('"Year"'), (col('"Value"')-100).alias('PCE')).sort('"Year"', ascending=False)
   #convert to pandas dataframe
   pd_df_pce_year = snow_df_pce_year.to_pandas()
   #round the PCE series
   pd_df_pce_year["PCE"] = pd_df_pce_year["PCE"].round(2)
    #create metrics
   latest_pce_year = pd_df_pce_year.loc[0]["Year"].astype('int')
   latest_pce_value = pd_df_pce_year.loc[0]["PCE"]
   delta_pce_value = latest_pce_value - pd_df_pce_year.loc[1]["PCE"]

   #Use Snowflake UDF for Model Inference
   snow_df_predict_years = session.create_dataframe([[int(latest_pce_year+1)], [int(latest_pce_year+2)],[int(latest_pce_year+3)]], schema=["Year"])
   pd_df_pce_predictions = snow_df_predict_years.select(col("year"), call_udf("predict_pce_udf", col("year")).as_("pce")).sort(col("year")).to_pandas()
   pd_df_pce_predictions.rename(columns={"YEAR": "Year"}, inplace=True)
   #round the PCE prediction series
   pd_df_pce_predictions["PCE"] = pd_df_pce_predictions["PCE"].round(2).astype(float)-100


   #Combine actual and predictions dataframes
   pd_df_pce_all = (
       pd_df_pce_year.set_index('Year').sort_index().rename(columns={"PCE": "Actual"})
       .append(pd_df_pce_predictions.set_index('Year').sort_index().rename(columns={"PCE": "Prediction"}))
   )


   #Data per quarter
   snow_df_pce_q = (session.table("ECONOMY_DATA_ATLAS.ECONOMY.BEANIPA")
                           .filter(col('Table Name') == 'Price Indexes For Personal Consumption Expenditures By Major Type Of Product')
                           .filter(col('Indicator Name') == 'Personal consumption expenditures (PCE)')
                           .filter(col('"Frequency"') == 'Q')
                           .select(year(col('"Date"')).alias('Year'),
                                   call_builtin("date_part", 'quarter', col('"Date"')).alias('"Quarter"') ,
                                   (col('"Value"')-100).alias('PCE'))
                           .sort('Year', ascending=False))


   # by Major Type Of Product
   snow_df_pce_all = (session.table("ECONOMY_DATA_ATLAS.ECONOMY.BEANIPA")
                       .filter(col('"Table Name"') == 'Price Indexes For Personal Consumption Expenditures By Major Type Of Product')
                       .filter(col('"Indicator Name"') != 'Personal consumption expenditures (PCE)')
                       .filter(col('"Frequency"') == 'A')
                       .filter(col('"Date"') >= '1972-01-01')
                       .select('"Indicator Name"', year(col('"Date"')).alias('Year'), (col('"Value"')-100).alias('PCE') ))
```

### ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è¿½åŠ 

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ä»¥ä¸‹ã‚’è¿½åŠ ã—ã¾ã™ã€‚

1. ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã€‚ã¾ãŸã€ã‚³ãƒ³ãƒ†ãƒŠã¨åˆ—ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ•´ç†ã—ã¾ã™ï¼ˆStreamlitã®_columns()_ã¨_container()_ã‚’ä½¿ç”¨ï¼‰ã€‚
2. Streamlitã®ãƒ¡ãƒˆãƒªãƒƒã‚¯é–¢æ•°ã‚’ä½¿ç”¨ã—ãŸå·®åˆ†ã‚’å«ã‚€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®è¡¨ç¤ºã€‚
3. Streamlitã®selectbox\_()\_ã¨_bar\_chart()_ã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ£’ã‚°ãƒ©ãƒ•ã€‚

```python
   # Add header and a subheader
   st.title("Knoema: Economical Data Atlas")
   st.header("Powered by Snowpark for Python and Snowflake Marketplace | Made with Streamlit")
   st.subheader("Personal consumption expenditures (PCE) over the last 25 years, baseline is 2012")
   # Add an explanation on the PCE Price Index that can be expanded
   with st.expander("What is the Personal Consumption Expenditures Price Index?"):
       st.write("""
        The prices you pay for goods and services change all the time â€“ moving at different rates and even in different directions. Some prices may drop while others are going up. A price index is a way of looking beyond individual price tags to measure overall inflation (or deflation) for a group of goods and services over time.


        The Personal Consumption Expenditures Price Index is a measure of the prices that people living in the United States, or those buying on their behalf, pay for goods and services.The PCE price index is known for capturing inflation (or deflation) across a wide range of consumer expenses and reflecting changes in consumer behavior.
       """)
   # Use columns to display metrics for global value and predictions
   col11, col12, col13 = st.columns(3)
   with st.container():
       with col11:
           st.metric("PCE in " + str(latest_pce_year), round(latest_pce_value), round(delta_pce_value), delta_color=("inverse"))
       with col12:
           st.metric("Predicted PCE for " + str(int(pd_df_pce_predictions.loc[0]["Year"])), round(pd_df_pce_predictions.loc[0]["PCE"]),
               round((pd_df_pce_predictions.loc[0]["PCE"] - latest_pce_value)), delta_color=("inverse"))
       with col13:
           st.metric("Predicted PCE for " + str(int(pd_df_pce_predictions.loc[1]["Year"])), round(pd_df_pce_predictions.loc[1]["PCE"]),
               round((pd_df_pce_predictions.loc[1]["PCE"] - latest_pce_value)), delta_color=("inverse"))

   # Barchart with actual and predicted PCE
   st.bar_chart(data=pd_df_pce_all.tail(25), width=0, height=0, use_container_width=True)

   # Display interactive chart to visualize PCE per quarter and per major type of product.
   with st.container():


       year_selection = st.selectbox('Select year', pd_df_pce_year['Year'].head(25),index=0 )
       pd_df_pce_q = snow_df_pce_q.filter(col('Year') == year_selection).sort(col('"Quarter"')).to_pandas().set_index('Quarter')
       with st.expander("Price Indexes For Personal Consumption Expenditures per Quarter"):
            st.bar_chart(data=pd_df_pce_q['PCE'], width=0, height=500, use_container_width=True)
       pd_df_pce_all = snow_df_pce_all.filter(col('Year') == year_selection).sort(col('"Indicator Name"')).to_pandas().set_index('Indicator Name')
       st.write("Price Indexes For Personal Consumption Expenditures By Major Type Of Product")
       st.bar_chart(data=pd_df_pce_all['PCE'], width=0, height=500, use_container_width=True)
```

ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®1ã¤ã¨ã—ã¦å—ã‘å–ã‚‹Streamlitã®_bar\_chart()_ã‚’ä½¿ç”¨ã—ã¦æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚ã“ã®å ´åˆã€ã“ã‚Œã¯ã€Snowpark DataFrameã®\_filter()\_ã«ã‚ˆã£ã¦æ—¥ä»˜åˆ¥ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸå€‹äººæ¶ˆè²»æ”¯å‡ºï¼ˆPCEï¼‰ç‰©ä¾¡æŒ‡æ•°ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚µãƒ–ã‚»ãƒƒãƒˆï¼ˆ25å¹´é–“ï¼‰ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®MLãƒ¢ãƒ‡ãƒ«ã‚’å«ã‚€Snowflakeãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©é–¢æ•°ã‚’æ´»ç”¨ã—ãŸäºˆæ¸¬PCEå€¤ã‚’çµ„ã¿åˆã‚ã›ãŸã‚‚ã®ã§ã™ã€‚Streamlit \_metric()\_é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ç›´è¿‘ã®PCEå€¤ã‚„ã€æ˜¨å¹´ã¨ã®å·®åˆ†ã‚’å«ã‚€æ¬¡ã®2ã¤ã®äºˆæ¸¬å€¤ãªã©ã®ä¸»è¦ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚

å¹´ã®é¸æŠï¼ˆStreamlit\_ selectbox()_é–¢æ•°ï¼‰ã€é¸æŠã—ãŸå¹´ã®å››åŠæœŸå€¤ã‚’å«ã‚€ãƒãƒ£ãƒ¼ãƒˆã€é¸æŠã—ãŸå¹´ã®ä¸»è¦ãªè£½å“ã‚¿ã‚¤ãƒ—ã®PCEå€¤ã®è©³ç´°ãƒãƒ£ãƒ¼ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šè©³ã—ã„æƒ…å ±ã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚å¹´ã‚’é¸æŠã™ã‚‹ãŸã³ã«ã€Snowflakeã§ã‚¯ã‚¨ãƒªãŒå®Ÿè¡Œã•ã‚Œã€çµæœãŒSnowparkã¨Streamlitã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

<!-- ------------------------ -->
## ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ

Duration: 4

æ¥½ã—ã„ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã«æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚„æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒãªã‘ã‚Œã°ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹æº–å‚™ã¯å®Œäº†ã§ã™ã€‚

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚   
<code>streamlit run my_snowpark_streamlit_app_pce.py</code></strong>ã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã§å®Ÿè¡Œã™ã‚‹ã‹ã€VSã‚³ãƒ¼ãƒ‰ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å®Ÿè¡Œã—ã¾ã™ï¼ˆ<em>my_snowpark_streamlit_app_pce.py</em>ã‚’å®Ÿéš›ã®Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã®åå‰ã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼‰ã€‚

ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚³ãƒãƒ³ãƒ‰<code>conda activate snowpark</code>ã‚’ä½¿ç”¨ã—ã¦ã€ã€Œsnowparkã€Condaç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚</strong>

æ­£ã—ã„Condaç’°å¢ƒã‚’é¸æŠã—ãŸã“ã¨ã‚’ç¤ºã™ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

```sql
(base) user SummitHOL % conda activate snowpark
(snowpark) user SummitHOL %
           
```

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼š

1. ã€Œ+ã€ã§ç¤ºã•ã‚ŒãŸå±•é–‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã§ãã¾ã™ã€‚
2. å¹´ã‚’é¸æŠã™ã‚‹ã¨è©³ç´°æƒ…å ±ã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚
3. å››åŠæœŸã”ã¨ã®PCEå€¤ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æŠ˜ã‚ŠãŸãŸã¾ã‚Œã¦ã„ã¾ã™ã€‚ã€Œ+ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã§ãã¾ã™ã€‚

![alt_text](assets/streamlit-output.png)

