{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "qmwmjzzsortdl6grx2fi",
   "authorId": "1902264014570",
   "authorName": "USER",
   "authorEmail": "",
   "sessionId": "f367bfac-5357-405a-b296-0e3c99767e6f",
   "lastEditTime": 1769179892122
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3afc1f6a-ddaf-48d3-be78-f700b2fa91b7",
   "metadata": {
    "name": "Notebook_intro",
    "collapsed": false
   },
   "source": "## Better Together: Unleash AI-powered BI with Snowflake + Quick Sight \nRefer to the [Quickstart](add github/sfquicks_start link) demostrates the integration between Snowflake and Amazon Quick Sight, showcasing Snowflake's semantic view, a new schema level objects. \n"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "Import_packages",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "554388c0-2e06-45fb-910a-ddfb139e7229",
   "metadata": {
    "language": "sql",
    "name": "Initial_Setup",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- ======================================================\n-- PART 1: Snowflake Setup for semantic view quick start\n-- To get started, we will CREATE a database called MOVIES and schema PUBLIC \n-- warehouse to auto-suspends after 30 mins (1800 seconds)\n-- ======================================================\n\nUSE ROLE ACCOUNTADMIN;\n\n-- Create role for semantic view quick start\nCREATE ROLE IF NOT EXISTS semantic_quick_start_role\nCOMMENT = 'Role for semantic view quick start demo';\n\n-- Set variables\nSET\n    my_user = CURRENT_USER();\n    \n--Grant role to your user \n    GRANT ROLE semantic_quick_start_role TO USER IDENTIFIER($my_user);\n    \n-- create database, schema and warehouse\n    CREATE WAREHOUSE IF NOT EXISTS WORKSHOPWH WITH WAREHOUSE_SIZE = 'XSMALL' AUTO_SUSPEND = 1800 AUTO_RESUME = TRUE COMMENT = 'Warehouse for semantic view quick start demo';\nCREATE DATABASE IF NOT EXISTS movies;\nGRANT OWNERSHIP ON DATABASE movies TO ROLE semantic_quick_start_role COPY CURRENT GRANTS;\nGRANT OWNERSHIP ON SCHEMA movies.PUBLIC TO ROLE semantic_quick_start_role COPY CURRENT GRANTS;\nGRANT OWNERSHIP ON WAREHOUSE workshopwh TO ROLE semantic_quick_start_role COPY CURRENT GRANTS;\n-- Grant privileges to create semantic views\nGRANT CREATE SEMANTIC VIEW ON SCHEMA movies.PUBLIC TO ROLE semantic_quick_start_role;\nGRANT CREATE STAGE ON SCHEMA movies.PUBLIC TO ROLE semantic_quick_start_role;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69948a46-d079-4ed0-8cda-469315f63fd9",
   "metadata": {
    "language": "sql",
    "name": "Verify_DB_Infor",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- =============================================\n-- PART 1: Snowflake Setup for semantic view quick start\n-- =============================================\n\n-- Verify the below information\nSELECT\n  CURRENT_DATABASE() AS current_db,\n  CURRENT_SCHEMA()   AS current_schema,\n  CURRENT_ROLE()     AS current_role,\n  CURRENT_USER() AS current_user;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "Set_Variables",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "-- =============================================\n-- PART 1: Snowflake Setup for semantic view quick start\n-- =============================================\n\n-- Set variables for the specified role, database, and schema\nSET my_role = 'semantic_quick_start_role';\nSET my_db = CURRENT_DATABASE();\nSET my_schema = CURRENT_SCHEMA();\nSET my_full_schema = $my_db || '.' || $my_schema;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dd62143f-aeb8-4c79-941f-724bb4f68e6b",
   "metadata": {
    "language": "sql",
    "name": "Set_Role_DB",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "USE ROLE semantic_quick_start_role;\nUSE DATABASE movies;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a0f083c-d592-4081-8230-8370dcfe27c4",
   "metadata": {
    "language": "sql",
    "name": "Confirm_db_info",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Verify the below information\nSELECT\n  CURRENT_DATABASE() AS current_db,\n  CURRENT_SCHEMA()   AS current_schema,\n  CURRENT_ROLE()     AS current_role,\n  CURRENT_USER() AS current_user;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88d37797-2307-484a-a4f7-6136c9d2ed4e",
   "metadata": {
    "language": "sql",
    "name": "create_tables",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- ==============================================\n-- PART 2: DATA SETUP (as semantic_quick_start_role)\n-- ==============================================\n-- Create Tables\n\n-- create demo table for our movie data.\nCREATE OR REPLACE TABLE movies_raw  (\n    movieid int,\n    title varchar,\n    genres varchar\n);\n\n-- create demo table for our movie rating data.\nCREATE OR REPLACE TABLE ratings_raw (\n    userid int,\n    movieid int,\n    rating float,\n    timestamp timestamp_ntz,\n    firstname varchar,\n    lastname varchar,\n    street varchar,\n    city varchar,\n    state varchar,\n    postcode varchar,\n    country varchar,\n    email varchar,\n    phonenumber varchar\n);\n\n-- create curated tables for our processed data.\nCREATE TABLE movies_curated\n(\n  movieid number,\n  title varchar,\n  release integer\n);\n\nCREATE TABLE genres_curated\n(\n  genresid number autoincrement start 1 increment 1,\n  genres varchar\n);\n\nCREATE TABLE movies_genres_curated\n(\n  genresid number,\n  movieid number\n);\n\nCREATE TABLE ratings_curated\n(\n    userid int,\n    movieid int,\n    rating float,\n    timestamp timestamp_ntz\n);\n\nCREATE TABLE users_curated\n(\n    userid int,\n    firstname varchar,\n    lastname varchar,\n    street varchar,\n    city varchar,\n    state varchar,\n    postcode varchar,\n    country varchar,\n    email varchar,\n    phonenumber varchar\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e15b937-1b18-432a-8613-8c958b38fbf0",
   "metadata": {
    "language": "sql",
    "name": "Load_data_into_movies_raw",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- ==============================================\n-- PART 2: DATA SETUP (as semantic_quick_start_role)\n-- ==============================================\n-- Load data into table\n\n--\n-- Scale up the warehouse to load the data\n--\nALTER WAREHOUSE workshopwh SET WAREHOUSE_SIZE = LARGE;\n\nCREATE OR REPLACE FILE FORMAT movielens_ffmt\n  TYPE = CSV\n  FIELD_DELIMITER = ','\n  SKIP_HEADER = 1\n  FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n  COMPRESSION = gzip;\n\n-- movies data\nCOPY INTO movies_raw\n  FROM s3://jhs-sf-aws-bucket/movies.csv.gz\n  FILE_FORMAT = (FORMAT_NAME = 'movielens_ffmt');\n\nSELECT * FROM movies_raw LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6ce55f44-2777-4d3a-bc6c-7c6460d9e451",
   "metadata": {
    "language": "sql",
    "name": "Verify_movies_loaded",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT count(*) FROM movies_raw;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "520ec154-344f-451c-8391-7d59622e3a39",
   "metadata": {
    "language": "sql",
    "name": "Load_data_Rating_Raw",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "-- ==============================================\n-- PART 2: DATA SETUP (as semantic_quick_start_role) \n-- ==============================================\n-- Load data into table\n\n-- rating data \nCOPY INTO ratings_raw\nFROM s3://jhs-sf-aws-bucket/ratings.csv.gz \nFILE_FORMAT=(FORMAT_NAME = 'movielens_ffmt');\n    \n-- Scale back down the warehouse\nALTER WAREHOUSE workshopwh SET WAREHOUSE_SIZE = SMALL;\n\nSELECT * FROM ratings_raw LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c568528b-8750-4fdf-a1c7-c38bff62e299",
   "metadata": {
    "language": "sql",
    "name": "Verify_data_loaded",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- verify 309,662 records loaded \nselect\n    count(*)\nfrom\n    ratings_raw;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e7c29b5-6b45-477e-8f93-a24dc7b165d4",
   "metadata": {
    "language": "sql",
    "name": "Load_Rating_Curated_Data",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Load raw ratings data into ratings_curated table.\n\n-- ratings_curated\nINSERT INTO ratings_curated (userid, movieid, rating, timestamp)\nSELECT userid, movieid, rating, timestamp\nFROM ratings_raw;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e19121b6-a3e0-41e5-b676-e94c12d05c57",
   "metadata": {
    "language": "sql",
    "name": "Load_User_Curated_Data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- users_curated\nINSERT INTO users_curated(userid, firstname, lastname, street, city, state, postcode, country, email, phonenumber)\nSELECT DISTINCT(userid), firstname, lastname, street, city, state, postcode, country, email, phonenumber\nFROM ratings_raw\nGROUP BY ALL;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "16eda453-8513-4ba7-ad35-6761c71f897f",
   "metadata": {
    "language": "sql",
    "name": "Load_Movie_Curated_Data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Insert the curated movied data\nINSERT INTO  movies_curated\nSELECT movieid,  substr(title,0,regexp_instr(title, '\\([0-9]{4}\\)')-2) as title,\n    regexp_substr(title, '([0-9]{4})') as myear\nFROM movies_raw\nWHERE myear is not null;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aad755de-6c8d-47c4-b268-b1404290f431",
   "metadata": {
    "language": "sql",
    "name": "Test_Rating_Curated_Data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM ratings_curated LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "547d7acc-4d41-4a06-9d00-99215ac93eaf",
   "metadata": {
    "language": "sql",
    "name": "Test_Users_Curated_Data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM users_curated LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "239aced5-771d-44b3-9ef5-c9c0f3e23f3b",
   "metadata": {
    "language": "sql",
    "name": "Test_Movies_Curated_Data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM movies_curated LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82e2496f-9671-48a0-b8ad-e94b75eb6e6b",
   "metadata": {
    "language": "sql",
    "name": "Define_SV",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Define the Semantic View\nCREATE OR REPLACE SEMANTIC VIEW MOVIE_ANALYTICS_SV\nTABLES (\n  MOVIES AS MOVIES.PUBLIC.MOVIES_CURATED\n    PRIMARY KEY (MOVIEID)\n    WITH SYNONYMS ('movies', 'films')\n    COMMENT = 'Movie dimension',\n\n  USERS AS MOVIES.PUBLIC.USERS_CURATED\n    PRIMARY KEY (USERID)\n    WITH SYNONYMS ('users', 'audience', 'viewers')\n    COMMENT = 'User dimension',\n\n  RATINGS AS MOVIES.PUBLIC.RATINGS_CURATED\n    PRIMARY KEY (USERID, MOVIEID)\n    WITH SYNONYMS ('ratings', 'reviews')\n    COMMENT = 'Movie ratings fact'\n)\n\nRELATIONSHIPS (\n  RATINGS_TO_MOVIES AS\n    RATINGS(MOVIEID) REFERENCES MOVIES,\n\n  RATINGS_TO_USERS AS\n    RATINGS(USERID) REFERENCES USERS\n)\n\nFACTS (\n  RATINGS.rating_value AS RATINGS.RATING\n)\n\nDIMENSIONS (\n  -- Movie dimensions\n  MOVIES.movie_title AS MOVIES.TITLE\n    WITH SYNONYMS = ('film title', 'movie name')\n    COMMENT = 'Title of the movie',\n  MOVIES.release_year AS MOVIES.RELEASE\n    COMMENT = 'Year the movie was released',\n\n  -- User dimensions\n  USERS.user_full_name AS CONCAT(USERS.FIRSTNAME, ' ', USERS.LASTNAME)\n    WITH SYNONYMS = ('audience name', 'viewer name')\n    COMMENT = 'Full name of the user',\n  USERS.user_first_name AS USERS.FIRSTNAME\n    COMMENT = 'First name of the user',\n  USERS.user_email AS USERS.EMAIL\n    WITH SYNONYMS = ('email address', 'contact email')\n    COMMENT = 'Email address of the user',\n  USERS.user_last_name AS USERS.LASTNAME\n    COMMENT = 'Last name of the user',\n  USERS.user_city AS USERS.CITY\n    COMMENT = 'City where user is located',\n  USERS.user_state AS USERS.STATE\n    COMMENT = 'State where user is located',\n  USERS.user_country AS USERS.COUNTRY\n    COMMENT = 'Country where user is located',\n\n  -- ID dimensions\n  USERS.user_id AS USERS.USERID\n    COMMENT = 'User ID',\n  MOVIES.movie_id AS MOVIES.MOVIEID\n    COMMENT = 'Movie ID',\n\n  -- Rating timestamp dimensions\n  RATINGS.rating_timestamp AS RATINGS.TIMESTAMP\n    WITH SYNONYMS = ('review date', 'rating date')\n    COMMENT = 'When the rating was given',\n  RATINGS.rating_year AS YEAR(RATINGS.TIMESTAMP)\n    WITH SYNONYMS = ('review year', 'year rated')\n    COMMENT = 'Year when the rating was given',\n  RATINGS.rating_month AS MONTH(RATINGS.TIMESTAMP)\n    WITH SYNONYMS = ('review month', 'month rated')\n    COMMENT = 'Month when the rating was given',\n  RATINGS.rating_day AS DAY(RATINGS.TIMESTAMP)\n    WITH SYNONYMS = ('review day', 'day rated')\n    COMMENT = 'Day when the rating was given',\n\n  -- Rating ID dimensions\n  RATINGS.user_id AS RATINGS.USERID\n    COMMENT = 'User ID from ratings table',\n  RATINGS.movie_id AS RATINGS.MOVIEID\n    COMMENT = 'Movie ID from ratings table'\n)\n\nMETRICS (\n  RATINGS.total_ratings AS COUNT(RATINGS.rating_value)\n    WITH SYNONYMS = ('total reviews', 'rating count', 'number of ratings')\n    COMMENT = 'Count of all rating values in the ratings table',\n\n  RATINGS.avg_rating AS AVG(RATINGS.rating_value)\n    WITH SYNONYMS = ('average rating', 'mean score', 'rating average')\n    COMMENT = 'Average of all rating values in the ratings table',\n\n  USERS.distinct_users AS COUNT(DISTINCT USERS.user_id)\n    WITH SYNONYMS = ('total users', 'user count', 'number of users')\n    COMMENT = 'Count of distinct user IDs from the users table',\n\n  MOVIES.distinct_movies AS COUNT(DISTINCT MOVIES.movie_id)\n    WITH SYNONYMS = ('total movies', 'movie count', 'number of movies')\n    COMMENT = 'Count of distinct movie IDs from the movies table',\n\n  RATINGS.distinct_users AS COUNT(DISTINCT RATINGS.user_id)\n    WITH SYNONYMS = ('active users', 'users who rated', 'rating participants')\n    COMMENT = 'Count of distinct user IDs from the ratings table',\n\n  RATINGS.distinct_movies AS COUNT(DISTINCT RATINGS.movie_id)\n    WITH SYNONYMS = ('rated movies', 'movies with ratings', 'reviewed films')\n    COMMENT = 'Count of distinct movie IDs from the ratings table',\n\n  RATINGS.popularity_score AS RATINGS.total_ratings * RATINGS.avg_rating\n    WITH SYNONYMS = ('movie popularity', 'engagement score', 'quality index')\n    COMMENT = 'Popularity score combining volume and quality'\n)\n\n--FILTER (\n -- recent_ratings AS RATINGS.rating_timestamp >= DATEADD(year, -1, CURRENT_TIMESTAMP())\n --   COMMENT = 'Ratings submitted in the last year',\n\n -- high_ratings AS RATINGS.rating_value >= 4\n --   COMMENT = 'Ratings with score 4 or higher'\n--)\n\nCOMMENT = 'Semantic view for movie ratings and user behavior analytics, including time-grain dimensions and popularity score';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f21fff7-55fa-4fcc-a62f-2e1eaf1a6471",
   "metadata": {
    "language": "sql",
    "name": "Verify_semantic_view_creation",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SHOW semantic views;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "033aa0b1-3ec0-4431-9798-d890a5d348be",
   "metadata": {
    "language": "sql",
    "name": "Test_SV_1",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- 1. Top movies by release year\nSELECT * FROM SEMANTIC_VIEW (\n  MOVIE_ANALYTICS_SV\n  DIMENSIONS MOVIES.release_year, MOVIES.movie_title\n  METRICS RATINGS.total_ratings, RATINGS.avg_rating\n)\nWHERE release_year >= 2020 AND release_year <=2026\nORDER BY total_ratings DESC;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5df05395-e19c-40f7-ad18-fb080627d8f1",
   "metadata": {
    "language": "sql",
    "name": "Test_SV_2",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- 2. Highly rated movies released after 2015\nSELECT * FROM SEMANTIC_VIEW (\n  MOVIE_ANALYTICS_SV\n  DIMENSIONS MOVIES.movie_title, MOVIES.release_year\n  METRICS RATINGS.avg_rating, RATINGS.total_ratings\n)\nWHERE release_year > 2015 \n  AND avg_rating >= 4.0\nORDER BY avg_rating DESC;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "988487a9-9422-408f-ad3a-22a1b5372663",
   "metadata": {
    "language": "sql",
    "name": "Test_SV_3",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- 3. Countries with the highest average ratings\nSELECT * FROM SEMANTIC_VIEW (\n  MOVIE_ANALYTICS_SV\n  DIMENSIONS USERS.user_country\n  METRICS RATINGS.avg_rating, RATINGS.total_ratings\n)\nORDER BY avg_rating DESC;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a632e5d5-9434-4fd3-a449-70884766c5d2",
   "metadata": {
    "language": "sql",
    "name": "DESC_SV",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Describe semantic view and save to dataframe\n\nDESCRIBE SEMANTIC VIEW MOVIE_ANALYTICS_SV",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a13aaa4-7cfd-49d8-90aa-1818298ccee2",
   "metadata": {
    "language": "python",
    "name": "sv_dataframe_cell",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Convert semantic view description to pandas dataframe\nfrom snowflake.snowpark import Session\nsv_metadata_df = get_active_session().sql(\"DESCRIBE SEMANTIC VIEW MOVIE_ANALYTICS_SV\").to_pandas()\nprint(f\"Semantic view metadata shape: {sv_metadata_df.shape}\")\nprint(\"\\nFirst 5 rows:\")\nprint(sv_metadata_df.head())\n\n# Save to CSV if needed\n# sv_metadata_df.to_csv('movie_analytics_sv_metadata.csv', index=False)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a351af2f-80c9-448d-8b7d-e5188176bac1",
   "metadata": {
    "language": "sql",
    "name": "Get_SV_DDL",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT TO_VARCHAR( GET_DDL(\n  'SEMANTIC_VIEW',\n  'MOVIES.PUBLIC.MOVIE_ANALYTICS_SV'\n));\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b1d3db20-6212-434a-89e9-6d86d029f0e0",
   "metadata": {
    "name": "Download_the_above_output_as_csv",
    "collapsed": false
   },
   "source": "## Click download button â¬‡ï¸ (top right corner of the output of the above cell) to ðŸ’¾ DOWNLOAD (the DDL) AS CSV file. "
  },
  {
   "cell_type": "code",
   "id": "3f614e9e-2b8c-4fe1-9bd4-36b4ba661819",
   "metadata": {
    "language": "python",
    "name": "Get_SV_DDL_to_df",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nsv_ddl_df = get_active_session().sql(\"SELECT TO_VARCHAR(GET_DDL('SEMANTIC_VIEW','MOVIES.PUBLIC.MOVIE_ANALYTICS_SV'))\").to_pandas()\n\nprint(sv_ddl_df.head())\n\n# Save to CSV if needed\nsv_ddl_df.to_csv('movie_analytics_sv_ddl.csv', index=False)\n\n\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4bde04ac-30d2-4ffe-b333-0e46d35de72b",
   "metadata": {
    "name": "Snowflake_side_completed",
    "collapsed": false
   },
   "source": "This completes the Snowflake's object creation and data load, semantic view.\n\nWe will move on to the AWS side configuration"
  },
  {
   "cell_type": "markdown",
   "id": "3799183d-1622-49ec-abed-d1f4c5417a8f",
   "metadata": {
    "name": "Quick_Suite_Guide",
    "collapsed": false
   },
   "source": "# QuickSight Dataset Generator - Complete End-to-End Guide\n\n## Overview\nThis guide walks you through the complete process of creating QuickSight datasets from Snowflake DDL, from setting up credentials to sharing datasets with users.\n\n## Complete Workflow\n\n```\n0. Open AWS console --> cloudshell --> Upload the zip\n   â†“\n1. Create AWS Secret (Snowflake credentials)\n   â†“\n2. Create QuickSight Data Source (using secret)\n   â†“\n3. Generate QuickSight Schema (from Snowflake DDL)\n   â†“\n4. Create Dataset (from generated schema)\n   â†“\n5. Start SPICE Ingestion (load data)\n   â†“\n6. Share Dataset (with users)\n  â†“\n7. From Quick Suite console, create Q topic or Dashboard\n```\n\n---\n\n## Prerequisites\n\n### Required Software\n- Python 3.x with boto3 installed\n- AWS CLI configured\n- Access to Snowflake account\n\n### Required Permissions\n- AWS Secrets Manager: Create/Update secrets\n- QuickSight: Create data sources and datasets\n- IAM: Get caller identity\n\n### Required Information\n- Snowflake account identifier\n- Snowflake database name\n- Snowflake warehouse name\n- Snowflake username and password\n- QuickSight user to share with\n\n---\n## Step 0: Prepare the environment\n\n1. Open AWS console\n\n2. Click the top menu button to open cloudshell\n\n3. Upload the zip \n\n4. Unzip the zip \n```bash\nunzip Solution_Package.zip\n```\n\n5. Go to the folder Solution_Package\n```bash\ncd Solution_Package\n```\n\n6. Upload the DDL.csv downloaded from last step\n\n---\n\n## Step 1: Create AWS Secret for Snowflake Credentials\n\nStore your Snowflake credentials securely in AWS Secrets Manager.\n\n### Option A: Using Python Script \n\n```bash\npython create_secret.py \\\n  --secret-name snowflake-credentials \\\n  --account YOUR_SNOWFLAKE_ACCOUNT \\\n  --database MOVIES \\\n  --warehouse WORKSHOPWH \\\n  --user YOUR_USERNAME \\\n  --password YOUR_PASSWORD \\\n  --region us-east-1 \\\n```\n\n### Option B: Using Interactive Shell Script (Recommended)\n\n```bash\n./setup_secrets.sh\n```\n\nThe script will prompt you for:\n- Snowflake account identifier\n- Database name (default: MOVIES)\n- Warehouse name (default: WORKSHOPWH)\n- Username\n- Password\n- AWS region (default: us-east-1)\n- Secret name (default: snowflake-credentials)\n\n### Verify Secret Creation\n\n```bash\naws secretsmanager get-secret-value \\\n  --secret-id snowflake-credentials \\\n  --region us-east-1 \\\n```\n\n### Expected Secret Format\n\n```json\n{\n  \"account\": \"your-account.us-east-1\",\n  \"database\": \"MOVIES\",\n  \"warehouse\": \"WORKSHOPWH\",\n  \"user\": \"your_username\",\n  \"password\": \"your_password\"\n}\n```\n\n---\n\n## Step 2: Create QuickSight Data Source\n\nCreate a QuickSight data source that connects to Snowflake using the credentials from Secrets Manager.\n\n### Command\n\n```bash\npython create_snowflake_datasource.py \\\n  --datasource-id movies-snowflake-datasource \\\n  --datasource-name \"Movies Snowflake Data Source\" \\\n  --secret-name snowflake-credentials \\\n  --region us-east-1 \\\n```\n\n### Parameters\n\n| Parameter | Required | Default | Description |\n|-----------|----------|---------|-------------|\n| --datasource-id | No | movies-snowflake-datasource | QuickSight data source ID |\n| --datasource-name | No | Movies Snowflake Data Source | Display name |\n| --secret-name | Yes | - | AWS Secrets Manager secret name |\n| --region | No | us-east-1 | AWS region |\n| --profile | No | default | AWS profile name |\n| --no-delete | No | False | Keep existing data source |\n\n### Expected Output\n\n```\nUsing AWS Account ID: your-account\nRegion: us-east-1\n\nRetrieving Snowflake credentials from secret: snowflake-credentials\n  âœ“ Snowflake Account: your-account.us-east-1\n  âœ“ Database: MOVIES\n  âœ“ Warehouse: WORKSHOPWH\n  âœ“ User: your_username\n\nCreating Snowflake data source: Movies Snowflake Data Source\n\n============================================================\nâœ“ Data Source Created Successfully!\n============================================================\n\nData Source Details:\n  ID: movies-snowflake-datasource\n  ARN: arn:aws:quicksight:us-east-1:your-account:datasource/movies-snowflake-datasource\n  Status: 200\n  Creation Status: CREATION_SUCCESSFUL\n```\n\n### Verify Data Source\n\n```bash\naws quicksight describe-data-source \\\n  --aws-account-id YOUR_ACCOUNT_ID \\\n  --data-source-id movies-snowflake-datasource \\\n  --region us-east-1 \\\n```\n\n---\n\n## Step 3: Generate QuickSight Schema from Snowflake DDL\n\nConvert your Snowflake Semantic View DDL (exported to CSV) into a complete QuickSight dataset schema.\n\n### Command\n\n```bash\npython generate_quicksight_schema_v2.py \\\n  --csv-path SF_DDL.csv \\\n  --datasource-arn \"arn:aws:quicksight:us-east-1:ACCOUNT_ID:datasource/movies-snowflake-datasource\" \\\n  --database MOVIES \\\n  --dataset-id movie-analytics-dataset \\\n  --dataset-name \"Movie Analytics Dataset\" \\\n  --output quicksight_schema_complete.json\n```\n\n### Parameters\n\n| Parameter | Required | Default | Description |\n|-----------|----------|---------|-------------|\n| --csv-path | No | ../SF_DDL.csv | Path to Snowflake DDL CSV file |\n| --datasource-arn | Yes | - | QuickSight data source ARN |\n| --database | No | MOVIES | Snowflake database name |\n| --dataset-id | No | movie-analytics-dataset | QuickSight dataset ID |\n| --dataset-name | No | Movie Analytics Dataset | Dataset display name |\n| --output | No | quicksight_schema_complete.json | Output file path |\n\n### Expected Output\n\n```\nParsing Snowflake DDL from: SF_DDL.csv\nFound 3 tables\nFound 2 relationships\nFound 17 dimensions\nFound 1 facts\nFound 7 metrics\n\nGenerating complete QuickSight dataset schema...\n\nComplete schema saved to: quicksight_schema_complete.json\n\nThis schema includes:\n  âœ“ All 3 physical tables (MOVIES, USERS, RATINGS)\n  âœ“ Logical tables with joins\n  âœ“ Column renames based on DDL aliases\n  âœ“ Type casts (IDs to STRING)\n  âœ“ Calculated fields (USER_FULL_NAME, 7 metrics)\n  âœ“ Column descriptions from DDL comments\n```\n\n### What Gets Generated\n\nThe schema includes:\n\n**Physical Tables (3)**\n- RATINGS_CURATED (fact table)\n- MOVIES_CURATED (dimension table)\n- USERS_CURATED (dimension table)\n\n**Transformations**\n- Column renames (e.g., TITLE â†’ MOVIE_TITLE)\n- Type casts (IDs to STRING)\n- Table joins (RATINGS â†’ MOVIES â†’ USERS)\n- USER_ prefix on all user columns\n\n**Calculated Fields (8)**\n1. USER_FULL_NAME\n2. MOVIES_DISTINCT_MOVIES\n3. USERS_DISTINCT_USERS\n4. RATINGS_TOTAL_RATINGS\n5. RATINGS_AVG_RATING\n6. RATINGS_DISTINCT_USERS\n7. RATINGS_DISTINCT_MOVIES\n8. RATINGS_POPULARITY_SCORE\n\n---\n\n## Step 4: Create Dataset and Start Ingestion\n\nCreate the QuickSight dataset from the generated schema and start loading data into SPICE.\n\n### Option A: Create Dataset Without Sharing\n\n```bash\npython test_complete_schema.py \\\n  --region us-east-1\n```\n\n### Option B: Create Dataset and Share with User (Recommended)\n\n```bash\npython test_complete_schema.py \\\n  --region us-east-1 \\\n  --share-with \"user-name\"\n```\n\n### Parameters\n\n| Parameter | Required | Default | Description |\n|-----------|----------|---------|-------------|\n| --profile | No | default | AWS profile name |\n| --region | No | us-east-1 | AWS region |\n| --share-with | No | - | Username to share with (format: namespace/username) |\n\n### Expected Output\n\n```\nAccount: your-account\nDataset ID: movie-analytics-dataset\nNo existing dataset\nâœ“ Dataset created: movie-analytics-dataset\nâœ“ Status: 201\nâœ“ Ingestion started: ingestion-id\nâœ“ Dataset shared with: user-name\n  User ARN: arn:aws:quicksight:us-east-1:your-account:user/default/user-name\n```\n\n---\n\n## Step 5: Monitor SPICE Ingestion\n\nCheck the status of data loading into SPICE.\n\n### Check Ingestion Status\n\n```bash\naws quicksight describe-ingestion \\\n  --aws-account-id YOUR_ACCOUNT_ID \\\n  --data-set-id movie-analytics-dataset \\\n  --ingestion-id INGESTION_ID \\\n  --region us-east-1 \\\n```\n\n### Expected Statuses\n\n- `INITIALIZED` - Ingestion is starting\n- `QUEUED` - Waiting to start\n- `RUNNING` - Currently loading data\n- `COMPLETED` - Successfully loaded\n- `FAILED` - Error occurred\n\n### Successful Ingestion Output\n\n```json\n{\n  \"IngestionStatus\": \"COMPLETED\",\n  \"RowInfo\": {\n    \"RowsIngested\": 378436,\n    \"RowsDropped\": 0,\n    \"TotalRowsInDataset\": 378436\n  },\n  \"ErrorInfo\": {}\n}\n```\n\n---\n\n## Step 6: Verify Dataset and Permissions\n\n### Check Dataset Details\n\n```bash\naws quicksight describe-data-set \\\n  --aws-account-id YOUR_ACCOUNT_ID \\\n  --data-set-id movie-analytics-dataset \\\n  --region us-east-1 \\\n```\n\n### Check Dataset Permissions\n\n```bash\naws quicksight describe-data-set-permissions \\\n  --aws-account-id YOUR_ACCOUNT_ID \\\n  --data-set-id movie-analytics-dataset \\\n  --region us-east-1 \\\n```\n\n### Verify Output Columns\n\n```bash\naws quicksight describe-data-set \\\n  --aws-account-id YOUR_ACCOUNT_ID \\\n  --data-set-id movie-analytics-dataset \\\n  --region us-east-1 \\\n  --query 'DataSet.OutputColumns[].Name'\n```\n\nExpected: 23 columns including all user columns with USER_ prefix and 7 metric calculated fields.\n\n---\n\n## Dataset Permissions Granted\n\nWhen sharing a dataset with `--share-with`, the following **full permissions** are granted:\n\n| Permission | Description |\n|------------|-------------|\n| UpdateDataSetPermissions | Manage who can access the dataset |\n| DescribeDataSet | View dataset details and schema |\n| DescribeDataSetPermissions | View current permissions |\n| PassDataSet | Use dataset in analyses and dashboards |\n| DescribeIngestion | View ingestion status and details |\n| ListIngestions | List all data refresh operations |\n| UpdateDataSet | Modify dataset configuration |\n| DeleteDataSet | Delete the dataset |\n| CreateIngestion | Start new data refresh |\n| CancelIngestion | Cancel running data refresh |\n\n**Total: 10 permissions** - Full control over the dataset\n\nThese permissions give the user complete control over the dataset including the ability to modify, delete, and manage permissions.\n\n---\n\n---\n\n## [Optional] Finding QuickSight Users to Share With\n\n### List All Namespaces\n\n```bash\naws quicksight list-namespaces \\\n  --aws-account-id YOUR_ACCOUNT_ID \\\n  --region us-east-1 \\\n```\n\n### List Users in Default Namespace\n\n```bash\naws quicksight list-users \\\n  --aws-account-id YOUR_ACCOUNT_ID \\\n  --namespace default \\\n  --region us-east-1 \\\n  --query 'UserList[].UserName'\n```\n\n### Username Formats\n\n| Format | Example | Use Case |\n|--------|---------|----------|\n| Simple | `reader1` | Simple QuickSight users |\n| Federated | `quicksight-fed-us-users/email@domain.com` | Federated identity users |\n\n---\n\n## Troubleshooting\n\n### Secret Creation Issues\n\n**Error: Access Denied**\n- Check IAM permissions for Secrets Manager\n- Ensure you have `secretsmanager:CreateSecret` and `secretsmanager:UpdateSecret` permissions\n\n**Error: Secret already exists**\n- Use `--no-delete` flag or delete the existing secret first\n- Or update the existing secret using the same command\n\n### Data Source Creation Issues\n\n**Error: Invalid credentials**\n- Verify Snowflake credentials in the secret\n- Test Snowflake connection manually\n- Check Snowflake account identifier format\n\n**Error: Warehouse not found**\n- Verify warehouse name in Snowflake\n- Ensure warehouse is running\n- Check user has access to the warehouse\n\n### Schema Generation Issues\n\n**Error: CSV file not found**\n- Check the path to SF_DDL.csv\n- Ensure the file exists and is readable\n\n**Error: No tables found**\n- Verify the DDL CSV format\n- Check that the DDL contains table definitions\n\n### Dataset Creation Issues\n\n**Error: Data source not found**\n- Verify the data source ARN is correct\n- Check that the data source was created successfully\n- Ensure you're using the correct AWS account and region\n\n**Error: Field does not exist**\n- This means a calculated field references a column not in ProjectedColumns\n- Check the generated schema for column names\n- Verify all referenced columns exist after transformations\n\n### Ingestion Issues\n\n**Status: FAILED**\n- Check Snowflake connection credentials\n- Verify data source permissions\n- Review ingestion error details using `describe-ingestion`\n- Check Snowflake query history for errors\n\n**Status: QUEUED for long time**\n- Check SPICE capacity limits\n- Verify no other ingestions are running\n- Check QuickSight service status\n\n### Sharing Issues\n\n**Error: Namespace not found**\n- Use `default` namespace for most users\n- Check available namespaces with `list-namespaces`\n\n**Error: User not found**\n- Verify username with `list-users`\n- Check the username format matches exactly\n- Ensure user exists in the correct namespace\n\n---\n\n## Next Steps After Dataset Creation\n\n### 1. Build Analyses\nUse QuickSight Analysis to create visualizations:\n- Create charts and graphs\n- Add filters and parameters\n- Build interactive dashboards\n\n### 2. Create Dashboards\nPublish analyses as dashboards:\n- Share with broader audience\n- Set up email reports\n- Configure refresh schedules\n\n### 3. Schedule Data Refreshes\nSet up automatic SPICE refresh:\n```bash\naws quicksight create-ingestion \\\n  --aws-account-id YOUR_ACCOUNT_ID \\\n  --data-set-id movie-analytics-dataset-v2 \\\n  --ingestion-id \"scheduled-$(date +%s)\" \\\n  --ingestion-type FULL_REFRESH\n```\n\n### 4. Monitor Usage\nTrack dataset usage and performance:\n- Review SPICE capacity consumption\n- Monitor query performance\n- Check user access patterns\n\n---\n\n## Additional Resources\n\n### AWS Documentation\n- [QuickSight User Guide](https://docs.aws.amazon.com/quicksight/)\n- [Secrets Manager User Guide](https://docs.aws.amazon.com/secretsmanager/)\n- [Boto3 QuickSight Reference](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/quicksight.html)\n\n### Snowflake Documentation\n- [Snowflake Semantic Views](https://docs.snowflake.com/en/user-guide/semantic-views)\n- [Snowflake DDL Reference](https://docs.snowflake.com/en/sql-reference/ddl-database)\n\n### Script Files\n- `create_secret.py` - Create AWS Secrets Manager secret\n- `create_snowflake_datasource.py` - Create QuickSight data source\n- `generate_quicksight_schema_v2.py` - Generate dataset schema\n- `test_complete_schema.py` - Create dataset and share\n- `setup_secrets.sh` - Interactive secret creation\n\n---\n\n## Quick Reference Commands\n\n```bash\n# Create secret\npython create_secret.py --secret-name NAME --account ACCOUNT --user USER --password PASS\n\n# Create data source\npython create_snowflake_datasource.py --secret-name NAME\n\n# Generate schema\npython generate_quicksight_schema_v2.py --csv-path DDL.csv --datasource-arn ARN\n\n# Create and share dataset\npython test_complete_schema.py --share-with \"Administrator/username\"\n\n# Check ingestion\naws quicksight describe-ingestion --aws-account-id ID --data-set-id DATASET --ingestion-id ING\n\n# List users\naws quicksight list-users --aws-account-id ID --namespace default\n```\n"
  }
 ]
}