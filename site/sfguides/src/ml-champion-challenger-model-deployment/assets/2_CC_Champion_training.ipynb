{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "xxc76tdnmwpaiczmdzlo",
   "authorId": "1282256439461",
   "authorName": "ADMIN",
   "authorEmail": "sheena.nasim@snowflake.com",
   "sessionId": "fbbc54c3-de7e-40c8-9b26-e2db24324a0c",
   "lastEditTime": 1758946591284
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bc18d4-9487-4887-b886-9d59d1624bcf",
   "metadata": {
    "name": "Intro",
    "collapsed": false
   },
   "source": "# üèÜ Champion Model Training\n\n## Overview\nThis section covers the **initial champion model training** phase of our Champion-Challenger MLOps framework. The champion model serves as the baseline production model that all future challenger models will compete against.\n\n## Process\n1. **Model Development**: Train and validate multiple model candidates using historical data\n2. **Model Selection**: Compare performance metrics (AUC, precision, recall) to identify the best performer\n3. **Champion Registration**: Deploy the selected model to Snowflake ML Registry with the `CHAMPION` alias\n4. **Production Deployment**: The champion model becomes the active production model serving predictions\n\n*üìù Note: This is a one-time setup. Subsequent model updates will be handled automatically by the challenger training pipeline.*"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "Imports"
   },
   "source": "# Import python packages\nfrom sklearn import pipeline, preprocessing, ensemble, metrics\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import type_hints\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f241327b-6f9b-4459-acc2-9026a7b7aa3c",
   "metadata": {
    "language": "python",
    "name": "Set_up"
   },
   "outputs": [],
   "source": "# Set up the database, schema and model registry\ndatabase_name='DEV_AUTOMATION_DEMO'\nschema_name='CHAMPION_CHALLENGER'\nsession.use_database(database_name)\nsession.use_schema(schema_name)  \n\n# Initialize registry\nregistry = Registry(session=session, \n                           database_name=database_name, \n                           schema_name=schema_name)  \nprint(f\"‚úÖ Environment ready: {database_name}.{schema_name}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0a116e63-cd5e-4e57-9aa6-358d5f6a93bd",
   "metadata": {
    "name": "Dataset",
    "collapsed": false
   },
   "source": "# üìä Load Dataset\n\n## Data Source\nThe synthetic credit approval dataset has been pre-generated and saved to the **`full_data`** table for consistent use across experiments. This ensures reproducibility and eliminates the need to regenerate the dataset for each model training run.\n"
  },
  {
   "cell_type": "code",
   "id": "9a29205a-0046-443b-a1eb-108f6eb7e67d",
   "metadata": {
    "language": "python",
    "name": "Load_data"
   },
   "outputs": [],
   "source": "full_dataset = session.table('full_data').to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c4a7fdda-f960-4826-ace0-178644c4cca1",
   "metadata": {
    "name": "Data_Split_Info",
    "collapsed": false
   },
   "source": "### üìã **Detailed Breakdown Of Data Split For Champion:**\n\n1. **TRAIN Period**: Weeks 0-9 (10 weeks) = 4,000 samples\n2. **TEST Period**: Weeks 10-12 (3 weeks) = 1,200 samples  "
  },
  {
   "cell_type": "code",
   "id": "fa519ddb-4cd4-431f-9630-5789990b4ef0",
   "metadata": {
    "language": "python",
    "name": "Data_split"
   },
   "outputs": [],
   "source": "def create_time_splits(full_dataset, train_weeks=10, test_weeks=3):\n        \"\"\"\n        Create proper time-based train/test splits\n        This ensures no data leakage and realistic business scenario\n        \"\"\"\n        print(f\"‚úÇÔ∏è Creating time-based splits: {train_weeks}w train, {test_weeks}w test\")\n        \n        # Initial training data (first 10 weeks)\n        train_mask = full_dataset['week_number'] < train_weeks\n        train_data = full_dataset[train_mask].copy()\n        \n        # Test data (weeks 10-12)\n        test_mask = (full_dataset['week_number'] >= train_weeks) & \\\n                   (full_dataset['week_number'] < train_weeks + test_weeks)\n        test_data = full_dataset[test_mask].copy()\n        \n        # Feature columns (exclude date, week, and target)\n        feature_cols = [col for col in full_dataset.columns \n                           if col not in ['application_date', 'week_number', 'approved']]\n        \n        print(f\"   üìä Train: {len(train_data):,} samples (weeks 0-{train_weeks-1})\")\n        print(f\"   üìä Test: {len(test_data):,} samples (weeks {train_weeks}-{train_weeks+test_weeks-1})\")  \n        \n        return train_data, test_data, feature_cols\n    \n# Get the data\ntrain_data, test_data, feature_cols = create_time_splits(full_dataset)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6fb38280-dc8a-470a-9298-62f5db549ea5",
   "metadata": {
    "language": "python",
    "name": "Train_champion"
   },
   "outputs": [],
   "source": "def train_champion_model(train_data, test_data):\n        \"\"\"Train the initial Champion model\"\"\"\n        print(\"üèÜ Training Initial Champion Model...\")\n        \n        X_train = train_data[feature_cols]\n        y_train = train_data['approved']\n        \n        # Create champion pipeline\n        champion_pipeline = pipeline.Pipeline([\n            ('scaler', preprocessing.StandardScaler()),\n            ('classifier', ensemble.RandomForestClassifier(\n                n_estimators=100,\n                random_state=42,\n                max_depth=10,\n                min_samples_split=5,\n                class_weight='balanced'\n            ))\n        ])\n        \n        # Train champion\n        champion_pipeline.fit(X_train, y_train)\n        \n        # Evaluate on validation set\n        X_test = test_data[feature_cols]\n        y_test = test_data['approved']\n        \n        champion_pred_proba = champion_pipeline.predict_proba(X_test)[:, 1]\n        champion_auc = round(metrics.roc_auc_score(y_test, champion_pred_proba) * 100.0, 2)\n        \n        print(f\"   ‚úÖ Champion trained successfully\")\n        print(f\"   üìà Test data AUC: {champion_auc:.2f}\")\n        \n        # Register champion in model registry\n        sample_input = X_train.head(100)\n        model_name=\"CREDIT_APPROVAL\"\n\n        #Log the model into Snowflake model registry\n        champion_ref = registry.log_model(\n            model=champion_pipeline,\n            model_name=model_name,\n            sample_input_data=sample_input,\n            target_platforms=[\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n            comment=f\"Champion model trained on weeks 0-9, AUC: {champion_auc:.2f}\",\n            metrics={\n                \"test_auc\": champion_auc,\n                \"train_weeks\": \"0-9\",\n                \"model_type\": \"champion\",\n                \"training_samples\": len(X_train)\n            },\n            task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION\n        )\n\n        try:\n            champion_ref.unset_alias(\"CHAMPION\")\n        except:\n            pass\n        # Set as CHAMPION alias\n        champion_ref.set_alias(\"CHAMPION\")\n        model = registry.get_model(model_name)\n        model.set_tag(\"LIVE_VERSION\", champion_ref.version_name)\n        \n        print(f\"   üè∑Ô∏è Champion registered: {champion_ref.version_name}\")\n        print(f\"   üè∑Ô∏è Aliases: CHAMPION\")\n        \n        return",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9da3179f-0efa-42d4-832d-65b33e9d9083",
   "metadata": {
    "language": "python",
    "name": "Training_function"
   },
   "outputs": [],
   "source": "train_champion_model(train_data, test_data)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a0b06198-5064-4c3b-8a0c-834699199c8e",
   "metadata": {
    "name": "Inference",
    "collapsed": false
   },
   "source": "# Inference"
  },
  {
   "cell_type": "code",
   "id": "bc6f2449-ee39-4e77-90a7-434ced691789",
   "metadata": {
    "language": "python",
    "name": "Inference_call"
   },
   "outputs": [],
   "source": "#Get the model\nmodel = registry.get_model(\"CREDIT_APPROVAL\")\nlive_version = model.get_tag(\"live_version\")\nprint(f'Current live model version name in Prod is ',live_version)\n\n#Run prediction function\nremote_prediction = model.version(live_version).run(test_data, function_name=\"predict\")\nremote_prediction = remote_prediction.rename(columns={'output_feature_0': 'predicted_values'})\nremote_prediction.head()",
   "execution_count": null
  }
 ]
}