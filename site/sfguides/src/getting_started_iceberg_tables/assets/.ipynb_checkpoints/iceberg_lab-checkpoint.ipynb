{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1680d4b-49a6-4c8e-9a63-dba8c0d920a2",
   "metadata": {},
   "source": [
    "# Locate Spark in Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df6598-a793-4ec1-b5bb-8bd1fc7aaec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b6134-ec0c-4a5c-83fd-fe16e9b7b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SPARK_HOME'] = '/<your path>/anaconda3/envs/iceberg-lab/lib/python3.11/site-packages/pyspark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dd9f6-be83-47d2-836c-a077787a3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a2b8a-0992-48c3-b587-947f99d63127",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf7810-3e52-4b42-913f-ff5c9fb888d4",
   "metadata": {},
   "source": [
    "### Environment variables for all clouds\n",
    "Regardless which cloud your Snowflake account is in, set the following environment variables replacing values with those of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472aae4-9776-4eba-9872-e7701c73bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SNOWFLAKE_CATALOG_URI'] = \"jdbc:snowflake://<your snowflake account locator>.snowflakecomputing.com\"\n",
    "os.environ['SNOWFLAKE_ROLE'] = \"ICEBERG_LAB\"\n",
    "os.environ['SNOWFLAKE_USERNAME'] = \"ICEBERG_LAB\"\n",
    "os.environ['SNOWFLAKE_PASSWORD'] = \"<your password>\"\n",
    "os.environ['PRIVATE_KEY_FILE'] = \"/<your path>/rsa_key.p8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dbbe7c-0bef-429d-8ff2-5a46ad83e01a",
   "metadata": {},
   "source": [
    "### Environment variables for AWS\n",
    "If your Snowflake account and object storage are on AWS, set these additional environment variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcab866-9cd3-4914-b2db-c001ed1c2e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PACKAGES'] = \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.1,net.snowflake:snowflake-jdbc:3.14.2,software.amazon.awssdk:bundle:2.20.160,software.amazon.awssdk:url-connection-client:2.20.160\"\n",
    "os.environ['AWS_REGION'] = \"<your aws region>\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = \"<your aws access key>\"\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"<your aws secret access key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03371f3-f557-4338-9dad-623a6b7621af",
   "metadata": {},
   "source": [
    "### Environment variables for Azure\n",
    "If your Snowflake account and object storage are on Azure, set these additional environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14183891-438b-411e-8f0f-7225231ae18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PACKAGES'] = \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.1,net.snowflake:snowflake-jdbc:3.14.2,com.microsoft.azure:azure-storage:8.6.6,org.apache.hadoop:hadoop-azure:3.3.6\"\n",
    "os.environ['AZURE_ACCESS_KEY'] = \"<your storage account access key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f3f9d-2eed-4d84-8892-840188f93c91",
   "metadata": {},
   "source": [
    "### Environment variables for GCP\n",
    "If your Snowflake account and object storage are on Google Cloud, set these additional environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c369b-7c54-4a2f-9dfa-0b4bfc0ebcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PACKAGES'] = \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.1,net.snowflake:snowflake-jdbc:3.14.2,com.google.cloud:google-cloud-storage:2.29.1,org.apache.iceberg:iceberg-gcp:1.4.2\"\n",
    "os.environ['spark.hadoop.fs.gs.project.id'] = \"<your project ID>\"\n",
    "os.environ['spark.hadoop.fs.gs.auth.service.account.json.keyfile'] = \"<path to your JSON keyfile>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce62921-cc0d-41aa-b3d5-04f640f88f0a",
   "metadata": {},
   "source": [
    "# Run Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30a594-eaec-47e5-9b37-1420936ee943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a99ce0-e4a4-4e52-89f3-cb6e3e4665f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession, for AWS and Azure\n",
    "spark = SparkSession.builder.appName('iceberg_lab')\\\n",
    "    .config('spark.jars.packages', os.environ['PACKAGES'])\\\n",
    "    .config('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e5a01-0ab7-493e-909e-e5dac884a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession, specifically for GCP where GCS needs the shaded jar as described here:\n",
    "# https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/master/gcs/INSTALL.md#troubleshooting-the-installation\n",
    "spark = SparkSession.builder.appName('iceberg_lab')\\\n",
    "    .config('spark.jars', 'https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.18/gcs-connector-hadoop3-2.2.18-shaded.jar')\\\n",
    "    .config('spark.jars.packages', os.environ['PACKAGES'])\\\n",
    "    .config('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c160774-3d56-4e2f-9102-7b745da4a12f",
   "metadata": {},
   "source": [
    "### Spark configurations for all clouds\n",
    "Regardless which cloud your Snowflake account is in, set the following configurations for Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad480e1-8a79-4d81-a5ae-9f6401d5545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.defaultCatalog\", \"snowflake_catalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.catalog-impl\", \"org.apache.iceberg.snowflake.SnowflakeCatalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.uri\", os.environ['SNOWFLAKE_CATALOG_URI'])\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.jdbc.role\", \"ICEBERG_LAB\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.jdbc.user\", \"ICEBERG_LAB\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.jdbc.password\", os.environ['SNOWFLAKE_PASSWORD'])\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.jdbc.private_key_file\", os.environ['PRIVATE_KEY_FILE'])\n",
    "spark.conf.set(\"spark.sql.iceberg.vectorization.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b759ea-1e59-4dee-ae52-c558a3e7f0ff",
   "metadata": {},
   "source": [
    "### Spark configurations for AWS\n",
    "If your Snowflake account and object storage are on AWS, set these additional Spark configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b430d4-bbbe-464d-be18-4184b2404dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.access.key\", os.environ['AWS_ACCESS_KEY_ID'])\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.secret.key\", os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.endpoint.region\", os.environ['AWS_REGION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa200763-69a4-4045-b170-eda14f5c459f",
   "metadata": {},
   "source": [
    "### Spark configurations for Azure\n",
    "If your Snowflake account and object storage are on Azure, set these additional Spark configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec85ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is using a storage account and container with anonymous access enabled.\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "spark.conf.set(\"spark.hadoop.fs.azure.account.key.snowflakeiceberg.blob.core.windows.net\", os.environ['AZURE_ACCESS_KEY'])\n",
    "spark.conf.set(\"spark.hadoop.fs.azure.account.auth.type.snowflakeiceberg.blob.core.windows.net\", \"SharedKey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3de6a9-16f9-4e6d-aba7-86291560f4db",
   "metadata": {},
   "source": [
    "### Spark configurations for GCP\n",
    "If your Snowflake account and object storage are on Google Cloud, set these additional Spark configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e492272-c01b-431d-9fe1-8badc596d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.gs.project.id\", os.environ['PROJECT_ID'])\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.gs.auth.type\", \"SERVICE_ACCOUNT_JSON_KEYFILE\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.json.keyfile\", os.environ['JSON_KEYFILE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5304667-f991-4004-8385-0a948f1bc007",
   "metadata": {},
   "source": [
    "# Read Snowflake-managed Iceberg Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea146b-8a09-4459-ab59-6008c6f1766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW NAMESPACES IN ICEBERG_LAB\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02e0a2-eacc-4627-8016-46b45613c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"USE ICEBERG_LAB.ICEBERG_LAB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411a03-97b1-417a-8feb-632c70b15b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6b944-ca4f-4c08-9d0c-56931d951875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(\"iceberg_lab.iceberg_lab.customer_iceberg\")\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
