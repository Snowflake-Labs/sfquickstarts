{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion\n",
    "\n",
    "The `diamonds` dataset has been widely used in data science and machine learning. We will use it to demonstrate Snowflake's native data science transformers in terms of database functionality and Spark & Pandas comportablity, using non-synthetic and statistically appropriate data that is well known to the ML community.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Secure Connection to Snowflake\n",
    "\n",
    "*Other connection options include Username/Password, MFA, OAuth, Okta, SSO. For more information, refer to the [Python Connector](https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-example) documentation.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark for Python\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.snowpark.types import StructType, StructField, FloatType, StringType, IntegerType\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "# data science libs\n",
    "import numpy as np\n",
    "\n",
    "# misc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : SIKHADAS\n",
      "Role                        : \"ACCOUNTADMIN\"\n",
      "Database                    : \"ML_HOL_DB\"\n",
      "Schema                      : \"ML_HOL_SCHEMA\"\n",
      "Warehouse                   : \"ML_HOL_WH\"\n",
      "Snowflake version           : 7.21.1\n",
      "Snowpark for Python version : 1.4.0\n"
     ]
    }
   ],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "################################################################################################################\n",
    "#  You can also use the SnowSQL Client to configure your connection params:\n",
    "#  https://docs.snowflake.com/en/user-guide/snowsql-install-config.html\n",
    "#\n",
    "#  >>> from snowflake.ml.utils import connection_params\n",
    "#  >>> session = Session.builder.configs(connection_params.SnowflakeLoginOptions()\n",
    "#  >>> ).create()   \n",
    "#\n",
    "#  NOTE: If you have named connection params then specify the connection name\n",
    "#  Example:\n",
    "#  \n",
    "#  >>> session = Session.builder.configs(\n",
    "#  >>> connection_params.SnowflakeLoginOptions(connection_name='connections.snowml')\n",
    "#  >>> ).create()\n",
    "#\n",
    "#################################################################################################################\n",
    "\n",
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage the `diamonds` CSV file to be read into the Snowpark DataFrame Reader\n",
    "\n",
    "For more information on loading data, see documentation on [snowflake.snowpark.DataFrameReader](https://docs.snowflake.com/ko/developer-guide/snowpark/reference/python/api/snowflake.snowpark.DataFrameReader.html).\n",
    "\n",
    "First, download the `diamonds` data from\n",
    "https://github.com/tidyverse/ggplot2/blob/882584f915b23cda5091fb69e88f19e8200811bf/data-raw/diamonds.csv and save it in this repo's folder.\n",
    "\n",
    "Once it's downloaded, run the rest of the cells in order to stage the file in Snowflake.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='diamonds.csv', target='diamonds.csv', source_size=2814963, target_size=0, source_compression='NONE', target_compression='NONE', status='SKIPPED', message='')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the diamonds CSV file to the stage we created earlier\n",
    "session.file.put(\"diamonds.csv\", \"@DIAMONDS_ASSETS\", auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------\n",
      "|\"ROW\"  |\"CARAT\"  |\"CUT\"      |\"COLOR\"  |\"CLARITY\"  |\"DEPTH\"  |\"TABLE\"  |\"PRICE\"  |\"X\"   |\"Y\"   |\"Z\"   |\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "|1      |0.23     |Ideal      |E        |SI2        |61.5     |55.0     |326.0    |3.95  |3.98  |2.43  |\n",
      "|2      |0.21     |Premium    |E        |SI1        |59.8     |61.0     |326.0    |3.89  |3.84  |2.31  |\n",
      "|3      |0.23     |Good       |E        |VS1        |56.9     |65.0     |327.0    |4.05  |4.07  |2.31  |\n",
      "|4      |0.29     |Premium    |I        |VS2        |62.4     |58.0     |334.0    |4.2   |4.23  |2.63  |\n",
      "|5      |0.31     |Good       |J        |SI2        |63.3     |58.0     |335.0    |4.34  |4.35  |2.75  |\n",
      "|6      |0.24     |Very Good  |J        |VVS2       |62.8     |57.0     |336.0    |3.94  |3.96  |2.48  |\n",
      "|7      |0.24     |Very Good  |I        |VVS1       |62.3     |57.0     |336.0    |3.95  |3.98  |2.47  |\n",
      "|8      |0.26     |Very Good  |H        |SI1        |61.9     |55.0     |337.0    |4.07  |4.11  |2.53  |\n",
      "|9      |0.22     |Fair       |E        |VS2        |65.1     |61.0     |337.0    |3.87  |3.78  |2.49  |\n",
      "|10     |0.23     |Very Good  |H        |VS1        |59.4     |61.0     |338.0    |4.0   |4.05  |2.39  |\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SUMMARY\"  |\"ROW\"               |\"CARAT\"              |\"CUT\"      |\"COLOR\"  |\"CLARITY\"  |\"DEPTH\"  |\"TABLE\"             |\"PRICE\"            |\"X\"                 |\"Y\"                 |\"Z\"                 |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|count      |53940.0             |53940.0              |53940      |53940    |53940      |53940    |53940.0             |53940.0            |53940.0             |53940.0             |53940.0             |\n",
      "|mean       |26970.5             |0.7979397478680015   |NULL       |NULL     |NULL       |NULL     |57.45718390804598   |3932.799721913237  |5.731157211716722   |5.734525954764553   |3.538733778272154   |\n",
      "|stddev     |15571.281096942537  |0.47401124440541836  |NULL       |NULL     |NULL       |NULL     |2.2344905628213527  |3989.439738146379  |1.1217607467924935  |1.1421346741235547  |0.7056988469499935  |\n",
      "|min        |1.0                 |0.2                  |Fair       |D        |I1         |43       |43.0                |326.0              |0.0                 |0.0                 |0.0                 |\n",
      "|max        |53940.0             |5.01                 |Very Good  |J        |VVS2       |79       |95.0                |18823.0            |10.74               |58.9                |31.8                |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the schema for the data in the CSV file\n",
    "diamonds_schema = StructType([StructField(\"row\", IntegerType()), \n",
    "                              StructField(\"carat\", FloatType()), \n",
    "                              StructField(\"cut\", StringType()),\n",
    "                              StructField(\"color\", StringType()),\n",
    "                              StructField(\"clarity\", StringType()),\n",
    "                              StructField(\"depth\", StringType()),\n",
    "                              StructField(\"table\", FloatType()),\n",
    "                              StructField(\"price\", FloatType()),\n",
    "                              StructField(\"x\", FloatType()),\n",
    "                              StructField(\"y\", FloatType()),\n",
    "                              StructField(\"z\", FloatType())\n",
    "                              ])\n",
    "\n",
    "# Create a Snowpark DataFrame that is configured to load data from the CSV file\n",
    "diamonds_df = session.read.options({\"field_delimiter\": \",\", \"skip_header\": 1}).schema(diamonds_schema).csv(\"@DIAMONDS_ASSETS/diamonds.csv\")\n",
    "diamonds_df.show()\n",
    "\n",
    "# Look at descriptive stats on the DataFrame\n",
    "diamonds_df.describe().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we standardize the category formatting for `CUT` using Snowpark DataFrame operations.\n",
    "\n",
    "This way, when we write to a Snowflake table, there will be no inconsistencies in how the Snowpark DataFrame will read in the column names. Secondly, the feature transformations on categoricals will be easier to encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------\n",
      "|\"ROW\"  |\"CARAT\"  |\"COLOR\"  |\"CLARITY\"  |\"DEPTH\"  |\"TABLE\"  |\"PRICE\"  |\"X\"   |\"Y\"   |\"Z\"   |\"CUT\"      |\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "|1      |0.23     |E        |SI2        |61.5     |55.0     |326.0    |3.95  |3.98  |2.43  |IDEAL      |\n",
      "|2      |0.21     |E        |SI1        |59.8     |61.0     |326.0    |3.89  |3.84  |2.31  |PREMIUM    |\n",
      "|3      |0.23     |E        |VS1        |56.9     |65.0     |327.0    |4.05  |4.07  |2.31  |GOOD       |\n",
      "|4      |0.29     |I        |VS2        |62.4     |58.0     |334.0    |4.2   |4.23  |2.63  |PREMIUM    |\n",
      "|5      |0.31     |J        |SI2        |63.3     |58.0     |335.0    |4.34  |4.35  |2.75  |GOOD       |\n",
      "|6      |0.24     |J        |VVS2       |62.8     |57.0     |336.0    |3.94  |3.96  |2.48  |VERY_GOOD  |\n",
      "|7      |0.24     |I        |VVS1       |62.3     |57.0     |336.0    |3.95  |3.98  |2.47  |VERY_GOOD  |\n",
      "|8      |0.26     |H        |SI1        |61.9     |55.0     |337.0    |4.07  |4.11  |2.53  |VERY_GOOD  |\n",
      "|9      |0.22     |E        |VS2        |65.1     |61.0     |337.0    |3.87  |3.78  |2.49  |FAIR       |\n",
      "|10     |0.23     |H        |VS1        |59.4     |61.0     |338.0    |4.0   |4.05  |2.39  |VERY_GOOD  |\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fix_values(columnn):\n",
    "    return F.upper(F.regexp_replace(F.col(columnn), '[^a-zA-Z0-9]+', '_'))\n",
    "\n",
    "for col in [\"CUT\"]:\n",
    "    diamonds_df = diamonds_df.with_column(col, fix_values(col))\n",
    "\n",
    "diamonds_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we remove the `row` column and force headers to uppercase using Snowpark DataFrame operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "|\"CARAT\"  |\"COLOR\"  |\"CLARITY\"  |\"DEPTH\"  |\"TABLE_PCT\"  |\"PRICE\"  |\"X\"   |\"Y\"   |\"Z\"   |\"CUT\"      |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "|0.23     |E        |SI2        |61.5     |55.0         |326.0    |3.95  |3.98  |2.43  |IDEAL      |\n",
      "|0.21     |E        |SI1        |59.8     |61.0         |326.0    |3.89  |3.84  |2.31  |PREMIUM    |\n",
      "|0.23     |E        |VS1        |56.9     |65.0         |327.0    |4.05  |4.07  |2.31  |GOOD       |\n",
      "|0.29     |I        |VS2        |62.4     |58.0         |334.0    |4.2   |4.23  |2.63  |PREMIUM    |\n",
      "|0.31     |J        |SI2        |63.3     |58.0         |335.0    |4.34  |4.35  |2.75  |GOOD       |\n",
      "|0.24     |J        |VVS2       |62.8     |57.0         |336.0    |3.94  |3.96  |2.48  |VERY_GOOD  |\n",
      "|0.24     |I        |VVS1       |62.3     |57.0         |336.0    |3.95  |3.98  |2.47  |VERY_GOOD  |\n",
      "|0.26     |H        |SI1        |61.9     |55.0         |337.0    |4.07  |4.11  |2.53  |VERY_GOOD  |\n",
      "|0.22     |E        |VS2        |65.1     |61.0         |337.0    |3.87  |3.78  |2.49  |FAIR       |\n",
      "|0.23     |H        |VS1        |59.4     |61.0         |338.0    |4.0   |4.05  |2.39  |VERY_GOOD  |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop 'ROW'\n",
    "diamonds_df = diamonds_df.drop('ROW')\n",
    "\n",
    "# Force headers to uppercase\n",
    "for colname in np.array(diamonds_df.columns):\n",
    "    if str.upper(colname) == \"TABLE\":\n",
    "        new_colname = colname + '_PCT'\n",
    "    else:\n",
    "        new_colname = str.upper(colname)\n",
    "\n",
    "    diamonds_df = diamonds_df.with_column_renamed(colname, new_colname)\n",
    "\n",
    "diamonds_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write cleaned data to a Snowflake table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_df.write.mode('overwrite').save_as_table('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysnowpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
