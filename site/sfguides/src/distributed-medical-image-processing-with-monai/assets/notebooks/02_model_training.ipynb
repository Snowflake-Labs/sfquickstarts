{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ecfee14",
   "metadata": {
    "name": "title"
   },
   "source": [
    "# MONAI Lung CT Registration Training Pipeline\n",
    "\n",
    "This notebook demonstrates distributed medical image registration using **MONAI** (Medical Open Network for AI) on **Snowflake's Notebooks with Container Runtime**.\n",
    "\n",
    "## Overview\n",
    "- **Task**: Register lung CT scans (align inspiration/expiration phases)\n",
    "- **Architecture**: LocalNet (CNN-based deformation field prediction)\n",
    "- **Framework**: Ray for distributed computing, PyTorch for deep learning\n",
    "- **Data Source**: NIfTI medical images stored in Snowflake stages\n",
    "\n",
    "## Workflow\n",
    "1. **Setup & Dependencies** - Install MONAI and configure Ray cluster\n",
    "2. **Data Loading** - Read paired CT scans from Snowflake stages\n",
    "3. **Model Training** - Train registration network with validation\n",
    "4. **Model Registry** - Save and register trained model for deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe347f4",
   "metadata": {
    "name": "step1_header"
   },
   "source": [
    "## Step 1: Initialize Snowflake Session\n",
    "\n",
    "Import core libraries and establish connection to Snowflake's active session. This session provides access to:\n",
    "- Snowflake stages for data storage\n",
    "- SQL execution capabilities\n",
    "- File I/O operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11786677-8f2c-4e69-9bf1-89ad993cd03b",
   "metadata": {
    "language": "python",
    "name": "init_session"
   },
   "outputs": [],
   "source": [
    "# Core Python libraries for data manipulation and UI\n",
    "import streamlit as st  # For interactive notebook UI elements\n",
    "import pandas as pd     # For tabular data handling\n",
    "\n",
    "# Snowflake-specific imports\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# Establish connection to the active Snowflake session\n",
    "# This provides access to stages, warehouses, and compute resources\n",
    "session = get_active_session()\n",
    "\n",
    "# Set query tag for consumption tracking\n",
    "session.query_tag = '{\"origin\":\"sf_sit-is\",\"name\":\"distributed_medical_image_processing_with_monai\",\"version\":{\"major\":1,\"minor\":0},\"attributes\":{\"is_quickstart\":1,\"source\":\"notebook\"}}'\n",
    "\n",
    "# Database name - matches setup.sql\n",
    "DATABASE_NAME = \"MONAI_DB\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf7ac8",
   "metadata": {
    "name": "step2_header"
   },
   "source": [
    "## Step 2: Configure Distributed Computing Environment\n",
    "\n",
    "This cell performs three critical tasks:\n",
    "\n",
    "1. **Ray Initialization** - Connect to the Ray cluster for distributed processing\n",
    "2. **Cluster Scaling** - Scale to 4 worker nodes for parallel training\n",
    "3. **Dependency Installation** - Install MONAI and medical imaging libraries on all nodes\n",
    "\n",
    "**Why distributed?** Medical image processing is computationally intensive. Ray allows us to parallelize data loading and preprocessing across multiple nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83815555-4313-4b34-8ef3-9f95dabf2394",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "ray_cluster_setup"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPROVED MONAI LUNG CT REGISTRATION WITH SNOWFLAKE ML + RAY\n",
    "# ============================================================================\n",
    "\n",
    "# Standard Python libraries\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import logging\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Distributed computing and ML frameworks\n",
    "import ray                          # Distributed computing framework\n",
    "import torch                        # PyTorch deep learning\n",
    "import torch.nn as nn              # Neural network modules\n",
    "import torch.optim as optim        # Optimization algorithms\n",
    "import numpy as np                 # Numerical operations\n",
    "\n",
    "# Snowflake integrations\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark.files import SnowflakeFile      # For reading files from stages\n",
    "from snowflake.ml.runtime_cluster import scale_cluster  # For scaling Ray cluster\n",
    "\n",
    "\n",
    "\n",
    "session = get_active_session()\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# RAY CLUSTER SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Connect to the Ray cluster in the Snowflake container runtime\n",
    "# 'auto' discovers the cluster head node automatically\n",
    "# ignore_reinit_error allows re-running this cell without errors\n",
    "ray.init(address='auto', ignore_reinit_error=True)\n",
    "\n",
    "def configure_ray_logger() -> None:\n",
    "    \"\"\"\n",
    "    Configure logging levels to reduce Ray's verbose output.\n",
    "    \n",
    "    We suppress Ray internals (CRITICAL only) but keep application logs (INFO)\n",
    "    to see training progress without being overwhelmed by cluster messages.\n",
    "    \"\"\"\n",
    "    # Suppress Ray core logging (only show critical errors)\n",
    "    ray_logger = logging.getLogger(\"ray\")\n",
    "    ray_logger.setLevel(logging.CRITICAL)\n",
    "    \n",
    "    # Suppress Ray Data logging (dataset operations)\n",
    "    data_logger = logging.getLogger(\"ray.data\")\n",
    "    data_logger.setLevel(logging.CRITICAL)\n",
    "    \n",
    "    # Keep INFO level for our application logs (training metrics, etc.)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Disable Ray's progress bars for cleaner output\n",
    "    context = ray.data.DataContext.get_current()\n",
    "    context.execution_options.verbose_progress = False\n",
    "    context.enable_operator_progress_bars = False\n",
    "\n",
    "# Apply logging configuration\n",
    "configure_ray_logger()\n",
    "\n",
    "# Scale the Ray cluster to 4 worker nodes\n",
    "# More nodes = faster parallel data loading and preprocessing\n",
    "scale_cluster(4)\n",
    "\n",
    "# ============================================================================\n",
    "# DISTRIBUTED DEPENDENCY INSTALLATION\n",
    "# ============================================================================\n",
    "\n",
    "@ray.remote(num_cpus=0)  # Uses negligible CPU (just runs pip install)\n",
    "def install_deps():\n",
    "    \"\"\"\n",
    "    Install required packages on a single Ray node.\n",
    "    \n",
    "    Packages include:\n",
    "    - monai: Medical imaging transformations and networks\n",
    "    - pytorch-ignite: Training utilities\n",
    "    - itk: Medical image I/O\n",
    "    - nibabel: NIfTI file format support\n",
    "    - torchvision: Additional vision utilities\n",
    "    - transformers, einops: Tensor manipulation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import subprocess\n",
    "        \n",
    "        # List of required packages for medical image registration\n",
    "        packages = [\n",
    "            \"monai\",            # Core medical imaging framework\n",
    "            \"pytorch-ignite\",   # Training loop utilities\n",
    "            \"itk\",             # Insight Toolkit for medical imaging\n",
    "            \"gdown\",           # Google Drive downloader (if needed)\n",
    "            \"torchvision\",     # Computer vision utilities\n",
    "            \"lmdb\",            # Lightning Memory-Mapped Database\n",
    "            \"transformers\",    # Attention mechanisms (if using vision transformers)\n",
    "            \"einops\",          # Tensor operations made easy\n",
    "            \"nibabel\"          # NIfTI and medical image file I/O\n",
    "        ]\n",
    "        \n",
    "        # Install packages with pip (suppress output for cleaner logs)\n",
    "        subprocess.run(\n",
    "            [\"pip\", \"install\"] + packages, \n",
    "            check=True, \n",
    "            stdout=subprocess.PIPE, \n",
    "            stderr=subprocess.PIPE\n",
    "        )\n",
    "        \n",
    "        # Verify installation by checking MONAI version\n",
    "        result = subprocess.run(\n",
    "            [\"pip\", \"show\", \"monai\"], \n",
    "            capture_output=True, \n",
    "            text=True, \n",
    "            check=True\n",
    "        )\n",
    "        \n",
    "        # Return success message with node IP for tracking\n",
    "        return f\"\u2705 Dependencies installed on {ray.util.get_node_ip_address()}:\\n{result.stdout.splitlines()[0]}\"\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # Return error message if installation fails\n",
    "        error_msg = e.stderr if e.stderr else e.stdout\n",
    "        return f\"\u274c Failed on {ray.util.get_node_ip_address()}: {error_msg}\"\n",
    "\n",
    "# Get all alive nodes in the Ray cluster\n",
    "nodes = {node[\"NodeManagerAddress\"] for node in ray.nodes() if node[\"Alive\"]}\n",
    "\n",
    "# Create installation tasks for each node (parallel execution)\n",
    "# resource constraint ensures each task runs on a different node\n",
    "tasks = [install_deps.options(resources={f\"node:{node}\": 0.01}).remote() for node in nodes]\n",
    "\n",
    "# Wait for all installations to complete and collect results\n",
    "results = ray.get(tasks)\n",
    "\n",
    "# Print installation status for each node\n",
    "for res in results:\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7db73",
   "metadata": {
    "name": "step3_header"
   },
   "source": [
    "## Step 3: Data Exploration - Visualize Medical Images\n",
    "\n",
    "Before training, let's inspect our data! This cell provides an interactive viewer for NIfTI (Neuroimaging Informatics Technology Initiative) files stored in Snowflake stages.\n",
    "\n",
    "**NIfTI Format**: Standard medical imaging format storing 3D volumetric data (like CT or MRI scans).\n",
    "\n",
    "**Interactive Slider**: Navigate through the scan's depth (z-axis) to view different slices of the lung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78827d26-d75e-4951-9ccd-953c677c0620",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "visualize_nifti"
   },
   "outputs": [],
   "source": [
    "# Visualization and medical imaging libraries\n",
    "import streamlit as st           # Interactive UI components\n",
    "import matplotlib.pyplot as plt  # Plotting 2D slices\n",
    "import nibabel as nib           # NIfTI medical image I/O\n",
    "import numpy as np              # Numerical operations\n",
    "import tempfile                 # Temporary file handling\n",
    "import os                       # File system operations\n",
    "\n",
    "# Snowflake integration\n",
    "from snowflake.snowpark.files import SnowflakeFile\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# MONAI medical imaging framework components\n",
    "from monai.networks.nets import LocalNet                                  # Deformable registration network\n",
    "from monai.networks.blocks import Warp                                    # Spatial warping layer\n",
    "from monai.losses import GlobalMutualInformationLoss, BendingEnergyLoss  # Registration objectives\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, Resized\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def load_nifti_from_stage(stage_path):\n",
    "    \"\"\"\n",
    "    Load a NIfTI medical image from Snowflake stage into memory.\n",
    "    \n",
    "    This function:\n",
    "    1. Downloads the .nii.gz file from Snowflake stage to a temp location\n",
    "    2. Loads it with nibabel (neuroimaging library)\n",
    "    3. Returns the 3D volume as a NumPy array\n",
    "    4. Cleans up temporary files\n",
    "    \n",
    "    Args:\n",
    "        stage_path (str): Path to NIfTI file in stage (with or without @ prefix)\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: 3D medical image volume, or None if loading fails\n",
    "    \"\"\"\n",
    "    session = get_active_session()\n",
    "    \n",
    "    # Ensure path starts with @ symbol (required for Snowflake stages)\n",
    "    clean_path = stage_path if stage_path.startswith(\"@\") else f\"@{stage_path}\"\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Download file from Snowflake stage to temporary location\n",
    "        with SnowflakeFile.open(clean_path, 'rb') as f:\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".nii.gz\", delete=False) as tmp:\n",
    "                tmp.write(f.read())\n",
    "                tmp_name = tmp.name\n",
    "        \n",
    "        # Step 2: Load NIfTI file using nibabel library\n",
    "        img = nib.load(tmp_name)\n",
    "        data = img.get_fdata()  # Extract raw voxel data as NumPy array\n",
    "        \n",
    "        # Step 3: Clean up temporary file to free disk space\n",
    "        os.unlink(tmp_name)\n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Display error in Streamlit UI if file loading fails\n",
    "        st.error(f\"Error reading {clean_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def visualize_nifti_interactive(stage_path):\n",
    "    \"\"\"\n",
    "    Create an interactive 3D volume viewer with Streamlit slider.\n",
    "    \n",
    "    Displays 2D slices from a 3D medical image, allowing users to navigate\n",
    "    through the volume depth (z-axis).\n",
    "    \n",
    "    Args:\n",
    "        stage_path (str): Path to NIfTI file in Snowflake stage\n",
    "    \"\"\"\n",
    "    st.write(f\"### Viewing: `{stage_path}`\")\n",
    "    \n",
    "    # 1. Load the 3D volume from Snowflake\n",
    "    vol_data = load_nifti_from_stage(stage_path)\n",
    "    if vol_data is None:\n",
    "        return  # Exit if loading failed\n",
    "\n",
    "    # 2. Get volume dimensions\n",
    "    # Typical shape: (Height, Width, Depth) or (X, Y, Z)\n",
    "    x, y, z = vol_data.shape\n",
    "    st.write(f\"Volume Shape: {vol_data.shape}\")\n",
    "\n",
    "    # 3. Create interactive slider for slice selection\n",
    "    # Z-axis represents depth (axial view in medical imaging)\n",
    "    # Default to middle slice\n",
    "    slice_idx = st.slider(\"Select Slice\", min_value=0, max_value=z-1, value=z//2)\n",
    "\n",
    "    # 4. Extract the selected 2D slice\n",
    "    slice_data = vol_data[:, :, slice_idx]\n",
    "    \n",
    "    # Rotate 90\u00b0 for correct anatomical orientation\n",
    "    # (Medical images often have unexpected orientations when loaded)\n",
    "    slice_data = np.rot90(slice_data)\n",
    "\n",
    "    # 5. Display the slice using matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(slice_data, cmap='gray')  # Grayscale colormap for CT scans\n",
    "    ax.axis('off')  # Hide axes for cleaner visualization\n",
    "    ax.set_title(f\"Slice {slice_idx}\")\n",
    "    \n",
    "    st.pyplot(fig)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE - Visualize a sample lung CT scan\n",
    "# ============================================================================\n",
    "# This demonstrates how to view medical images stored in Snowflake stages\n",
    "# Replace with any path from your dataset (e.g., from load_paired_paths())\n",
    "\n",
    "sample_path = f\"{DATABASE_NAME}.UTILS.monai_medical_images_stg/scansExp/case_001_exp.nii.gz\" \n",
    "visualize_nifti_interactive(sample_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d540ab",
   "metadata": {
    "name": "step4_header"
   },
   "source": [
    "## Step 4: Load Paired Image Paths (Metadata Only)\n",
    "\n",
    "**Key Insight**: We DON'T load the actual image data yet - just the file paths!\n",
    "\n",
    "This cell:\n",
    "1. Lists all NIfTI files in the Snowflake stage using SQL\n",
    "2. Pairs \"fixed\" (expiration) and \"moving\" (inspiration) scans\n",
    "3. Returns a lightweight Ray dataset containing only file paths\n",
    "\n",
    "**Why paths only?** Loading all medical images into memory would consume GB/TB of RAM. Instead, we'll load images just-in-time during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ef797-5c60-4ac6-9b32-76ac85664896",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "load_paired_paths"
   },
   "outputs": [],
   "source": [
    "def load_paired_paths(stage_location=f\"@{DATABASE_NAME}.UTILS.MONAI_MEDICAL_IMAGES_STG\"):\n",
    "    \"\"\"\n",
    "    Load paired CT scan paths for medical image registration.\n",
    "    \n",
    "    This function performs METADATA OPERATIONS ONLY - no actual image data is loaded.\n",
    "    It identifies pairs of:\n",
    "    - Fixed image (expiration CT)\n",
    "    - Moving image (inspiration CT)\n",
    "    - Fixed label (lung mask for expiration)\n",
    "    - Moving label (lung mask for inspiration)\n",
    "    \n",
    "    Args:\n",
    "        stage_location (str): Snowflake stage containing medical images\n",
    "    \n",
    "    Returns:\n",
    "        ray.data.Dataset: Lightweight dataset with file paths only\n",
    "    \"\"\"\n",
    "    session = get_active_session()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: List all NIfTI files using SQL (fast, metadata-only operation)\n",
    "    # ========================================================================\n",
    "    # This returns only file paths, not binary data\n",
    "    df_files = session.sql(\n",
    "        f\"LIST {stage_location} PATTERN = '.*.nii.gz'\"\n",
    "    ).select('\"name\"').to_pandas()\n",
    "    \n",
    "    # Clean up column names and add fully-qualified path\n",
    "    df_files.rename(columns={'\"name\"': 'name'})\n",
    "    df_files[\"name\"] = f\"{DATABASE_NAME}.UTILS.\" + df_files[\"name\"]\n",
    "  \n",
    "    print(df_files)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: Categorize files by type using regex patterns\n",
    "    # ========================================================================\n",
    "    # Expected folder structure:\n",
    "    #   - scans/case_XXX_exp.nii.gz    (expiration CT)\n",
    "    #   - scans/case_XXX_insp.nii.gz   (inspiration CT)\n",
    "    #   - lungMasks/case_XXX_exp.nii.gz    (expiration lung segmentation)\n",
    "    #   - lungMasks/case_XXX_insp.nii.gz   (inspiration lung segmentation)\n",
    "    \n",
    "    fixed_imgs = df_files[df_files['name'].str.contains(\"scans.*_exp\", regex=True)]\n",
    "    moving_imgs = df_files[df_files['name'].str.contains(\"scans.*_insp\", regex=True)]\n",
    "    fixed_masks = df_files[df_files['name'].str.contains(\"lungMasks.*_exp\", regex=True)]\n",
    "    moving_masks = df_files[df_files['name'].str.contains(\"lungMasks.*_insp\", regex=True)]\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: Match files into training pairs using case IDs\n",
    "    # ========================================================================\n",
    "    # For each fixed (expiration) image, find its corresponding:\n",
    "    # - Moving (inspiration) image\n",
    "    # - Fixed and moving lung masks\n",
    "    \n",
    "    for _, row in fixed_imgs.iterrows():\n",
    "        f_path = row['name']\n",
    "        \n",
    "        # Extract case identifier (e.g., \"case_001\" from \"case_001_exp.nii.gz\")\n",
    "        filename = f_path.split('/')[-1] \n",
    "        case_id = filename.split('_exp')[0] \n",
    "        \n",
    "        # Find matching files by case ID\n",
    "        m_path = moving_imgs[moving_imgs['name'].str.contains(f\"{case_id}_insp\")].iloc[0]['name']\n",
    "        fl_path = fixed_masks[fixed_masks['name'].str.contains(f\"{case_id}_exp\")].iloc[0]['name']\n",
    "        ml_path = moving_masks[moving_masks['name'].str.contains(f\"{case_id}_insp\")].iloc[0]['name']\n",
    "        \n",
    "        # Store the complete pair\n",
    "        pairs.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"fixed_path\": f_path,           # Expiration CT\n",
    "            \"moving_path\": m_path,          # Inspiration CT\n",
    "            \"fixed_label_path\": fl_path,    # Expiration lung mask\n",
    "            \"moving_label_path\": ml_path    # Inspiration lung mask\n",
    "        })\n",
    "        \n",
    "    print(f\"\u2705 Paired {len(pairs)} cases using paths only (no binary data loaded).\")\n",
    "    \n",
    "    # Convert to Ray dataset for distributed processing\n",
    "    return ray.data.from_pandas(pd.DataFrame(pairs))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTE: Load paired file paths\n",
    "# ============================================================================\n",
    "# This dataset is tiny (only strings), not the actual GB-sized medical images\n",
    "ray_dataset = load_paired_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1952285",
   "metadata": {
    "name": "step5_header"
   },
   "source": [
    "## Step 5: Define Custom Dataset with Just-In-Time Loading\n",
    "\n",
    "This cell creates a PyTorch `Dataset` that:\n",
    "1. **Loads images on-demand** - Downloads from Snowflake stage only when needed\n",
    "2. **Applies preprocessing** - Normalizes intensities, resizes volumes\n",
    "3. **Handles labels correctly** - Preserves binary masks without intensity scaling\n",
    "\n",
    "**Why custom dataset?** Standard datasets can't handle Snowflake stage I/O. This custom implementation downloads each file to a temporary location, processes it, then cleans up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729555b-b088-42bd-9ee4-4e73c061c074",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "custom_dataset"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS FOR SNOWFLAKE STAGE I/O\n",
    "# ============================================================================\n",
    "\n",
    "def read_file_from_stage(stage_path):\n",
    "    \"\"\"\n",
    "    Read binary file content from Snowflake stage.\n",
    "    \n",
    "    Args:\n",
    "        stage_path (str): Path to file in stage (with or without @ prefix)\n",
    "    \n",
    "    Returns:\n",
    "        bytes: Raw file content\n",
    "    \"\"\"\n",
    "    session = get_active_session()\n",
    "    # Ensure path has @ prefix for Snowflake stage access\n",
    "    clean_path = stage_path if stage_path.startswith(\"@\") else f\"@{stage_path}\"\n",
    "    \n",
    "    with SnowflakeFile.open(clean_path, 'rb') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CUSTOM PYTORCH DATASET WITH SNOWFLAKE INTEGRATION\n",
    "# ============================================================================\n",
    "\n",
    "class SnowflakeStageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for medical images stored in Snowflake stages.\n",
    "    \n",
    "    Key Features:\n",
    "    1. **Just-In-Time Loading**: Downloads images from Snowflake only when needed\n",
    "    2. **Automatic Cleanup**: Deletes temporary files after processing\n",
    "    3. **MONAI Integration**: Applies medical imaging transformations\n",
    "    4. **Separate Transforms**: Different pipelines for images vs. labels\n",
    "    \n",
    "    This approach avoids loading all GB/TB of medical data into memory at once.\n",
    "    \n",
    "    Args:\n",
    "        data_dicts (list): List of dicts with keys like 'fixed_path', 'moving_path', etc.\n",
    "        transform_img (Callable): MONAI transforms for images (includes normalization)\n",
    "        transform_lbl (Callable): MONAI transforms for labels (NO normalization)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dicts, transform_img=None, transform_lbl=None):\n",
    "        self.data_dicts = data_dicts\n",
    "        self.transform_img = transform_img\n",
    "        self.transform_lbl = transform_lbl\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of image pairs in dataset.\"\"\"\n",
    "        return len(self.data_dicts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Load and preprocess a single training sample.\n",
    "        \n",
    "        This method:\n",
    "        1. Downloads 4 files from Snowflake (fixed/moving images + labels)\n",
    "        2. Saves them to temporary locations\n",
    "        3. Applies MONAI transformations\n",
    "        4. Cleans up temporary files\n",
    "        5. Returns preprocessed tensors\n",
    "        \n",
    "        Args:\n",
    "            index (int): Dataset index\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary with 'fixed', 'moving', 'fixed_label', 'moving_label' tensors\n",
    "        \"\"\"\n",
    "        item = self.data_dicts[index]\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 1: Download files from Snowflake to temporary locations\n",
    "        # ====================================================================\n",
    "        temp_files = {}\n",
    "        for key in [\"fixed\", \"moving\", \"fixed_label\", \"moving_label\"]:\n",
    "            path = item[f\"{key}_path\"]\n",
    "            binary = read_file_from_stage(path)\n",
    "            \n",
    "            # Create temporary file with .nii.gz extension (required by nibabel)\n",
    "            tf = tempfile.NamedTemporaryFile(suffix=\".nii.gz\", delete=False)\n",
    "            tf.write(binary)\n",
    "            tf.close()\n",
    "            temp_files[key] = tf.name\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 2: Prepare data dictionary for MONAI transforms\n",
    "        # ====================================================================\n",
    "        # MONAI expects file paths as input to LoadImaged transform\n",
    "        data = {\n",
    "            \"fixed\": temp_files[\"fixed\"],\n",
    "            \"moving\": temp_files[\"moving\"],\n",
    "            \"fixed_label\": temp_files[\"fixed_label\"],\n",
    "            \"moving_label\": temp_files[\"moving_label\"],\n",
    "        }\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 3: Apply MONAI transformations (load, normalize, resize, augment)\n",
    "        # ====================================================================\n",
    "        if self.transform_img:\n",
    "            data = self.transform_img(data)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 4: Clean up temporary files to free disk space\n",
    "        # ====================================================================\n",
    "        for fpath in temp_files.values():\n",
    "            if os.path.exists(fpath):\n",
    "                os.unlink(fpath)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6a6c0",
   "metadata": {
    "name": "step6_header"
   },
   "source": [
    "## Step 6: Define Training Function\n",
    "\n",
    "This is the core training loop! The function:\n",
    "\n",
    "1. **Defines Transforms** - Preprocessing pipeline for medical images (windowing, resizing, augmentation)\n",
    "2. **Creates Data Loaders** - Wraps our custom dataset for batch iteration\n",
    "3. **Builds Model** - LocalNet architecture for deformation field prediction\n",
    "4. **Training Loop** - Iterates through epochs, computing loss and updating weights\n",
    "5. **Validation** - Monitors Dice score on held-out data\n",
    "6. **Model Checkpointing** - Saves best model to Snowflake stage\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Deformation Field (DDF)**: 3D vector field showing how to warp moving image to match fixed image\n",
    "- **Global Mutual Information Loss**: Measures image similarity (registration quality)\n",
    "- **Bending Energy Loss**: Regularization to keep deformations smooth and realistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d955bfc-126d-456c-8445-a1a78e923e7e",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "train_function"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MONAI MEDICAL IMAGING IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "from monai.networks.nets import LocalNet            # CNN-based registration network\n",
    "from monai.networks.blocks import Warp              # Spatial transformation layer\n",
    "from monai.losses import GlobalMutualInformationLoss, BendingEnergyLoss  # Registration losses\n",
    "from monai.transforms import (\n",
    "    Compose,                    # Chain multiple transforms\n",
    "    LoadImaged,                 # Load medical images from disk\n",
    "    EnsureChannelFirstd,        # Ensure channel-first format (C, H, W, D)\n",
    "    ScaleIntensityRanged,       # CT windowing (normalize HU values)\n",
    "    Resized,                    # Resize 3D volumes\n",
    "    LoadImage,                  # Single-image loader\n",
    "    EnsureChannelFirst,         # Single-image channel formatting\n",
    "    ScaleIntensityRange,        # Single-image intensity scaling\n",
    "    Resize,                     # Single-image resizing\n",
    "    RandAffined,                # Random affine augmentation (rotation, translation, scale)\n",
    "    RandGaussianNoised,         # Add random Gaussian noise\n",
    "    RandGaussianSmoothd         # Random Gaussian smoothing (blur)\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DISTRIBUTED TRAINING FUNCTION (GPU-ACCELERATED)\n",
    "# ============================================================================\n",
    "\n",
    "@ray.remote(num_gpus=1)\n",
    "def train_registration_model(\n",
    "    train_files, \n",
    "    val_files=None,\n",
    "    config=None,                                      # \u2190 FIX: Use None as default\n",
    "    save_path=None                                    # \u2190 FIX: Use None as default  \n",
    "):\n",
    "    \"\"\"\n",
    "    Train a deep learning model for medical image registration.\n",
    "    \n",
    "    This function performs end-to-end training:\n",
    "    1. **Data Preprocessing**: CT windowing, resizing, augmentation\n",
    "    2. **Model Architecture**: LocalNet (U-Net-like CNN for deformation field prediction)\n",
    "    3. **Loss Function**: Mutual Information (similarity) + Bending Energy (smoothness)\n",
    "    4. **Optimization**: Adam with learning rate scheduling\n",
    "    5. **Validation**: Dice score monitoring on held-out data\n",
    "    6. **Checkpointing**: Save best model to Snowflake stage\n",
    "    \n",
    "    Args:\n",
    "        train_files (list): List of training sample dictionaries with file paths\n",
    "        val_files (list, optional): List of validation sample dictionaries\n",
    "        config (dict): Training configuration (epochs, batch size, learning rate, etc.)\n",
    "        save_path (str): Snowflake stage path for saving model checkpoints\n",
    "    \n",
    "    Returns:\n",
    "        dict: Training results including best model path, final metrics, and history\n",
    "    \"\"\"\n",
    "    print(f\"\ud83d\ude80 Starting training with config: {config}\")\n",
    "    \n",
    "    # Determine compute device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\ud83d\udccd Using device: {device}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DATA PREPROCESSING PIPELINE\n",
    "    # ========================================================================\n",
    "    # These transforms must match those used during inference for consistency!\n",
    "    \n",
    "    # ========================================================================\n",
    "    # IMAGE TRANSFORMS (with data augmentation for training)\n",
    "    # ========================================================================\n",
    "    train_img_transforms = Compose([\n",
    "        # Step 1: Load NIfTI files from disk\n",
    "        LoadImaged(keys=[\"fixed\", \"moving\"]),\n",
    "        \n",
    "        # Step 2: Ensure channel-first format: (C, H, W, D)\n",
    "        # Medical images are often (H, W, D), but PyTorch needs (C, H, W, D)\n",
    "        EnsureChannelFirstd(keys=[\"fixed\", \"moving\"]),\n",
    "        \n",
    "        # Step 3: CT WINDOWING - Map Hounsfield Units (HU) to [0, 1] range\n",
    "        # This is CRITICAL for consistent training and inference!\n",
    "        # CT_MIN_HU = -1000 (air), CT_MAX_HU = 500 (soft tissue/bone)\n",
    "        # Values outside this range are clipped\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"fixed\", \"moving\"],\n",
    "            a_min=CT_MIN_HU,   # Input minimum (Hounsfield Units)\n",
    "            a_max=CT_MAX_HU,   # Input maximum (Hounsfield Units)\n",
    "            b_min=0.0,         # Output minimum (normalized)\n",
    "            b_max=1.0,         # Output maximum (normalized)\n",
    "            clip=True          # Clip values outside [CT_MIN_HU, CT_MAX_HU]\n",
    "        ),\n",
    "        \n",
    "        # Step 4: Resize volumes to consistent shape for batching\n",
    "        # Trilinear interpolation for smooth resampling\n",
    "        Resized(\n",
    "            keys=[\"fixed\", \"moving\"], \n",
    "            spatial_size=config[\"spatial_size\"],  # e.g., (96, 96, 104)\n",
    "            mode=\"trilinear\"\n",
    "        ),\n",
    "        \n",
    "        # ====================================================================\n",
    "        # DATA AUGMENTATION (improves model generalization)\n",
    "        # ====================================================================\n",
    "        \n",
    "        # Random affine transformations (50% probability)\n",
    "        # Simulates patient positioning variations\n",
    "        RandAffined(\n",
    "            keys=[\"fixed\", \"moving\"],\n",
    "            prob=0.5,                              # Apply 50% of the time\n",
    "            rotate_range=(0.1, 0.1, 0.1),         # \u00b10.1 radians (~6\u00b0) per axis\n",
    "            translate_range=(10, 10, 10),         # \u00b110 pixels shift\n",
    "            scale_range=(0.1, 0.1, 0.1),          # \u00b110% scaling\n",
    "            mode=[\"bilinear\", \"bilinear\"],        # Smooth interpolation\n",
    "            padding_mode=\"zeros\"                   # Fill empty regions with zeros\n",
    "        ),\n",
    "        \n",
    "        # Random Gaussian noise (30% probability)\n",
    "        # Simulates scanner noise and improves robustness\n",
    "        RandGaussianNoised(\n",
    "            keys=[\"fixed\", \"moving\"], \n",
    "            prob=0.3,     # Apply 30% of the time\n",
    "            std=0.05      # Standard deviation of noise\n",
    "        ),\n",
    "        \n",
    "        # Random Gaussian smoothing (30% probability)\n",
    "        # Simulates different scanner resolutions\n",
    "        RandGaussianSmoothd(\n",
    "            keys=[\"fixed\", \"moving\"], \n",
    "            prob=0.3, \n",
    "            sigma_x=(0.5, 1.5),  # Blur kernel size range per axis\n",
    "            sigma_y=(0.5, 1.5), \n",
    "            sigma_z=(0.5, 1.5)\n",
    "        ),\n",
    "    ])\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LABEL (SEGMENTATION MASK) TRANSFORMS\n",
    "    # ========================================================================\n",
    "    # CRITICAL: Labels are binary masks (0 or 1) - NO intensity normalization!\n",
    "    train_lbl_transforms = Compose([\n",
    "        # Step 1: Load segmentation masks from disk\n",
    "        LoadImaged(keys=[\"fixed_label\", \"moving_label\"]),\n",
    "        \n",
    "        # Step 2: Ensure channel-first format\n",
    "        EnsureChannelFirstd(keys=[\"fixed_label\", \"moving_label\"]),\n",
    "        \n",
    "        # Step 3: Resize masks to match image size\n",
    "        # \u26a0\ufe0f IMPORTANT: Use \"nearest\" interpolation to preserve binary values!\n",
    "        # Trilinear/bilinear would create fractional values between 0 and 1\n",
    "        Resized(\n",
    "            keys=[\"fixed_label\", \"moving_label\"], \n",
    "            spatial_size=config[\"spatial_size\"], \n",
    "            mode=\"nearest\"  # Preserve discrete labels (no blending)\n",
    "        ),\n",
    "        \n",
    "        # Step 4: Apply SAME affine transformations as images\n",
    "        # This ensures images and labels stay aligned after augmentation\n",
    "        RandAffined(\n",
    "            keys=[\"fixed_label\", \"moving_label\"],\n",
    "            prob=0.5,                              # Must match image augmentation\n",
    "            rotate_range=(0.1, 0.1, 0.1),\n",
    "            translate_range=(10, 10, 10),\n",
    "            scale_range=(0.1, 0.1, 0.1),\n",
    "            mode=[\"nearest\", \"nearest\"],           # Nearest for labels (preserve binary)\n",
    "            padding_mode=\"zeros\"\n",
    "        ),\n",
    "    ])\n",
    "    \n",
    "    # Validation transforms (no augmentation)\n",
    "    val_transforms = Compose([\n",
    "        LoadImaged(keys=[\"fixed\", \"moving\", \"fixed_label\", \"moving_label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"fixed\", \"moving\", \"fixed_label\", \"moving_label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"fixed\", \"moving\"],\n",
    "            a_min=CT_MIN_HU,\n",
    "            a_max=CT_MAX_HU,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True\n",
    "        ),\n",
    "        Resized(keys=[\"fixed\", \"moving\", \"fixed_label\", \"moving_label\"],\n",
    "                spatial_size=config[\"spatial_size\"],\n",
    "                mode=[\"trilinear\", \"trilinear\", \"nearest\", \"nearest\"]),\n",
    "    ])\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DATASETS & LOADERS\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Combine image and label transforms\n",
    "    def combined_transform(data):\n",
    "        data = train_img_transforms(data)\n",
    "        data = train_lbl_transforms(data)\n",
    "        return data\n",
    "    \n",
    "    train_ds = SnowflakeStageDataset(train_files, transform_img=combined_transform)\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, \n",
    "        batch_size=config[\"batch_size\"], \n",
    "        shuffle=True, \n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    val_loader = None\n",
    "    if val_files:\n",
    "        val_ds = SnowflakeStageDataset(val_files, transform_img=val_transforms)\n",
    "        val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MODEL SETUP\n",
    "    # ========================================================================\n",
    "    \n",
    "    model = LocalNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=2,\n",
    "        out_channels=3,\n",
    "        num_channel_initial=config[\"num_channel_initial\"],\n",
    "        extract_levels=[3],\n",
    "        out_activation=None,\n",
    "        out_kernel_initializer=\"zeros\"\n",
    "    ).to(device)\n",
    "    \n",
    "    warp_layer = Warp().to(device)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LOSS & OPTIMIZER\n",
    "    # ========================================================================\n",
    "    \n",
    "    loss_sim = GlobalMutualInformationLoss()\n",
    "    loss_reg = BendingEnergyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TRAINING LOOP\n",
    "    # ========================================================================\n",
    "    \n",
    "    best_val_dice = 0.0\n",
    "    training_history = []\n",
    "    \n",
    "    for epoch in range(config[\"max_epochs\"]):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_sim_loss = 0\n",
    "        epoch_reg_loss = 0\n",
    "        step = 0\n",
    "        \n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            fixed = batch_data[\"fixed\"].to(device)\n",
    "            moving = batch_data[\"moving\"].to(device)\n",
    "            \n",
    "            # Forward\n",
    "            input_tensor = torch.cat((moving, fixed), dim=1)\n",
    "            ddf = model(input_tensor)\n",
    "            pred_image = warp_layer(moving, ddf)\n",
    "            \n",
    "            # Loss calculation\n",
    "            sim_loss = loss_sim(pred_image, fixed)\n",
    "            reg_loss = loss_reg(ddf)\n",
    "            total_loss = sim_loss + config[\"reg_weight\"] * reg_loss\n",
    "            \n",
    "            # Backward\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += total_loss.item()\n",
    "            epoch_sim_loss += sim_loss.item()\n",
    "            epoch_reg_loss += reg_loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / step\n",
    "        avg_sim = epoch_sim_loss / step\n",
    "        avg_reg = epoch_reg_loss / step\n",
    "        \n",
    "        print(f\"\u2705 Epoch {epoch + 1}/{config['max_epochs']}\")\n",
    "        print(f\"   Loss: {avg_loss:.4f} (Sim: {avg_sim:.4f}, Reg: {avg_reg:.4f})\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # VALIDATION\n",
    "        # ====================================================================\n",
    "        \n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            val_dice_scores = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    fixed = val_batch[\"fixed\"].to(device)\n",
    "                    moving = val_batch[\"moving\"].to(device)\n",
    "                    fixed_lbl = val_batch[\"fixed_label\"].to(device)\n",
    "                    moving_lbl = val_batch[\"moving_label\"].to(device)\n",
    "                    \n",
    "                    input_tensor = torch.cat((moving, fixed), dim=1)\n",
    "                    ddf = model(input_tensor)\n",
    "                    pred_label = warp_layer(moving_lbl, ddf)\n",
    "                    \n",
    "                    # Dice calculation\n",
    "                    intersection = (pred_label * fixed_lbl).sum()\n",
    "                    dice = (2.0 * intersection + 1e-5) / (pred_label.sum() + fixed_lbl.sum() + 1e-5)\n",
    "                    val_dice_scores.append(dice.item())\n",
    "            \n",
    "            avg_val_dice = np.mean(val_dice_scores)\n",
    "            print(f\"   Val Dice: {avg_val_dice:.4f}\")\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step(avg_loss)\n",
    "            \n",
    "            # Save best model\n",
    "            if avg_val_dice > best_val_dice:\n",
    "                best_val_dice = avg_val_dice\n",
    "                print(f\"   \ud83c\udfc6 New best model! Dice: {best_val_dice:.4f}\")\n",
    "                save_model_to_stage(model, f\"{save_path}/best_model.pth\")\n",
    "        \n",
    "        # Record history\n",
    "        training_history.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": avg_loss,\n",
    "            \"train_sim\": avg_sim,\n",
    "            \"train_reg\": avg_reg,\n",
    "            \"val_dice\": avg_val_dice if val_loader else None\n",
    "        })\n",
    "        \n",
    "        # Periodic checkpoint\n",
    "        if (epoch + 1) % config[\"save_interval\"] == 0:\n",
    "            checkpoint_path = f\"{save_path}/checkpoint_epoch_{epoch+1}.pth\"\n",
    "            save_model_to_stage(model, checkpoint_path)\n",
    "            print(f\"   \ud83d\udcbe Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SAVE FINAL MODEL\n",
    "    # ========================================================================\n",
    "    \n",
    "    final_path = f\"{save_path}/final_model.pth\"\n",
    "    save_model_to_stage(model, final_path)\n",
    "    print(f\"\ud83c\udfc1 Training complete! Final model: {final_path}\")\n",
    "    \n",
    "    return {\n",
    "        \"final_model_path\": final_path,\n",
    "        \"best_model_path\": f\"{save_path}/best_model.pth\",\n",
    "        \"best_val_dice\": best_val_dice,\n",
    "        \"training_history\": training_history\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def save_model_to_stage(model, stage_path):\n",
    "    \"\"\"\n",
    "    Save PyTorch model to Snowflake stage with correct filename.\n",
    "    \n",
    "    Args:\n",
    "        stage_path: Full stage path like \"@RESULTS_STG/final_model.pth\"\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Extract the desired filename from stage_path\n",
    "    # \"@RESULTS_STG/final_model.pth\" -> \"final_model.pth\"\n",
    "    filename = stage_path.split('/')[-1]\n",
    "    \n",
    "    # Create local file with EXACT name we want\n",
    "    local_path = f\"/tmp/{filename}\"\n",
    "    \n",
    "    # Save model locally\n",
    "    torch.save(model.state_dict(), local_path)\n",
    "    \n",
    "    # Extract stage directory (without filename)\n",
    "    # \"@RESULTS_STG/final_model.pth\" -> \"@RESULTS_STG\"\n",
    "    stage_dir = '/'.join(stage_path.split('/')[:-1])\n",
    "    \n",
    "    try:\n",
    "        session = get_active_session()\n",
    "        \n",
    "        # Upload to stage DIRECTORY only (filename preserved from local)\n",
    "        session.file.put(\n",
    "            local_path,\n",
    "            stage_dir,  # \u2705 Just the directory!\n",
    "            overwrite=True,\n",
    "            auto_compress=False\n",
    "        )\n",
    "        \n",
    "        print(f\"\u2705 Saved to {stage_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Failed to save: {e}\")\n",
    "    finally:\n",
    "        # Clean up local file\n",
    "        if os.path.exists(local_path):\n",
    "            os.unlink(local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b3abc",
   "metadata": {
    "name": "step7_header"
   },
   "source": [
    "## Step 7: Prepare Training and Validation Sets\n",
    "\n",
    "Now we split our dataset into:\n",
    "- **Training Set (80%)** - Used for model optimization\n",
    "- **Validation Set (20%)** - Used for monitoring performance and early stopping\n",
    "\n",
    "This split helps prevent overfitting and ensures our model generalizes to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819b251-0382-43de-8d7a-b39a2545c1fe",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "prepare_splits"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONVERT RAY DATASET TO PYTHON LIST\n",
    "# ============================================================================\n",
    "# Ray datasets are distributed - we need to collect them for training\n",
    "\n",
    "train_files_list = []\n",
    "\n",
    "# Iterate through all image pairs in the Ray dataset\n",
    "for row in ray_dataset.iter_rows():\n",
    "    train_files_list.append({\n",
    "        \"fixed_path\": row[\"fixed_path\"],        # Expiration CT path\n",
    "        \"moving_path\": row[\"moving_path\"],      # Inspiration CT path\n",
    "        \"fixed_label_path\": row[\"fixed_label_path\"],    # Expiration lung mask\n",
    "        \"moving_label_path\": row[\"moving_label_path\"]   # Inspiration lung mask\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SPLIT INTO TRAINING AND VALIDATION SETS (80/20)\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate split index (80% for training)\n",
    "split_idx = int(0.8 * len(train_files_list))\n",
    "\n",
    "# Create splits\n",
    "train_split = train_files_list[:split_idx]   # First 80%\n",
    "val_split = train_files_list[split_idx:]     # Last 20%\n",
    "\n",
    "# Display split information\n",
    "print(f\"\ud83d\udcca Training: {len(train_split)} pairs, Validation: {len(val_split)} pairs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba77249",
   "metadata": {
    "name": "step8_header"
   },
   "source": [
    "## Step 8: Launch Training \ud83d\ude80\n",
    "\n",
    "Time to train! This cell:\n",
    "1. **Defines hyperparameters** - Learning rate, batch size, epochs, etc.\n",
    "2. **Launches distributed training** - Runs on GPU via Ray\n",
    "3. **Monitors progress** - Prints training loss and validation Dice score\n",
    "4. **Saves best model** - Checkpoints to Snowflake stage\n",
    "\n",
    "**Expected Training Time**: ~10-30 minutes depending on dataset size and GPU.\n",
    "\n",
    "**What is Dice Score?** \n",
    "A metric for segmentation overlap (0 = no overlap, 1 = perfect overlap). We use it to evaluate registration quality by warping lung masks and comparing them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad356002",
   "metadata": {
    "name": "training_config"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING CONFIGURATION & HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# CT WINDOWING PARAMETERS (Hounsfield Units)\n",
    "# ============================================================================\n",
    "# These define the CT intensity range we're interested in for lung imaging\n",
    "CT_MIN_HU = -1000  # Air (lowest HU in lungs)\n",
    "CT_MAX_HU = 500    # Soft tissue/bone (upper limit for lung CT)\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL & TRAINING HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "CONFIG = {\n",
    "    # Image size after preprocessing (downsampled for memory efficiency)\n",
    "    \"spatial_size\": (96, 96, 104),  # (Height, Width, Depth)\n",
    "    \n",
    "    # Network architecture parameter (controls model capacity)\n",
    "    \"num_channel_initial\": 32,  # Number of feature channels in first layer\n",
    "    \n",
    "    # Training parameters\n",
    "    \"batch_size\": 2,            # Number of image pairs per batch (limited by GPU memory)\n",
    "    \"learning_rate\": 1e-4,      # Adam optimizer learning rate\n",
    "    \"max_epochs\": 25,           # Total training iterations through dataset\n",
    "    \n",
    "    # Loss function weighting\n",
    "    \"reg_weight\": 1.0,          # Weight for regularization (smoothness penalty)\n",
    "                                # Lower = more flexible deformations\n",
    "                                # Higher = smoother but potentially less accurate\n",
    "    \n",
    "    # Checkpointing\n",
    "    \"save_interval\": 10,        # Save model checkpoint every N epochs\n",
    "}\n",
    "\n",
    "print(\"\u2705 Training configuration defined:\")\n",
    "print(f\"   CT Window: [{CT_MIN_HU}, {CT_MAX_HU}] HU\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1404bb",
   "metadata": {
    "name": "launch_training"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LAUNCH DISTRIBUTED TRAINING ON GPU\n",
    "# ============================================================================\n",
    "\n",
    "# Submit training task to Ray (runs on GPU-enabled node)\n",
    "training_future = train_registration_model.remote(\n",
    "    train_files=train_split,       # Training image pairs\n",
    "    val_files=val_split,           # Validation image pairs\n",
    "    config=CONFIG,                 # Hyperparameters defined above\n",
    "    save_path=f\"@{DATABASE_NAME}.UTILS.RESULTS_STG\"  # Snowflake stage for checkpoints\n",
    ")\n",
    "\n",
    "# Wait for training to complete and retrieve results\n",
    "# This will block until training finishes (could take 10-30 minutes)\n",
    "training_result = ray.get(training_future)\n",
    "\n",
    "# Display results in Streamlit UI\n",
    "st.success(f\"\u2705 Training Complete! Best Dice: {training_result['best_val_dice']:.4f}\")\n",
    "st.json(training_result)  # Show full training history and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9263d1",
   "metadata": {
    "name": "step9_header"
   },
   "source": [
    "## Step 9: Verify Saved Model Checkpoints\n",
    "\n",
    "Let's verify that our model was successfully saved to the Snowflake stage during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8def641-cab2-411e-afea-4cddd375a70a",
   "metadata": {
    "language": "sql",
    "name": "verify_checkpoints"
   },
   "outputs": [],
   "source": [
    "ls @results_stg;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cffd8",
   "metadata": {
    "name": "step10_header"
   },
   "source": [
    "## Step 10: Register Model in Snowflake Model Registry\n",
    "\n",
    "Now we register our trained model in Snowflake's Model Registry for:\n",
    "- **Version Control** - Track different model versions over time\n",
    "- **Deployment** - Easy deployment to inference services\n",
    "- **Reproducibility** - Store model metadata alongside weights\n",
    "- **Collaboration** - Share models across teams\n",
    "\n",
    "The Model Registry provides enterprise-grade model management capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516744e-8d09-4489-bacc-ece5379f4d66",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "register_model_func"
   },
   "outputs": [],
   "source": [
    "# Required imports for model registration\n",
    "import torch                                        # PyTorch deep learning framework\n",
    "import io                                          # For binary stream handling\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.ml.registry import Registry         # Snowflake Model Registry\n",
    "from monai.networks.nets import LocalNet          # Registration network architecture\n",
    "\n",
    "session = get_active_session()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL REGISTRATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def register_model(\n",
    "    model_stage_path=f\"@{DATABASE_NAME}.UTILS.RESULTS_STG/best_model.pth\",\n",
    "    model_name=\"LUNG_CT_REGISTRATION\",\n",
    "    version_name=\"v1\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Register a trained PyTorch model in Snowflake Model Registry.\n",
    "    \n",
    "    This function:\n",
    "    1. Loads model weights from Snowflake stage\n",
    "    2. Reconstructs the model architecture\n",
    "    3. Registers the model with sample input for schema inference\n",
    "    4. Returns a model reference for deployment\n",
    "    \n",
    "    Args:\n",
    "        model_stage_path (str): Path to .pth file in Snowflake stage\n",
    "        model_name (str): Name for the model in registry\n",
    "        version_name (str): Version identifier (e.g., \"v1\", \"v2\")\n",
    "    \n",
    "    Returns:\n",
    "        ModelReference: Reference to registered model\n",
    "    \"\"\"\n",
    "    print(f\"\ud83d\udd04 Registering {model_name} v{version_name}...\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Load model weights from Snowflake stage\n",
    "    # ========================================================================\n",
    "    raw_stream = session.file.get_stream(model_stage_path)\n",
    "    state_dict = torch.load(\n",
    "        io.BytesIO(raw_stream.read()), \n",
    "        map_location='cpu'  # Load to CPU first (works on any node)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: Reconstruct model architecture\n",
    "    # ========================================================================\n",
    "    # Architecture must match the one used during training!\n",
    "    model = LocalNet(\n",
    "        spatial_dims=3,              # 3D medical images\n",
    "        in_channels=2,               # Concatenated fixed + moving (2 images)\n",
    "        out_channels=3,              # 3D deformation field (x, y, z displacement)\n",
    "        num_channel_initial=32,      # Feature channels (must match training)\n",
    "        extract_levels=[3],          # U-Net depth\n",
    "        out_activation=None,         # No activation on output (regression task)\n",
    "        out_kernel_initializer=\"zeros\"  # Initialize to identity transform\n",
    "    )\n",
    "    \n",
    "    # Load trained weights into architecture\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Set to evaluation mode (disable dropout, batch norm tracking)\n",
    "    model.eval()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: Create sample input for schema inference\n",
    "    # ========================================================================\n",
    "    # Model Registry uses this to infer input/output shapes\n",
    "    # Shape: (batch=1, channels=2, H=96, W=96, D=104)\n",
    "    sample_input = torch.randn(1, 2, 96, 96, 104)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 4: Register model in Snowflake Model Registry\n",
    "    # ========================================================================\n",
    "    registry = Registry(\n",
    "        session, \n",
    "        database_name=DATABASE_NAME, \n",
    "        schema_name=\"UTILS\"\n",
    "    )\n",
    "    \n",
    "    model_ref = registry.log_model(\n",
    "        model_name=model_name,\n",
    "        version_name=version_name,\n",
    "        model=model,                    # PyTorch model (registry handles conversion)\n",
    "        sample_input_data=sample_input  # For input/output schema inference\n",
    "    )\n",
    "    \n",
    "    print(f\"\u2705 Registered: {model_ref.fully_qualified_model_name}\")\n",
    "    return model_ref\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b737b56",
   "metadata": {
    "name": "step11_header"
   },
   "source": [
    "## Step 11: Execute Model Registration\n",
    "\n",
    "Run the registration function and verify the model appears in the registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df533a3f-99fa-4862-add3-478e8aafb1e0",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "execute_registration"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXECUTE MODEL REGISTRATION\n",
    "# ============================================================================\n",
    "\n",
    "# Register the best model from training\n",
    "# This creates a new entry in the Model Registry\n",
    "model_ref = register_model(\n",
    "    model_stage_path=f\"@{DATABASE_NAME}.UTILS.RESULTS_STG/best_model.pth\",  # Best checkpoint\n",
    "    model_name=\"LUNG_CT_REGISTRATION\",   # Model identifier\n",
    "    version_name=\"v1\"                     # Version tag (increment for updates)\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFY REGISTRATION SUCCESS\n",
    "# ============================================================================\n",
    "\n",
    "# Connect to Model Registry\n",
    "registry = Registry(\n",
    "    session, \n",
    "    database_name=DATABASE_NAME, \n",
    "    schema_name=\"UTILS\"\n",
    ")\n",
    "\n",
    "# List all registered models\n",
    "all_models = registry.show_models()\n",
    "\n",
    "print(\"\\n\ud83d\udcda All registered models in {DATABASE_NAME}.UTILS:\")\n",
    "print(all_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f496ed",
   "metadata": {
    "name": "step12_header"
   },
   "source": [
    "## Step 12: Test Model Loading & Inference\n",
    "\n",
    "Verify we can load the registered model and run inference. This confirms the model is ready for deployment!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f3326-12ed-402a-bc9b-fd0ca46a0121",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "test_inference"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD MODEL FROM REGISTRY\n",
    "# ============================================================================\n",
    "\n",
    "# Retrieve the registered model by name and version\n",
    "loaded = registry.get_model(\"LUNG_CT_REGISTRATION\").version(\"v1\")\n",
    "print(f\"\\n\u2705 Successfully loaded: {loaded.model_name}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST INFERENCE WITH DUMMY DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Create synthetic test input matching expected shape\n",
    "# Shape: (batch=1, channels=2, H=96, W=96, D=104)\n",
    "# Channels: [fixed_image, moving_image] concatenated\n",
    "test_input = torch.randn(1, 2, 96, 96, 104)\n",
    "\n",
    "try:\n",
    "    # Run inference (predicts 3D deformation field)\n",
    "    result = loaded.run(test_input)\n",
    "    \n",
    "    print(f\"\u2705 Test inference works! Output shape: {result.shape}\")\n",
    "    print(f\"   Expected: (1, 3, 96, 96, 104) - 3D displacement field\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # If there's an error, it's still registered (just can't run on synthetic data)\n",
    "    print(f\"\u2139\ufe0f  Note: {e}\")\n",
    "    print(\"   Model is registered successfully!\")\n",
    "    print(\"   (Use with actual preprocessed CT data for real inference)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ee158",
   "metadata": {
    "name": "dynamic_summary"
   },
   "outputs": [],
   "source": [
    "# Dynamic summary with actual database name\n",
    "st.markdown(f\"\"\"\n",
    "## \ud83c\udf89 Training Complete!\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. \u2705 **Set up distributed computing** with Ray on Snowflake containers\n",
    "2. \u2705 **Loaded medical images** from Snowflake stages (just-in-time)\n",
    "3. \u2705 **Trained a deep learning model** for CT registration using MONAI\n",
    "4. \u2705 **Monitored training** with validation metrics (Dice score)\n",
    "5. \u2705 **Saved model checkpoints** to Snowflake stages\n",
    "6. \u2705 **Registered model** in Snowflake Model Registry\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Deploy for Inference**: Use the registered model in 03_model_inference\n",
    "- **Tune Hyperparameters**: Adjust learning rate, regularization weight, or epochs\n",
    "- **Add More Data**: Train on larger datasets for better generalization\n",
    "- **Export Visualizations**: Save training loss curves and sample predictions\n",
    "\n",
    "### Model Location\n",
    "\n",
    "- **Checkpoints**: `@{DATABASE_NAME}.UTILS.RESULTS_STG/best_model.pth`\n",
    "- **Registry**: `{DATABASE_NAME}.UTILS.LUNG_CT_REGISTRATION` (version v1)\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to run inference? Proceed to 03_model_inference!** \ud83d\ude80\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_spcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  },
  "lastEditStatus": {
   "authorEmail": "carlos.guzman@snowflake.com",
   "authorId": "4124439897012",
   "authorName": "CGUZMAN",
   "lastEditTime": 1763698038769,
   "notebookId": "u24q2ex56v4septcdgf4",
   "sessionId": "a47d4778-ca0f-4e20-98b9-25cb3d3908b0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}